---
code-fold: show
code-annotations: hover
---

# Sieci splotowe

W tym rozdziale przedstawimy konwolucyjne (lub splotowe) sieci neuronowe (ang. *convolutional neural networks*), znane również jako *CovNets*, rodzaj modelu głębokiego uczenia się, który jest niemal zawsze stosowany w aplikacjach widzenia komputerowego.

Wkrótce zagłębimy się w teorię tego, czym są sieci splotowe i dlaczego odniosły taki sukces w zadaniach związanych z widzeniem komputerowym.
Ale najpierw przyjrzyjmy się w praktyce prostemu przykładowi sieci splotowej.
Wykorzystuje on sieć kowolucyjną do klasyfikacji cyfr MNIST, czyli zadania, które wykonaliśmy wcześnej przy użyciu sieci gęsto połączonej (nasza dokładność testu wyniosła wtedy 97,8%).

Poniższe linie kodu pokazują, jak wygląda podstawowa sieć *CovNet*.
Jest to stos warstw `layer_conv_2d` i `layer_max_pooling_2d` o których zasadzie działania będzie jeszcze więcej za chwilę.

```{r}
library(keras)
model <- keras_model_sequential() %>%
  layer_conv_2d(filters = 32, kernel_size = c(3, 3), activation = "relu",
  input_shape = c(28, 28, 1)) %>%
  layer_max_pooling_2d(pool_size = c(2, 2)) %>%
  layer_conv_2d(filters = 64, kernel_size = c(3, 3), activation = "relu") %>%
  layer_max_pooling_2d(pool_size = c(2, 2)) %>%
  layer_conv_2d(filters = 64, kernel_size = c(3, 3), activation = "relu")
```

Co ważne, *CovNet* przyjmuje jako dane wejściowe tensory o kształcie `(image_height, image_width, image_channels)` (nie licząc wymiaru partii).
W tym przypadku skonfigurujemy sieć do przetwarzania danych wejściowych o rozmiarze `(28, 28, 1)`, czyli w formacie obrazów MNIST.
Zrobimy to przekazując argument `input_shape = c(28, 28, 1)` do pierwszej warstwy.

```{r}
model
```

Możesz zauważyć, że wyjście z warstw `layer_conv_2d` i `layer_max_pooling_2d` jest tensorem 3D kształtu `(wysokość, szerokość, filtry)`[^convolution-1].
Wymiary szerokości i wysokości mają tendencję do kurczenia się, gdy wchodzisz głębiej w sieć.
Liczba filtrów jest kontrolowana przez pierwszy argument przekazany do `layer_conv_2d` (32 lub 64).

[^convolution-1]: w niektórych publikacjach ostatni parametr jest nazywany kanałami, ale aby nie wprowadzać zamieszania, ponieważ nazwa kanał jest zarezerwowana do obrazów, to zostanę przy nazwie filtry

Następnym krokiem jest wprowadzenie ostatniego tensora wyjściowego (o kształcie `(3, 3, 64)`) do gęsto połączonej sieci klasyfikatorów, takich jak te, które już znasz - stosu gęstych warstw.
Te klasyfikatory przetwarzają wektory, które są 1D, podczas gdy bieżące wyjście jest tensorem 3D.
Najpierw musimy spłaszczyć wyjścia 3D do 1D, a następnie dodać kilka gęstych warstw na wierzchu.

```{r}
model <- model %>%
  layer_flatten() %>%
  layer_dense(units = 64, activation = "relu") %>%
  layer_dense(units = 10, activation = "softmax")
```

Zrobimy klasyfikację 10-kierunkową, używając warstwy końcowej z 10 wyjściami i aktywacją softmax.
Oto jak wygląda teraz sieć:

```{r}
model
```

Jak widać, wyjścia `(3, 3, 64)` są spłaszczane do wektorów o kształcie `(576)`[^convolution-2] przed przejściem przez dwie warstwy gęste.

[^convolution-2]: ponieważ 3\*3\*64=576

```{r}
#| cache: true
mnist <- dataset_mnist()

c(c(train_images, train_labels), c(test_images, test_labels)) %<-% mnist
train_images <- array_reshape(train_images, c(60000, 28, 28, 1))
train_images <- train_images / 255
test_images <- array_reshape(test_images, c(10000, 28, 28, 1))
test_images <- test_images / 255
train_labels <- to_categorical(train_labels)
test_labels <- to_categorical(test_labels)
```

```{r}
#| eval: false
model %>% compile(
  optimizer = "rmsprop",
  loss = "categorical_crossentropy",
  metrics = c("accuracy")
)

history <- model %>% fit(
  train_images, 
  train_labels,
  epochs = 5, 
  batch_size=64,
  validation_split = 0.2
)
```

```{r}
#| echo: false
model <- load_model_tf(filepath = "models/conv_mnist1/")
load("models/conv_hist1.rda")
plot(history)
```

Jak widać z powyższego wykresu model bardzo dobrze dopasował się do danych.
Sprawdźmy zatem jak sobie radzi na zbiorze testowym.

```{r}
# cache: true
results <- model %>% evaluate(test_images, test_labels)
results
```

W rezultacie otrzymaliśmy sieć o dokładności 0.9908.
Choć może to w stosunku do 0.9779, czyli dokładności dla sieci gęstej z pierwszego przykładu MNIST, to jednak względny błąd predykcji dla sieci splotowej zmalał o ponad 58% `r emo::ji("star_struck")`.

Wynik imponujący, zatem pojawia się pytanie skąd taka dokładność?
na czym polega magia sieci splotowych?
W poniższych listingach postaramy się to wyjaśnić.

``` r
#| label: fig-conv1
#| fig-cap: Wyniki filtracji pierwszą warstwą splotową (wybrano filtry 4 i 10)
#| layout-ncol: 2
img <- train_images[44,,,] |> as.raster() # <1>
plot(img, interp=F)

img_tensor <- train_images[44,,,] # <2>
dim(img_tensor)

img_tensor <- array_reshape(img_tensor, c(1, 28, 28, 1)) # <3>
dim(img_tensor)

layer_outputs <- lapply(model$layers[1:5], function(layer) layer$output) # <4>
layer_outputs

activation_model <- keras_model(inputs = model$input, outputs = layer_outputs) # <5>
activations <- activation_model %>% predict(img_tensor)

first_layer_activation <- activations[[1]] # <6>
dim(first_layer_activation)

plot_channel <- function(channel) { # <7>
  rotate <- function(x) t(apply(x, 2, rev))
  image(rotate(channel), axes = FALSE, asp = 1, 
        col = gray.colors(20))
}

plot_channel(first_layer_activation[1,,,4]) # <8>
plot_channel(first_layer_activation[1,,,10])
```

1.  wybierz obraz
2.  zamień go na tensor
3.  dostosuj rozmiar tensora do wejścia do sieci
4.  wylistuj wszystkie wyjścia z sieci splotowych
5.  stwórz model pomocniczy składający się z wejścia i warstw splotowych
6.  wybierz warstwę do wizualizacji
7.  napisz funkcję do wyświetlania obrazów
8.  rysuj obrazy

Tak wygląda wynik pierwszej warstwy splotowej dla wybranych dwóch filtrów (kanałów), a jakby to wyglądało gdyby wyświetlić wyniki wszystkich warstw i kanałów.

``` r
#| eval: false
dir.create("nine_activations") # <1>
image_size <- 58 # <2>
images_per_row <- 16 # <3>
for (i in 1:5) { # <4>
  
  layer_activation <- activations[[i]] # <5>
  layer_name <- model$layers[[i]]$name $ #<6>

  n_features <- dim(layer_activation)[[4]] # <7>
  n_cols <- n_features %/% images_per_row # <8>
 
  png(paste0("nine_activations/", i, "_", layer_name, ".png"), # <9>
      width = image_size * images_per_row, 
      height = image_size * n_cols)
  op <- par(mfrow = c(n_cols, images_per_row), mai = rep_len(0.02, 4)) # <10>
  
  for (col in 0:(n_cols-1)) { # <11>
    for (row in 0:(images_per_row-1)) { # <12>
      channel_image <- layer_activation[1,,,(col*images_per_row) + row + 1] # <13>
      plot_channel(channel_image) # <14>
    }
  }
  
  par(op)
  dev.off() # <15>
}
```

1.  stwórz katalog na obrazy
2.  wybierz wielkość obrazu w px
3.  wybierz ile obrazów ma się mieścić w wierszu
4.  rozpocznij pętlę po wszystkich nr warstw splowych
5.  przypisz i-tą warstwę
6.  zapisz nazwę warstwy
7.  wyciągnij liczbę filtrów
8.  oblicz liczbę obrazów na wiersz
9.  stwórz plik png o wymiarach zgodnych z liczbą obrazów w wierszu i liczbą wierszy
10. określ parametry obrazu (zmiana layout i marginesów)
11. rozpocznij pętlę po kolumnach
12. rozpocznij pętlę po wierszach
13. wybierz filtr do obrazowania
14. narysuj obraz filtra
15. zapisz plik

![](nine_activations/1_conv2d_14.png){fig-align="center" width="1000"}

![](nine_activations/2_max_pooling2d_9.png){fig-align="center" width="1000"}

![](nine_activations/3_conv2d_13.png){fig-align="center" width="1000"}

![](nine_activations/4_max_pooling2d_8.png){fig-align="center" width="1000"}

![](nine_activations/5_conv2d_12.png){fig-align="center" width="1000"}

Wyniki wszystkich warstw splotowych i wszystkich filtrów
