<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="pl" xml:lang="pl"><head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="generator" content="quarto-1.4.549">
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">
<title>Automatyczna analiza obrazu - 14&nbsp; Segmentacja obrazów</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>

<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./references.html" rel="next">
<link href="./example.html" rel="prev">
<link href="./cover.png" rel="icon" type="image/png">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-dark.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="site_libs/bootstrap/bootstrap-dark.min.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark"><script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "Brak wyników",
    "search-matching-documents-text": "dopasowane dokumenty",
    "search-copy-link-title": "Kopiuj link do wyszukiwania",
    "search-hide-matches-text": "Ukryj dodatkowe dopasowania",
    "search-more-match-text": "więcej dopasowań w tym dokumencie",
    "search-more-matches-text": "więcej dopasowań w tym dokumencie",
    "search-clear-button-title": "Wyczyść",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Anuluj",
    "search-submit-button-title": "Zatwierdź",
    "search-label": "Szukaj"
  }
}</script>
</head>
<body class="nav-sidebar floating slimcontent">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top"><nav class="quarto-secondary-nav"><div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Przełącz pasek boczny" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./segmentation.html"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Segmentacja obrazów</span></a></li></ol></nav>
        <a class="flex-grow-1" role="button" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Przełącz pasek boczny" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav></header><!-- content --><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto"><div class="pt-lg-2 mt-2 text-left sidebar-header sidebar-header-stacked">
      <a href="./index.html" class="sidebar-logo-link">
      <img src="./images/logo.jpg" alt="" class="sidebar-logo py-0 d-lg-inline d-none"></a>
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Automatyczna analiza obrazu</a> 
        <div class="sidebar-tools-main tools-wide">
    <a href="https://twitter.com" title="" class="quarto-navigation-tool px-1" aria-label=""><i class="bi bi-twitter"></i></a>
    <a href="https://github.com/dax44/ComputerVision/" title="Source Code" class="quarto-navigation-tool px-1" aria-label="Source Code"><i class="bi bi-github"></i></a>
    <a href="https://twitter.com/intent/tweet?url=%7Curl%7C" title="Twitter" class="quarto-navigation-tool px-1" aria-label="Twitter"><i class="bi bi-twitter"></i></a>
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Przełącz tryb ciemny"><i class="bi"></i></a>
  <a href="" class="quarto-reader-toggle quarto-navigation-tool px-1" onclick="window.quartoToggleReader(); return false;" title="Przełącz tryb czytnika">
  <div class="quarto-reader-toggle-btn">
  <i class="bi"></i>
  </div>
</a>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Szukaj"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Wstęp</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Wprowadzenie</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./history.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Historia wizji komputerowej</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./digt_img.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Obrazy cyfrowe</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./transformations.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Transformacje geometryczne</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./point_trans.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Transformacje punktowe</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./filters.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Filtry</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./edge.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Wykrywanie krawędzi i konturów</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./morpho.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Filtry morfologiczne</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./fourier.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Transformata Fouriera</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./deeplearning.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Deep learning</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./fundamentals.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Fundamenty DNN</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./convolution.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Sieci splotowe</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./example.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Przykład uczenia sieci splotowej</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./segmentation.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Segmentacja obrazów</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Bibliografia</span></a>
  </div>
</li>
    </ul>
</div>
</nav><div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active"><h2 id="toc-title">Spis treści</h2>
   
  <ul>
<li>
<a href="#nowoczesne-architektury-sieci-splotowych" id="toc-nowoczesne-architektury-sieci-splotowych" class="nav-link active" data-scroll-target="#nowoczesne-architektury-sieci-splotowych"><span class="header-section-number">14.1</span> Nowoczesne architektury sieci splotowych</a>
  <ul class="collapse">
<li><a href="#po%C5%82%C4%85czenia-rezydualne" id="toc-połączenia-rezydualne" class="nav-link" data-scroll-target="#po%C5%82%C4%85czenia-rezydualne"><span class="header-section-number">14.1.1</span> Połączenia rezydualne</a></li>
  <li><a href="#normalizacja-partii" id="toc-normalizacja-partii" class="nav-link" data-scroll-target="#normalizacja-partii"><span class="header-section-number">14.1.2</span> Normalizacja partii</a></li>
  <li><a href="#konwolucje-separowalne" id="toc-konwolucje-separowalne" class="nav-link" data-scroll-target="#konwolucje-separowalne"><span class="header-section-number">14.1.3</span> Konwolucje separowalne</a></li>
  <li><a href="#przyk%C5%82ad-wykorzystania-sieci-xception" id="toc-przykład-wykorzystania-sieci-xception" class="nav-link" data-scroll-target="#przyk%C5%82ad-wykorzystania-sieci-xception"><span class="header-section-number">14.1.4</span> Przykład wykorzystania sieci Xception</a></li>
  </ul>
</li>
  <li><a href="#co-widzi-sie%C4%87-konwolucyjna" id="toc-co-widzi-sieć-konwolucyjna" class="nav-link" data-scroll-target="#co-widzi-sie%C4%87-konwolucyjna"><span class="header-section-number">14.2</span> Co widzi sieć konwolucyjna?</a></li>
  </ul><div class="toc-actions"><ul><li><a href="https://github.com/dax44/ComputerVision/issues/new" class="toc-action"><i class="bi bi-github"></i>Zgłoś problem</a></li></ul></div></nav>
    </div>
<!-- main -->
<main class="content page-columns page-full" id="quarto-document-content"><header id="title-block-header" class="quarto-title-block default"><div class="quarto-title">
<h1 class="title">
<span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Segmentacja obrazów</span>
</h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header><p>Do tej pory skupialiśmy się na modelach klasyfikacji obrazów gdzie wejściem był obraz, a wyjściem etykieta: “Ten obraz prawdopodobnie zawiera kota; ten inny prawdopodobnie zawiera psa”. Ale klasyfikacja obrazów jest tylko jednym z kilku możliwych zastosowań głębokiego uczenia w wizji komputerowej. Ogólnie rzecz biorąc, istnieją trzy podstawowe zadania wizji komputerowej:</p>
<ul>
<li>Klasyfikacja obrazu - gdy celem jest przypisanie jednej lub więcej etykiet do obrazu. Może to być klasyfikacja jednoetykietowa (obraz może należeć tylko do jednej kategorii, z pominięciem innych) lub wieloetykietowa (oznaczanie wszystkich kategorii, do których należy obraz, jak widać na <a href="#fig-seg1" class="quarto-xref">Rysunek&nbsp;<span>14.1</span></a>). Na przykład, gdy wyszukujemy słowo kluczowe w aplikacji Zdjęcia Google, za kulisami odpytujemy bardzo duży model klasyfikacji wieloznakowej - jedna z ponad 20 000 różnych klas, wytrenowany na milionach obrazów.</li>
<li>Segmentacja obrazu - gdy celem jest “podział” obrazu na różne obszary, przy czym każdy obszar reprezentuje zazwyczaj kategorię (jak widać na <a href="#fig-seg1" class="quarto-xref">Rysunek&nbsp;<span>14.1</span></a>). Na przykład, gdy podczas rozmowy wideo Zoom lub Google Meet wyświetlają za nami niestandardowe tła, wykorzystywana jest wówczas segmentacji obrazu, aby odróżnić naszą twarz od tego, co znajduje się za nią, z dokładnością do piksela.</li>
<li>Wykrywanie obiektów - gdzie celem jest narysowanie prostokątów (zwanych polami ograniczającymi) wokół interesujących obiektów na obrazie i powiązanie każdego prostokąta z klasą. Samochód samojezdny może używać modelu wykrywania obiektów do monitorowania samochodów, pieszych i znaków w polu widzenia kamer.</li>
</ul>
<div id="fig-seg1" class="quarto-figure quarto-figure-center quarto-float anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure"><div aria-describedby="fig-seg1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="images/Zrzut ekranu 2023-03-18 o 10.29.55.png" class="img-fluid quarto-figure quarto-figure-center figure-img" width="700">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-seg1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Rysunek&nbsp;14.1: Przykłady wykorzystania sieci splotowych w zadaniach z wizji komputerowej
</figcaption></figure>
</div>
<p>Głębokie uczenie dla wizji komputerowej obejmuje również szereg nieco bardziej niszowych zadań poza tymi trzema, takich jak ocena podobieństwa obrazów (szacowanie, jak bardzo dwa obrazy są podobne wizualnie), wykrywanie punktów kluczowych (wskazywanie atrybutów zainteresowania na obrazie, takich jak rysy twarzy), ocena pozy czy humoru, estymacja siatki 3D i tak dalej. Ale na początek klasyfikacja obrazów, segmentacja obrazów i wykrywanie obiektów stanowią podstawę, z którą powinniśmy poznać. Większość zastosowań wizji komputerowej sprowadza się do jednego z tych trzech zadań.</p>
<div class="quarto-figure quarto-figure-center page-columns page-full">
<figure class="figure page-columns page-full"><div class="page-columns page-full"><p></p><div class="no-row-height column-margin column-container"><img src="https://pcl.sitehost.iu.edu/rgoldsto/projects/segmentation.jpg" class="img-fluid quarto-figure quarto-figure-center figure-img" width="400"></div></div>
</figure>
</div>
<p>Segmentacja obrazu z głębokim uczeniem polega na użyciu modelu do przypisania klasy do każdego piksela w obrazie, a tym samym segmentacji obrazu na różne strefy (takie jak “tło” i “pierwszy plan” lub “droga”, “samochód” i “chodnik”). Ta ogólna kategoria technik może być wykorzystana do zasilania znacznej liczby cennych aplikacji w edycji obrazu i wideo, autonomicznej jazdy, robotyki, obrazowania medycznego, itp. Istnieją dwa różne rodzaje segmentacji obrazu, o których powinniśmy wiedzieć:</p>
<ul>
<li>Segmentacja semantyczna, gdzie każdy piksel jest niezależnie klasyfikowany do kategorii semantycznej, jak “kot”. Jeśli na obrazie są dwa koty, to wszystkie odpowiadające im piksele są mapowane do tej samej ogólnej kategorii “kot” (patrz <a href="#fig-seg2" class="quarto-xref">Rysunek&nbsp;<span>14.2</span></a>).</li>
<li>Segmentacja instancji, która ma na celu nie tylko klasyfikację pikseli obrazu według kategorii, ale także wyodrębnienie poszczególnych instancji obiektu. W przypadku obrazu z dwoma kotami segmentacja instancji traktowałaby “kot 1” i “kot 2” jako dwie oddzielne klasy pikseli (patrz <a href="#fig-seg2" class="quarto-xref">Rysunek&nbsp;<span>14.2</span></a>).</li>
</ul>
<p>W tym przykładzie skupimy się na segmentacji semantycznej: ponownie przyjrzymy się obrazom kotów i psów, i tym razem nauczymy się, jak odróżnić główny obiekt od jego tła.</p>
<div id="fig-seg2" class="quarto-figure quarto-figure-center quarto-float anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure"><div aria-describedby="fig-seg2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="images/Zrzut ekranu 2023-03-18 o 10.35.38.png" class="img-fluid quarto-figure quarto-figure-center figure-img" width="600">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-seg2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Rysunek&nbsp;14.2: Przykłady segmentacji
</figcaption></figure>
</div>
<p>Będziemy pracować z zestawem danych Oxford-IIIT Pets (<a href="http://www.robots.ox.ac.uk/~vgg/data/pets/" class="uri">http://www.robots.ox.ac.uk/~vgg/data/pets/</a>), który zawiera 7390 zdjęć różnych ras kotów i psów, wraz z maskami segmentacji pierwszego planu i tła dla każdego zdjęcia. Maska segmentacyjna jest odpowiednikiem etykiety: jest to obraz o tym samym rozmiarze co obraz wejściowy, z jednym kanałem koloru, gdzie każda wartość całkowita odpowiada klasie odpowiadającego jej piksela na obrazie wejściowym. W naszym przypadku piksele masek segmentacyjnych mogą przyjmować jedną z trzech wartości całkowitych:</p>
<ol type="1">
<li>pierwszy plan</li>
<li>tło</li>
<li>kontur</li>
</ol>
<div class="cell">
<details open="" class="code-fold"><summary>Kod</summary><div class="sourceCode" id="cb1"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># eval: false</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://fs.r-lib.org">fs</a></span><span class="op">)</span></span>
<span><span class="va">data_dir</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://fs.r-lib.org/reference/path.html">path</a></span><span class="op">(</span><span class="st">"/Users/majerek/Downloads/pets_dataset"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://fs.r-lib.org/reference/create.html">dir_create</a></span><span class="op">(</span><span class="va">data_dir</span><span class="op">)</span></span>
<span></span>
<span><span class="va">data_url</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://fs.r-lib.org/reference/path.html">path</a></span><span class="op">(</span><span class="st">"http://www.robots.ox.ac.uk/~vgg/data/pets/data"</span><span class="op">)</span> </span>
<span><span class="kw">for</span> <span class="op">(</span><span class="va">filename</span> <span class="kw">in</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"images.tar.gz"</span>, <span class="st">"annotations.tar.gz"</span><span class="op">)</span><span class="op">)</span> <span class="op">{</span></span>
<span>  <span class="co"># uncomment for the first time</span></span>
<span> <span class="co"># download.file(url = data_url / filename,</span></span>
<span> <span class="co">#             destfile = data_dir / filename)</span></span>
<span> <span class="co"># untar(data_dir / filename, exdir = data_dir)</span></span>
<span><span class="op">}</span></span></code><button title="Kopiuj do schowka" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>Obrazy wejściowe zapisywane są jako pliki JPG w folderze <code>images/</code> (np. <code>images/Abyssinian_1.jpg</code>), a odpowiadająca im maska segmentacyjna zapisywana jest jako plik PNG o tej samej nazwie w folderze <code>annotations/trimaps/</code> (np. <code>annotations/trimaps/Abyssinian_1.png</code>). Przygotujmy ramki danych (technicznie rzecz biorąc, <code>tibble</code>) z kolumnami dla naszych ścieżek do plików wejściowych, a także listę odpowiadających im ścieżek do plików maski:</p>
<div class="cell">
<details open="" class="code-fold"><summary>Kod</summary><div class="sourceCode" id="cb2"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">input_dir</span> <span class="op">&lt;-</span> <span class="va">data_dir</span> <span class="op">/</span> <span class="st">"images"</span></span>
<span><span class="va">target_dir</span> <span class="op">&lt;-</span> <span class="va">data_dir</span> <span class="op">/</span> <span class="st">"annotations/trimaps/"</span></span>
<span></span>
<span><span class="va">image_paths</span> <span class="op">&lt;-</span> <span class="fu">tibble</span><span class="fu">::</span><span class="fu"><a href="https://tibble.tidyverse.org/reference/tibble.html">tibble</a></span><span class="op">(</span></span>
<span> input <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/sort.html">sort</a></span><span class="op">(</span><span class="fu"><a href="https://fs.r-lib.org/reference/dir_ls.html">dir_ls</a></span><span class="op">(</span><span class="va">input_dir</span>, glob <span class="op">=</span> <span class="st">"*.jpg"</span><span class="op">)</span><span class="op">)</span>,</span>
<span> target <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/sort.html">sort</a></span><span class="op">(</span><span class="fu"><a href="https://fs.r-lib.org/reference/dir_ls.html">dir_ls</a></span><span class="op">(</span><span class="va">target_dir</span>, glob <span class="op">=</span> <span class="st">"*.png"</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span></code><button title="Kopiuj do schowka" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>Aby mieć pewność, że dopasujemy obraz do właściwego celu, posortujemy obie listy. Wektory ścieżek sortują się tak samo, ponieważ cele i ścieżki obrazów mają tę samą bazową nazwę pliku. Następnie, aby pomóc nam śledzić ścieżki i upewnić się, że nasze wektory wejściowe i docelowe pozostają zsynchronizowane, łączymy je w dwukolumnową ramkę danych (używamy <code>tibble()</code>, aby stworzyć ramkę danych):</p>
<div class="cell">
<details open="" class="code-fold"><summary>Kod</summary><div class="sourceCode" id="cb3"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu">tibble</span><span class="fu">::</span><span class="fu"><a href="https://pillar.r-lib.org/reference/glimpse.html">glimpse</a></span><span class="op">(</span><span class="va">image_paths</span><span class="op">)</span></span></code><button title="Kopiuj do schowka" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>Rows: 7,390
Columns: 2
$ input  &lt;fs::path&gt; "/Users/majerek/Downloads/pets_dataset/images/Abyssinian_1…
$ target &lt;fs::path&gt; "/Users/majerek/Downloads/pets_dataset/annotations/trimaps…</code></pre>
</div>
</div>
<p>Jak wygląda jedno z tych wejść i jego maska? Najpierw zdefiniujemy funkcję pomocniczą, która wykreśli tensor TensorFlow zawierający obraz przy użyciu funkcji <code><a href="https://rdrr.io/r/graphics/plot.default.html">plot()</a></code> programu R:</p>
<div class="cell">
<details open="" class="code-fold"><summary>Kod</summary><div class="sourceCode" id="cb5"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">display_image_tensor</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">x</span>, <span class="va">...</span>, <span class="va">max</span> <span class="op">=</span> <span class="fl">255</span>,</span>
<span>                                 <span class="va">plot_margins</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">0</span>, <span class="fl">0</span>, <span class="fl">0</span><span class="op">)</span><span class="op">)</span> <span class="op">{</span>   </span>
<span>  <span class="kw">if</span><span class="op">(</span><span class="op">!</span><span class="fu"><a href="https://rdrr.io/r/base/NULL.html">is.null</a></span><span class="op">(</span><span class="va">plot_margins</span><span class="op">)</span><span class="op">)</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/r/graphics/par.html">par</a></span><span class="op">(</span>mar <span class="op">=</span> <span class="va">plot_margins</span><span class="op">)</span></span>
<span> </span>
<span>  <span class="va">x</span> <span class="op">|&gt;</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/r/base/array.html">as.array</a></span><span class="op">(</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/r/base/drop.html">drop</a></span><span class="op">(</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/r/grDevices/as.raster.html">as.raster</a></span><span class="op">(</span>max <span class="op">=</span> <span class="va">max</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="va">...</span>, interpolate <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span></span>
<span><span class="op">}</span></span></code><button title="Kopiuj do schowka" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>W wywołaniu <code><a href="https://rdrr.io/r/grDevices/as.raster.html">as.raster()</a></code> ustawiamy <code>max = 255</code>, ponieważ podobnie jak w przypadku MNIST, obrazy są zakodowane jako <code>uint8</code>.</p>
<div class="cell">
<details open="" class="code-fold"><summary>Kod</summary><div class="sourceCode" id="cb6"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://github.com/rstudio/tensorflow">tensorflow</a></span><span class="op">)</span></span>
<span><span class="va">image_tensor</span> <span class="op">&lt;-</span> <span class="va">image_paths</span><span class="op">$</span><span class="va">input</span><span class="op">[</span><span class="fl">10</span><span class="op">]</span> <span class="op">|&gt;</span> </span>
<span>   <span class="va">tf</span><span class="op">$</span><span class="va">io</span><span class="op">$</span><span class="fu">read_file</span><span class="op">(</span><span class="op">)</span> <span class="op">|&gt;</span> </span>
<span>   <span class="va">tf</span><span class="op">$</span><span class="va">io</span><span class="op">$</span><span class="fu">decode_jpeg</span><span class="op">(</span><span class="op">)</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/str.html">str</a></span><span class="op">(</span><span class="va">image_tensor</span><span class="op">)</span></span></code><button title="Kopiuj do schowka" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>&lt;tf.Tensor: shape=(448, 500, 3), dtype=uint8, numpy=…&gt;</code></pre>
</div>
<details open="" class="code-fold"><summary>Kod</summary><div class="sourceCode" id="cb8"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu">display_image_tensor</span><span class="op">(</span><span class="va">image_tensor</span><span class="op">)</span></span></code><button title="Kopiuj do schowka" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output-display">
<div id="fig-seg3" class="quarto-figure quarto-figure-center quarto-float anchored">
<figure class="quarto-float quarto-float-fig figure"><div aria-describedby="fig-seg3-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="segmentation_files/figure-html/fig-seg3-1.png" class="img-fluid figure-img" width="672">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-seg3-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Rysunek&nbsp;14.3: Przykładowy obraz z bazy
</figcaption></figure>
</div>
</div>
</div>
<p>Zdefiniujemy również funkcję do wyświetlania obrazu docelowego. Obraz docelowy jest również odczytywany jako <code>uint8</code>, ale tym razem w tensorze obrazu docelowego znajdują się tylko wartości (1, 2, 3). Aby go wykreślić, odejmujemy 1, aby etykiety miały zakres od 0 do 2, a następnie ustawiamy <code>max = 2</code>, aby etykiety miały wartości 0 (czarny), 1 (szary) i 2 (biały).</p>
<div class="cell">
<details open="" class="code-fold"><summary>Kod</summary><div class="sourceCode" id="cb9"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">display_target_tensor</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">target</span><span class="op">)</span> <span class="fu">display_image_tensor</span><span class="op">(</span><span class="va">target</span> <span class="op">-</span> <span class="fl">1</span>, max <span class="op">=</span> <span class="fl">2</span><span class="op">)</span>   </span>
<span></span>
<span><span class="va">target</span> <span class="op">&lt;-</span> <span class="va">image_paths</span><span class="op">$</span><span class="va">target</span><span class="op">[</span><span class="fl">10</span><span class="op">]</span> <span class="op">|&gt;</span> </span>
<span>   <span class="va">tf</span><span class="op">$</span><span class="va">io</span><span class="op">$</span><span class="fu">read_file</span><span class="op">(</span><span class="op">)</span> <span class="op">|&gt;</span> </span>
<span>   <span class="va">tf</span><span class="op">$</span><span class="va">io</span><span class="op">$</span><span class="fu">decode_png</span><span class="op">(</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/str.html">str</a></span><span class="op">(</span><span class="va">target</span><span class="op">)</span></span></code><button title="Kopiuj do schowka" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>&lt;tf.Tensor: shape=(448, 500, 1), dtype=uint8, numpy=…&gt;</code></pre>
</div>
<details open="" class="code-fold"><summary>Kod</summary><div class="sourceCode" id="cb11"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu">display_target_tensor</span><span class="op">(</span><span class="va">target</span><span class="op">)</span></span></code><button title="Kopiuj do schowka" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output-display">
<div id="fig-seg4" class="quarto-figure quarto-figure-center quarto-float anchored">
<figure class="quarto-float quarto-float-fig figure"><div aria-describedby="fig-seg4-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="segmentation_files/figure-html/fig-seg4-1.png" class="img-fluid figure-img" width="672">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-seg4-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Rysunek&nbsp;14.4: Przykładowa maska
</figcaption></figure>
</div>
</div>
</div>
<p>Następnie załadujmy nasze wejścia i cele do dwóch TF Datasets i podzielmy pliki na zestawy treningowe i walidacyjne. Ponieważ zbiór danych jest bardzo mały, możemy po prostu załadować wszystko do pamięci:</p>
<div class="cell">
<details open="" class="code-fold"><summary>Kod</summary><div class="sourceCode" id="cb12"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://github.com/rstudio/tfdatasets">tfdatasets</a></span><span class="op">)</span></span>
<span><span class="va">tf_read_image</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">path</span>, <span class="va">format</span> <span class="op">=</span> <span class="st">"image"</span>, <span class="va">resize</span> <span class="op">=</span> <span class="cn">NULL</span>, <span class="va">...</span><span class="op">)</span> <span class="op">{</span></span>
<span></span>
<span>  <span class="va">img</span> <span class="op">&lt;-</span> <span class="va">path</span> <span class="op">|&gt;</span> </span>
<span>    <span class="va">tf</span><span class="op">$</span><span class="va">io</span><span class="op">$</span><span class="fu">read_file</span><span class="op">(</span><span class="op">)</span>  <span class="op">|&gt;</span> </span>
<span>    <span class="va">tf</span><span class="op">$</span><span class="va">io</span><span class="op">[[</span><span class="fu"><a href="https://rdrr.io/r/base/paste.html">paste0</a></span><span class="op">(</span><span class="st">"decode_"</span>, <span class="va">format</span><span class="op">)</span><span class="op">]</span><span class="op">]</span><span class="op">(</span><span class="va">...</span><span class="op">)</span></span>
<span></span>
<span>  <span class="kw">if</span> <span class="op">(</span><span class="op">!</span><span class="fu"><a href="https://rdrr.io/r/base/NULL.html">is.null</a></span><span class="op">(</span><span class="va">resize</span><span class="op">)</span><span class="op">)</span> <span class="op">{</span></span>
<span>    <span class="va">img</span> <span class="op">&lt;-</span> <span class="va">img</span> <span class="op">|&gt;</span> </span>
<span>      <span class="va">tf</span><span class="op">$</span><span class="va">image</span><span class="op">$</span><span class="fu">resize</span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/integer.html">as.integer</a></span><span class="op">(</span><span class="va">resize</span><span class="op">)</span><span class="op">)</span></span>
<span>  <span class="op">}</span></span>
<span>  <span class="va">img</span></span>
<span><span class="op">}</span></span>
<span></span>
<span><span class="va">img_size</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">200</span>, <span class="fl">200</span><span class="op">)</span></span>
<span></span>
<span><span class="va">tf_read_image_and_resize</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">...</span>, <span class="va">resize</span> <span class="op">=</span> <span class="va">img_size</span><span class="op">)</span> <span class="op">{</span></span>
<span>  <span class="fu">tf_read_image</span><span class="op">(</span><span class="va">...</span>, resize <span class="op">=</span> <span class="va">resize</span><span class="op">)</span></span>
<span><span class="op">}</span></span>
<span></span>
<span><span class="va">make_dataset</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">paths_df</span><span class="op">)</span> <span class="op">{</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/pkg/tfdatasets/man/tensor_slices_dataset.html">tensor_slices_dataset</a></span><span class="op">(</span><span class="va">paths_df</span><span class="op">)</span> <span class="op">|&gt;</span> </span>
<span>    <span class="fu"><a href="https://rdrr.io/pkg/tfdatasets/man/dataset_map.html">dataset_map</a></span><span class="op">(</span><span class="kw">function</span><span class="op">(</span><span class="va">path</span><span class="op">)</span> <span class="op">{</span></span>
<span>      <span class="va">image</span> <span class="op">&lt;-</span> <span class="va">path</span><span class="op">$</span><span class="va">input</span> <span class="op">|&gt;</span> </span>
<span>        <span class="fu">tf_read_image_and_resize</span><span class="op">(</span><span class="st">"jpeg"</span>, channels <span class="op">=</span> <span class="fl">3L</span><span class="op">)</span></span>
<span>      <span class="va">target</span> <span class="op">&lt;-</span> <span class="va">path</span><span class="op">$</span><span class="va">target</span> <span class="op">|&gt;</span> </span>
<span>        <span class="fu">tf_read_image_and_resize</span><span class="op">(</span><span class="st">"png"</span>, channels <span class="op">=</span> <span class="fl">1L</span><span class="op">)</span></span>
<span>      <span class="va">target</span> <span class="op">&lt;-</span> <span class="va">target</span> <span class="op">-</span> <span class="fl">1</span></span>
<span>      <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span><span class="va">image</span>, <span class="va">target</span><span class="op">)</span></span>
<span>    <span class="op">}</span><span class="op">)</span> <span class="op">|&gt;</span> </span>
<span>    <span class="fu"><a href="https://rdrr.io/pkg/tfdatasets/man/dataset_cache.html">dataset_cache</a></span><span class="op">(</span><span class="op">)</span> <span class="op">|&gt;</span> </span>
<span>    <span class="fu"><a href="https://rdrr.io/pkg/tfdatasets/man/dataset_shuffle.html">dataset_shuffle</a></span><span class="op">(</span>buffer_size <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/nrow.html">nrow</a></span><span class="op">(</span><span class="va">paths_df</span><span class="op">)</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/pkg/tfdatasets/man/dataset_batch.html">dataset_batch</a></span><span class="op">(</span><span class="fl">32</span><span class="op">)</span></span>
<span><span class="op">}</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span><span class="op">(</span><span class="fl">44</span><span class="op">)</span></span>
<span><span class="va">num_val_samples</span> <span class="op">&lt;-</span> <span class="fl">1000</span></span>
<span><span class="va">val_idx</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/sample.html">sample.int</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/nrow.html">nrow</a></span><span class="op">(</span><span class="va">image_paths</span><span class="op">)</span>, <span class="va">num_val_samples</span><span class="op">)</span></span>
<span></span>
<span><span class="va">val_paths</span> <span class="op">&lt;-</span> <span class="va">image_paths</span><span class="op">[</span><span class="va">val_idx</span>, <span class="op">]</span></span>
<span><span class="va">train_paths</span> <span class="op">&lt;-</span> <span class="va">image_paths</span><span class="op">[</span><span class="op">-</span><span class="va">val_idx</span>, <span class="op">]</span></span>
<span></span>
<span><span class="va">validation_dataset</span> <span class="op">&lt;-</span> <span class="fu">make_dataset</span><span class="op">(</span><span class="va">val_paths</span><span class="op">)</span></span>
<span><span class="va">train_dataset</span> <span class="op">&lt;-</span> <span class="fu">make_dataset</span><span class="op">(</span><span class="va">train_paths</span><span class="op">)</span></span></code><button title="Kopiuj do schowka" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>Teraz zdefiniujemy model:</p>
<div class="cell">
<details open="" class="code-fold"><summary>Kod</summary><div class="sourceCode" id="cb13"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://tensorflow.rstudio.com/">keras</a></span><span class="op">)</span></span>
<span><span class="va">get_model</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">img_size</span>, <span class="va">num_classes</span><span class="op">)</span> <span class="op">{</span></span>
<span>  <span class="va">conv</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">...</span>, <span class="va">padding</span> <span class="op">=</span> <span class="st">"same"</span>, <span class="va">activation</span> <span class="op">=</span> <span class="st">"relu"</span><span class="op">)</span> <span class="op">{</span> </span>
<span>    <span class="fu"><a href="https://rdrr.io/pkg/keras/man/layer_conv_2d.html">layer_conv_2d</a></span><span class="op">(</span><span class="va">...</span>, padding <span class="op">=</span> <span class="va">padding</span>, activation <span class="op">=</span> <span class="va">activation</span><span class="op">)</span></span>
<span>  <span class="op">}</span></span>
<span></span>
<span>  <span class="va">conv_transpose</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">...</span>, <span class="va">padding</span> <span class="op">=</span> <span class="st">"same"</span>, <span class="va">activation</span> <span class="op">=</span> <span class="st">"relu"</span><span class="op">)</span> <span class="op">{</span> </span>
<span>    <span class="fu"><a href="https://rdrr.io/pkg/keras/man/layer_conv_2d_transpose.html">layer_conv_2d_transpose</a></span><span class="op">(</span><span class="va">...</span>, padding <span class="op">=</span> <span class="va">padding</span>, activation <span class="op">=</span> <span class="va">activation</span><span class="op">)</span></span>
<span>  <span class="op">}</span></span>
<span></span>
<span>  <span class="va">input</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/keras/man/layer_input.html">layer_input</a></span><span class="op">(</span>shape <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="va">img_size</span>, <span class="fl">3</span><span class="op">)</span><span class="op">)</span></span>
<span>  <span class="va">output</span> <span class="op">&lt;-</span> <span class="va">input</span> <span class="op">|&gt;</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/pkg/keras/man/layer_rescaling.html">layer_rescaling</a></span><span class="op">(</span>scale <span class="op">=</span> <span class="fl">1</span> <span class="op">/</span> <span class="fl">255</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>    <span class="fu">conv</span><span class="op">(</span><span class="fl">64</span>, <span class="fl">3</span>, strides <span class="op">=</span> <span class="fl">2</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>    <span class="fu">conv</span><span class="op">(</span><span class="fl">64</span>, <span class="fl">3</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>    <span class="fu">conv</span><span class="op">(</span><span class="fl">128</span>, <span class="fl">3</span>, strides <span class="op">=</span> <span class="fl">2</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>    <span class="fu">conv</span><span class="op">(</span><span class="fl">128</span>, <span class="fl">3</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>    <span class="fu">conv</span><span class="op">(</span><span class="fl">256</span>, <span class="fl">3</span>, strides <span class="op">=</span> <span class="fl">2</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>    <span class="fu">conv</span><span class="op">(</span><span class="fl">256</span>, <span class="fl">3</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>    <span class="fu">conv_transpose</span><span class="op">(</span><span class="fl">256</span>, <span class="fl">3</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>    <span class="fu">conv_transpose</span><span class="op">(</span><span class="fl">256</span>, <span class="fl">3</span>, strides <span class="op">=</span> <span class="fl">2</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>    <span class="fu">conv_transpose</span><span class="op">(</span><span class="fl">128</span>, <span class="fl">3</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>    <span class="fu">conv_transpose</span><span class="op">(</span><span class="fl">128</span>, <span class="fl">3</span>, strides <span class="op">=</span> <span class="fl">2</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>    <span class="fu">conv_transpose</span><span class="op">(</span><span class="fl">64</span>, <span class="fl">3</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>    <span class="fu">conv_transpose</span><span class="op">(</span><span class="fl">64</span>, <span class="fl">3</span>, strides <span class="op">=</span> <span class="fl">2</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>    <span class="fu">conv</span><span class="op">(</span><span class="va">num_classes</span>, <span class="fl">3</span>, activation <span class="op">=</span> <span class="st">"softmax"</span><span class="op">)</span></span>
<span></span>
<span>  <span class="fu"><a href="https://rdrr.io/pkg/keras/man/keras_model.html">keras_model</a></span><span class="op">(</span><span class="va">input</span>, <span class="va">output</span><span class="op">)</span></span>
<span><span class="op">}</span></span>
<span></span>
<span><span class="va">model</span> <span class="op">&lt;-</span> <span class="fu">get_model</span><span class="op">(</span>img_size <span class="op">=</span> <span class="va">img_size</span>, num_classes <span class="op">=</span> <span class="fl">3</span><span class="op">)</span></span>
<span><span class="va">model</span></span></code><button title="Kopiuj do schowka" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>Model: "model"
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 input_1 (InputLayer)               [(None, 200, 200, 3)]           0           
 rescaling (Rescaling)              (None, 200, 200, 3)             0           
 conv2d_6 (Conv2D)                  (None, 100, 100, 64)            1792        
 conv2d_5 (Conv2D)                  (None, 100, 100, 64)            36928       
 conv2d_4 (Conv2D)                  (None, 50, 50, 128)             73856       
 conv2d_3 (Conv2D)                  (None, 50, 50, 128)             147584      
 conv2d_2 (Conv2D)                  (None, 25, 25, 256)             295168      
 conv2d_1 (Conv2D)                  (None, 25, 25, 256)             590080      
 conv2d_transpose_5 (Conv2DTranspo  (None, 25, 25, 256)             590080      
 se)                                                                            
 conv2d_transpose_4 (Conv2DTranspo  (None, 50, 50, 256)             590080      
 se)                                                                            
 conv2d_transpose_3 (Conv2DTranspo  (None, 50, 50, 128)             295040      
 se)                                                                            
 conv2d_transpose_2 (Conv2DTranspo  (None, 100, 100, 128)           147584      
 se)                                                                            
 conv2d_transpose_1 (Conv2DTranspo  (None, 100, 100, 64)            73792       
 se)                                                                            
 conv2d_transpose (Conv2DTranspose  (None, 200, 200, 64)            36928       
 )                                                                              
 conv2d (Conv2D)                    (None, 200, 200, 3)             1731        
================================================================================
Total params: 2880643 (10.99 MB)
Trainable params: 2880643 (10.99 MB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________</code></pre>
</div>
</div>
<p>Pierwsza połowa modelu bardzo przypomina sieć splotową używaną do klasyfikacji obrazów: stos warstw <code>Conv2D</code> ze stopniowo zwiększającymi się rozmiarami filtrów. Obniżamy próbkowanie naszych obrazów dwukrotnie aż trzy razy, kończąc na aktywacjach o rozmiarze <code>(25, 25, 256)</code>. Celem tej pierwszej połowy jest zakodowanie obrazów w mniejsze mapy cech, gdzie każde miejsce przestrzenne (lub piksel) zawiera informację o dużym przestrzennym kawałku oryginalnego obrazu. Można to rozumieć jako rodzaj kompresji.</p>
<p>Jedną z ważnych różnic pomiędzy pierwszą połową tego modelu a modelami klasyfikacyjnymi, które widziałeś wcześniej, jest sposób, w jaki dokonujemy <em>downsamplingu</em>: w sieciach splotowych klasyfikacyjnych z wcześniejszego rozdziału używaliśmy warstw <code>MaxPooling2D</code> do <em>downsamplingu</em> map cech. W tym przypadku <em>downsamplingu</em> dokonujemy poprzez dodanie <em>strides</em> do każdej kolejnej warstwy konwolucji. Robimy to, ponieważ w przypadku segmentacji obrazu bardzo zależy nam na przestrzennej lokalizacji informacji w obrazie, ponieważ musimy wyprodukować docelowe maski pikselowe jako wyjście modelu. Kiedy wykonujemy <em>max pooling</em> 2 × 2, całkowicie niszczymy informacje o lokalizacji w każdym oknie <em>poolingu</em>: zwracamy jedną wartość na okno, z zerową wiedzą o tym, z której z czterech lokalizacji pochodzi ta wartość. Tak więc, mimo że warstwy <em>max pooling</em> dobrze sprawdzają się w zadaniach klasyfikacji, to w przypadku zadania segmentacji nie są tak skuteczne. W międzyczasie, konwolucje paskowe (<em>strides</em>) lepiej radzą sobie z <em>downsamplingiem</em> map cech, zachowując jednocześnie informacje o lokalizacji.</p>
<div class="quarto-figure quarto-figure-center page-columns page-full">
<figure class="figure page-columns page-full"><div class="page-columns page-full"><p></p><div class="no-row-height column-margin column-container"><img src="https://media.giphy.com/media/glmRyiSI3v5E4/giphy-downsized-large.gif" class="img-fluid quarto-figure quarto-figure-center figure-img" width="400"></div></div>
</figure>
</div>
<p>Druga połowa modelu to stos warstw <code>Conv2DTranspose</code>. Co to jest? Cóż, wyjściem pierwszej połowy modelu jest mapa cech o kształcie <code>(25, 25, 256)</code>, ale chcemy, aby nasze ostateczne wyjście miało taki sam kształt jak maski docelowe, <code>(200, 200, 3).</code> W związku z tym musimy zastosować coś w rodzaju odwrotności dotychczasowych przekształceń - coś, co spowoduje zwiększenie próbkowania map funkcji zamiast ich zmniejszenia. Jest to cel warstwy <code>Conv2DTranspose</code>: można o niej myśleć jak o warstwie konwolucji, która uczy się zwiększać próbkowanie. Jeśli mamy wejście o kształcie <code>(100, 100, 64)</code> i przepuścimy je przez warstwę <code>layer_conv_2d(128, 3, strides = 2, padding = "same")</code>, otrzymamy wyjście o kształcie <code>(50, 50, 128)</code>. Jeśli przepuścimy to wyjście przez warstwę <code>layer_conv_2d_transpose(64, 3, strides = 2, padding = "same")</code>, otrzymamy z powrotem wyjście o kształcie <code>(100, 100, 64)</code>, takie samo jak oryginał. Tak więc po skompresowaniu naszych danych wejściowych do map funkcji o kształcie <code>(25, 25, 256)</code> poprzez stos warstw <code>Conv2D</code>, możemy po prostu zastosować odpowiednią sekwencję warstw <code>Conv2DTranspose</code>, aby uzyskać z powrotem obrazy o kształcie <code>(200, 200, 3)</code>.</p>
<p>Możemy teraz skompilować i dopasować nasz model:</p>
<div class="cell">
<details open="" class="code-fold"><summary>Kod</summary><div class="sourceCode" id="cb15"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">model</span> <span class="op">|&gt;</span></span>
<span> <span class="fu"><a href="https://generics.r-lib.org/reference/compile.html">compile</a></span><span class="op">(</span>optimizer <span class="op">=</span> <span class="st">"rmsprop"</span>,</span>
<span>         loss <span class="op">=</span> <span class="st">"sparse_categorical_crossentropy"</span><span class="op">)</span>   </span>
<span></span>
<span><span class="va">callbacks</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span></span>
<span> <span class="fu"><a href="https://rdrr.io/pkg/keras/man/callback_model_checkpoint.html">callback_model_checkpoint</a></span><span class="op">(</span><span class="st">"models/oxford_segmentation.keras"</span>,</span>
<span>                             save_best_only <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="va">history</span> <span class="op">&lt;-</span> <span class="va">model</span> <span class="op">|&gt;</span> <span class="fu"><a href="https://generics.r-lib.org/reference/fit.html">fit</a></span><span class="op">(</span></span>
<span> <span class="va">train_dataset</span>,</span>
<span> epochs <span class="op">=</span> <span class="fl">50</span>,</span>
<span> callbacks <span class="op">=</span> <span class="va">callbacks</span>,</span>
<span> validation_data <span class="op">=</span> <span class="va">validation_dataset</span></span>
<span><span class="op">)</span></span></code><button title="Kopiuj do schowka" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>Podczas treningu możesz zobaczyć ostrzeżenie takie jak <code>Corrupt JPEG data: premature end of data segment</code>. To dlatego, że zbiór danych nie jest perfekcyjnie przygotowany.</p>
<div class="cell">
<details open="" class="code-fold"><summary>Kod</summary><div class="sourceCode" id="cb16"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">model</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/keras/man/save_model_tf.html">load_model_tf</a></span><span class="op">(</span><span class="st">"models/oxford_segmentation.keras"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/load.html">load</a></span><span class="op">(</span><span class="st">"models/oxford_seg_hist.rda"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="va">history</span><span class="op">)</span></span></code><button title="Kopiuj do schowka" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output-display">
<div>
<figure class="figure"><p><img src="segmentation_files/figure-html/unnamed-chunk-10-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<p>Widać, że w połowie drogi, około epoki 25, model zaczyna się nadmiernie dopasowywać.</p>
<div class="cell">
<details open="" class="code-fold"><summary>Kod</summary><div class="sourceCode" id="cb17"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">test_image</span> <span class="op">&lt;-</span> <span class="va">val_paths</span><span class="op">$</span><span class="va">input</span><span class="op">[</span><span class="fl">4</span><span class="op">]</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu">tf_read_image_and_resize</span><span class="op">(</span><span class="st">"jpeg"</span>, channels <span class="op">=</span> <span class="fl">3L</span><span class="op">)</span></span>
<span></span>
<span><span class="va">predicted_mask_probs</span> <span class="op">&lt;-</span> </span>
<span>  <span class="fu">model</span><span class="op">(</span><span class="va">test_image</span><span class="op">[</span><span class="va">tf</span><span class="op">$</span><span class="va">newaxis</span>, , , <span class="op">]</span><span class="op">)</span></span>
<span></span>
<span><span class="va">predicted_mask</span> <span class="op">&lt;-</span> </span>
<span>  <span class="va">tf</span><span class="op">$</span><span class="fu">argmax</span><span class="op">(</span><span class="va">predicted_mask_probs</span>, axis <span class="op">=</span> <span class="op">-</span><span class="fl">1L</span><span class="op">)</span></span>
<span></span>
<span><span class="va">predicted_target</span> <span class="op">&lt;-</span> <span class="va">predicted_mask</span> <span class="op">+</span> <span class="fl">1</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/par.html">par</a></span><span class="op">(</span>mfrow <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">1</span>, <span class="fl">2</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="fu">display_image_tensor</span><span class="op">(</span><span class="va">test_image</span><span class="op">)</span></span>
<span><span class="fu">display_target_tensor</span><span class="op">(</span><span class="va">predicted_target</span><span class="op">)</span></span></code><button title="Kopiuj do schowka" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output-display">
<div id="fig-seg5" class="quarto-figure quarto-figure-center quarto-float anchored">
<figure class="quarto-float quarto-float-fig figure"><div aria-describedby="fig-seg5-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="segmentation_files/figure-html/fig-seg5-1.png" class="img-fluid figure-img" width="672">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-seg5-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Rysunek&nbsp;14.5: Obraz testowy i jego przewidywana maska segmentacyjna
</figcaption></figure>
</div>
</div>
</div>
<p>Jest kilka małych artefaktów w naszej przewidywanej masce. Niemniej jednak nasz model wydaje się działać poprawnie.</p>
<section id="nowoczesne-architektury-sieci-splotowych" class="level2 page-columns page-full" data-number="14.1"><h2 data-number="14.1" class="anchored" data-anchor-id="nowoczesne-architektury-sieci-splotowych">
<span class="header-section-number">14.1</span> Nowoczesne architektury sieci splotowych</h2>
<p>Architektura modelu jest sumą wyborów, które zostały dokonane przy jego tworzeniu: jakich warstw użyć, jak je skonfigurować i w jakim układzie je połączyć. Te wybory definiują przestrzeń hipotez twojego modelu: przestrzeń możliwych funkcji, które mogą być przeszukiwane przez spadek gradientu, parametryzowane przez wagi modelu. Podobnie jak w przypadku inżynierii cech, dobra przestrzeń hipotez koduje wcześniejszą wiedzę, którą posiadamy na temat danego problemu i jego rozwiązania. Na przykład, użycie warstw konwolucji oznacza, że z góry wiemy, że istotne wzory obecne na obrazach wejściowych są niezmienne względem translacji. Aby skutecznie uczyć się z danych, musimy przyjąć założenia dotyczące tego, czego szukamy.</p>
<p>Jeśli dokonamy niewłaściwego wyboru architektury, nasz model może utknąć z nieoptymalnymi metrykami i żadna ilość danych treningowych go nie uratuje. I odwrotnie, dobra architektura modelu przyspieszy uczenie i umożliwi efektywne wykorzystanie dostępnych danych treningowych, zmniejszając zapotrzebowanie na duże zbiory danych. Dobra architektura modelu to taka, która zmniejsza rozmiar przestrzeni wyszukiwania lub w inny sposób ułatwia konwergencję do dobrego punktu przestrzeni wyszukiwania. Podobnie jak w przypadku inżynierii cech, architektura modelu polega na uproszczeniu problemu do rozwiązania przez spadek gradientu.</p>
<div class="quarto-figure quarto-figure-center page-columns page-full">
<figure class="figure page-columns page-full"><div class="page-columns page-full"><p></p><div class="no-row-height column-margin column-container"><img src="https://media.giphy.com/media/Fkmgse8OMKn9C/giphy.gif" class="img-fluid quarto-figure quarto-figure-center figure-img"></div></div>
</figure>
</div>
<p>Architektura modelu jest bardziej sztuką niż nauką. Doświadczeni inżynierowie uczenia maszynowego są w stanie intuicyjnie poskładać wydajne modele przy pierwszej próbie, podczas gdy początkujący często mają problemy ze stworzeniem modelu, który w ogóle się uczy. Kluczowym słowem jest tu intuicja: nikt nie jest w stanie podać jasnego wyjaśnienia, co działa, a co nie. Eksperci polegają na kojarzeniu wzorców, umiejętności, którą nabywają poprzez bogate doświadczenie praktyczne.</p>
<p>W dalszej części omówimy kilka podstawowych praktyk architektury sieci konwolucyjnych: w szczególności połączenia resztkowe (ang. <em>residual connection</em>), normalizację partii (ang. <em>batch normalization</em>) i konwolucje separowalne (ang. <em>separable convolutions</em>).</p>
<p>Większość sieci splotowych często charakteryzuje się strukturami przypominającymi piramidy (hierarchie cech). Przypomnij sobie na przykład progresję w liczbie filtrów konwolucyjnych, których użyliśmy w pierwszej sieci splotowej: 32, 64, 128. Liczba filtrów rośnie wraz z głębokością warstw, podczas gdy rozmiar map cech odpowiednio się kurczy. Ten sam wzór zauważymy w blokach modelu VGG16 (patrz <a href="#fig-seg6" class="quarto-xref">Rysunek&nbsp;<span>14.6</span></a>).</p>
<div id="fig-seg6" class="quarto-figure quarto-figure-center quarto-float anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure"><div aria-describedby="fig-seg6-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="images/Zrzut ekranu 2023-03-18 o 14.10.24.png" class="img-fluid quarto-figure quarto-figure-center figure-img" width="600">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-seg6-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Rysunek&nbsp;14.6: Architektura sieci VGG16
</figcaption></figure>
</div>
<p>Ogólnie rzecz biorąc, głęboki stos wąskich warstw działa lepiej niż płytki stos dużych warstw. Istnieje jednak pewne ograniczenie, jak głęboko można układać warstwy, a wiąże się z problem znikających gradientów. To prowadzi nas do naszego pierwszego istotnego wzorca architektury modelu: połączeń resztkowych.</p>
<section id="połączenia-rezydualne" class="level3 page-columns page-full" data-number="14.1.1"><h3 data-number="14.1.1" class="anchored" data-anchor-id="połączenia-rezydualne">
<span class="header-section-number">14.1.1</span> Połączenia rezydualne</h3>
<p>Wsteczna propagacja używania do uczenia modeli głębokich przypomina grę w “głuchy telefon”, gdzie kolejne osoby szepczą sobie do ucha przekazując pewną - wymyśloną przez pierwszego gracza - informację. Po kilku przejściach informacja ta jest znacznie zniekształcona. Podobnie jest w uczeniu sieci, gdzie propagacją błędów wstecz powoduje wprowadzenie pewnych błędów w kolejnych warstwach sieci. Każda kolejna funkcja w łańcuchu wprowadza pewną ilość szumu. Jeśli łańcuch funkcji jest zbyt głęboki, szum ten zaczyna przytłaczać informacje o gradiencie i wsteczna propagacja przestaje działać. Jest to problem znikających gradientów.</p>
<p>Rozwiązanie jest proste: wystarczy wymusić, aby każda funkcja w łańcuchu była nieniszcząca - zachowywała “czystą” wersję informacji zawartej w poprzednim wejściu. Najłatwiejszym sposobem wdrożenia tego jest użycie połączenia rezydualnego.</p>
<div class="quarto-figure quarto-figure-center page-columns page-full">
<figure class="figure page-columns page-full"><div class="page-columns page-full"><p></p><div class="no-row-height column-margin column-container"><img src="https://media.giphy.com/media/OYnjptyYk6Lny/giphy.gif" class="img-fluid quarto-figure quarto-figure-center figure-img"></div></div>
</figure>
</div>
<p>Jest to bardzo proste: wystarczy dodać wejście warstwy lub bloku warstw z powrotem do jej wyjścia (patrz <a href="#fig-seg7" class="quarto-xref">Rysunek&nbsp;<span>14.7</span></a>). Połączenie rezydualne działa jak skrót informacyjny wokół destrukcyjnych lub zaszumiających bloków (takich jak bloki zawierające aktywacje <code>relu</code> lub warstwy <code>dropout</code>), przekazując informację o gradiencie błędu z wczesnych warstw, tak aby propagować przez głęboką sieć. Technika ta została wprowadzona w 2015 roku wraz z rodziną modeli <em>ResNet</em> (opracowanych przez <span class="citation" data-cites="heDeepResidualLearning2015">He i in. (<a href="references.html#ref-heDeepResidualLearning2015" role="doc-biblioref">2015</a>)</span>).</p>
<div id="fig-seg7" class="quarto-figure quarto-figure-center quarto-float anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure"><div aria-describedby="fig-seg7-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="images/Zrzut ekranu 2023-03-18 o 14.23.47.png" class="img-fluid quarto-figure quarto-figure-center figure-img" width="600">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-seg7-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Rysunek&nbsp;14.7: Połączenie rezydualne
</figcaption></figure>
</div>
<p>Zauważmy, że dodanie wejścia z powrotem do wyjścia bloku sugeruje, że wyjście powinno mieć taki sam kształt jak wejście. Jednak tak nie jest, jeśli nasz blok zawiera warstwy konwolucyjne ze zwiększoną liczbą filtrów lub warstwę <em>max-pooling</em>. W takich przypadkach używamy warstwy 1x1 <code><a href="https://rdrr.io/pkg/keras/man/layer_conv_2d.html">layer_conv_2d()</a></code> bez aktywacji, aby liniowo rzutować resztę na pożądany kształt wyjścia. Zazwyczaj używamy <code>paddingu = "same"</code> w warstwach konwolucji w bloku docelowym, aby uniknąć przestrzennego <em>downsamplingu</em> spowodowanego <em>paddingiem</em>, a w projekcji resztkowej używamy <em>strides</em>.</p>
<div class="cell">
<details open="" class="code-fold"><summary>Kod</summary><div class="sourceCode" id="cb18"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># klasyczne podejście</span></span>
<span><span class="va">inputs</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/keras/man/layer_input.html">layer_input</a></span><span class="op">(</span>shape <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">32</span>, <span class="fl">32</span>, <span class="fl">3</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">x</span> <span class="op">&lt;-</span> <span class="va">inputs</span> <span class="op">|&gt;</span> <span class="fu"><a href="https://rdrr.io/pkg/keras/man/layer_conv_2d.html">layer_conv_2d</a></span><span class="op">(</span><span class="fl">32</span>, <span class="fl">3</span>, activation <span class="op">=</span> <span class="st">"relu"</span><span class="op">)</span></span>
<span><span class="va">residual</span> <span class="op">&lt;-</span> <span class="va">x</span></span>
<span><span class="va">x</span> <span class="op">&lt;-</span> <span class="va">x</span> <span class="op">|&gt;</span> <span class="fu"><a href="https://rdrr.io/pkg/keras/man/layer_conv_2d.html">layer_conv_2d</a></span><span class="op">(</span><span class="fl">64</span>, <span class="fl">3</span>, activation <span class="op">=</span> <span class="st">"relu"</span>, padding <span class="op">=</span> <span class="st">"same"</span><span class="op">)</span></span>
<span><span class="va">residual</span> <span class="op">&lt;-</span> <span class="va">residual</span> <span class="op">|&gt;</span> <span class="fu"><a href="https://rdrr.io/pkg/keras/man/layer_conv_2d.html">layer_conv_2d</a></span><span class="op">(</span><span class="fl">64</span>, <span class="fl">1</span><span class="op">)</span></span>
<span><span class="va">x</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/keras/man/layer_add.html">layer_add</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="va">x</span>, <span class="va">residual</span><span class="op">)</span><span class="op">)</span></span></code><button title="Kopiuj do schowka" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div class="cell">
<details open="" class="code-fold"><summary>Kod</summary><div class="sourceCode" id="cb19"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># podejście wykorzystujące stride</span></span>
<span><span class="va">inputs</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/keras/man/layer_input.html">layer_input</a></span><span class="op">(</span>shape <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">32</span>, <span class="fl">32</span>, <span class="fl">3</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">x</span> <span class="op">&lt;-</span> <span class="va">inputs</span> <span class="op">|&gt;</span> <span class="fu"><a href="https://rdrr.io/pkg/keras/man/layer_conv_2d.html">layer_conv_2d</a></span><span class="op">(</span><span class="fl">32</span>, <span class="fl">3</span>, activation <span class="op">=</span> <span class="st">"relu"</span><span class="op">)</span></span>
<span><span class="va">residual</span> <span class="op">&lt;-</span> <span class="va">x</span></span>
<span><span class="va">x</span> <span class="op">&lt;-</span> <span class="va">x</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/pkg/keras/man/layer_conv_2d.html">layer_conv_2d</a></span><span class="op">(</span><span class="fl">64</span>, <span class="fl">3</span>, activation <span class="op">=</span> <span class="st">"relu"</span>, padding <span class="op">=</span> <span class="st">"same"</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/pkg/keras/man/layer_max_pooling_2d.html">layer_max_pooling_2d</a></span><span class="op">(</span><span class="fl">2</span>, padding <span class="op">=</span> <span class="st">"same"</span><span class="op">)</span></span>
<span><span class="va">residual</span> <span class="op">&lt;-</span> <span class="va">residual</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/pkg/keras/man/layer_conv_2d.html">layer_conv_2d</a></span><span class="op">(</span><span class="fl">64</span>, <span class="fl">1</span>, strides <span class="op">=</span> <span class="fl">2</span><span class="op">)</span></span>
<span><span class="va">x</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/keras/man/layer_add.html">layer_add</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span><span class="va">x</span>, <span class="va">residual</span><span class="op">)</span><span class="op">)</span></span></code><button title="Kopiuj do schowka" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>Aby uczynić te pomysły bardziej konkretnymi, oto przykład prostej sieci splotowej zorganizowanej w serię bloków, z których każdy składa się z dwóch warstw konwolucji i jednej opcjonalnej warstwy <em>max-pooling</em>, z połączeniem rezydualnym wokół każdego bloku:</p>
<div class="cell">
<details open="" class="code-fold"><summary>Kod</summary><div class="sourceCode" id="cb20"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">inputs</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/keras/man/layer_input.html">layer_input</a></span><span class="op">(</span>shape <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">32</span>, <span class="fl">32</span>, <span class="fl">3</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">x</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/keras/man/layer_rescaling.html">layer_rescaling</a></span><span class="op">(</span><span class="va">inputs</span>, scale <span class="op">=</span> <span class="fl">1</span><span class="op">/</span><span class="fl">255</span><span class="op">)</span></span>
<span></span>
<span><span class="va">residual_block</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">x</span>, <span class="va">filters</span>, </span>
<span>                           <span class="va">pooling</span> <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span> <span class="op">{</span></span>
<span>  <span class="va">residual</span> <span class="op">&lt;-</span> <span class="va">x</span></span>
<span>  <span class="va">x</span> <span class="op">&lt;-</span> <span class="va">x</span> <span class="op">|&gt;</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/pkg/keras/man/layer_conv_2d.html">layer_conv_2d</a></span><span class="op">(</span><span class="va">filters</span>, <span class="fl">3</span>, activation <span class="op">=</span> <span class="st">"relu"</span>, padding <span class="op">=</span> <span class="st">"same"</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/pkg/keras/man/layer_conv_2d.html">layer_conv_2d</a></span><span class="op">(</span><span class="va">filters</span>, <span class="fl">3</span>, activation <span class="op">=</span> <span class="st">"relu"</span>, padding <span class="op">=</span> <span class="st">"same"</span><span class="op">)</span></span>
<span></span>
<span>  <span class="kw">if</span> <span class="op">(</span><span class="va">pooling</span><span class="op">)</span> <span class="op">{</span></span>
<span>    <span class="va">x</span> <span class="op">&lt;-</span> <span class="va">x</span> <span class="op">|&gt;</span> <span class="fu"><a href="https://rdrr.io/pkg/keras/man/layer_max_pooling_2d.html">layer_max_pooling_2d</a></span><span class="op">(</span>pool_size <span class="op">=</span> <span class="fl">2</span>, padding <span class="op">=</span> <span class="st">"same"</span><span class="op">)</span></span>
<span>    <span class="va">residual</span> <span class="op">&lt;-</span> <span class="va">residual</span> <span class="op">|&gt;</span> <span class="fu"><a href="https://rdrr.io/pkg/keras/man/layer_conv_2d.html">layer_conv_2d</a></span><span class="op">(</span><span class="va">filters</span>, <span class="fl">1</span>, strides <span class="op">=</span> <span class="fl">2</span><span class="op">)</span></span>
<span>  <span class="op">}</span> <span class="kw">else</span> <span class="kw">if</span> <span class="op">(</span><span class="va">filters</span> <span class="op">!=</span> <span class="fu"><a href="https://rdrr.io/r/base/dim.html">dim</a></span><span class="op">(</span><span class="va">residual</span><span class="op">)</span><span class="op">[</span><span class="fl">4</span><span class="op">]</span><span class="op">)</span> <span class="op">{</span></span>
<span>    <span class="va">residual</span> <span class="op">&lt;-</span> <span class="va">residual</span> <span class="op">|&gt;</span> <span class="fu"><a href="https://rdrr.io/pkg/keras/man/layer_conv_2d.html">layer_conv_2d</a></span><span class="op">(</span><span class="va">filters</span>, <span class="fl">1</span><span class="op">)</span></span>
<span>  <span class="op">}</span></span>
<span></span>
<span>  <span class="fu"><a href="https://rdrr.io/pkg/keras/man/layer_add.html">layer_add</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span><span class="va">x</span>, <span class="va">residual</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="op">}</span></span>
<span></span>
<span><span class="va">outputs</span> <span class="op">&lt;-</span> <span class="va">x</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu">residual_block</span><span class="op">(</span>filters <span class="op">=</span> <span class="fl">32</span>, pooling <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu">residual_block</span><span class="op">(</span>filters <span class="op">=</span> <span class="fl">64</span>, pooling <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu">residual_block</span><span class="op">(</span>filters <span class="op">=</span> <span class="fl">128</span>, pooling <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/pkg/keras/man/layer_global_average_pooling_2d.html">layer_global_average_pooling_2d</a></span><span class="op">(</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/pkg/keras/man/layer_dense.html">layer_dense</a></span><span class="op">(</span>units <span class="op">=</span> <span class="fl">1</span>, activation <span class="op">=</span> <span class="st">"sigmoid"</span><span class="op">)</span></span>
<span><span class="va">model</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/keras/man/keras_model.html">keras_model</a></span><span class="op">(</span>inputs <span class="op">=</span> <span class="va">inputs</span>, outputs <span class="op">=</span> <span class="va">outputs</span><span class="op">)</span></span>
<span><span class="va">model</span></span></code><button title="Kopiuj do schowka" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>Model: "model_1"
________________________________________________________________________________
 Layer (type)           Output Shape            Param   Connected to            
                                                 #                              
================================================================================
 input_4 (InputLayer)   [(None, 32, 32, 3)]     0       []                      
 rescaling_1 (Rescalin  (None, 32, 32, 3)       0       ['input_4[0][0]']       
 g)                                                                             
 conv2d_14 (Conv2D)     (None, 32, 32, 32)      896     ['rescaling_1[0][0]']   
 conv2d_13 (Conv2D)     (None, 32, 32, 32)      9248    ['conv2d_14[0][0]']     
 max_pooling2d_1 (MaxP  (None, 16, 16, 32)      0       ['conv2d_13[0][0]']     
 ooling2D)                                                                      
 conv2d_15 (Conv2D)     (None, 16, 16, 32)      128     ['rescaling_1[0][0]']   
 add_2 (Add)            (None, 16, 16, 32)      0       ['max_pooling2d_1[0][0]'
                                                        , 'conv2d_15[0][0]']    
 conv2d_17 (Conv2D)     (None, 16, 16, 64)      18496   ['add_2[0][0]']         
 conv2d_16 (Conv2D)     (None, 16, 16, 64)      36928   ['conv2d_17[0][0]']     
 max_pooling2d_2 (MaxP  (None, 8, 8, 64)        0       ['conv2d_16[0][0]']     
 ooling2D)                                                                      
 conv2d_18 (Conv2D)     (None, 8, 8, 64)        2112    ['add_2[0][0]']         
 add_3 (Add)            (None, 8, 8, 64)        0       ['max_pooling2d_2[0][0]'
                                                        , 'conv2d_18[0][0]']    
 conv2d_20 (Conv2D)     (None, 8, 8, 128)       73856   ['add_3[0][0]']         
 conv2d_19 (Conv2D)     (None, 8, 8, 128)       14758   ['conv2d_20[0][0]']     
                                                4                               
 conv2d_21 (Conv2D)     (None, 8, 8, 128)       8320    ['add_3[0][0]']         
 add_4 (Add)            (None, 8, 8, 128)       0       ['conv2d_19[0][0]',     
                                                         'conv2d_21[0][0]']     
 global_average_poolin  (None, 128)             0       ['add_4[0][0]']         
 g2d (GlobalAveragePoo                                                          
 ling2D)                                                                        
 dense (Dense)          (None, 1)               129     ['global_average_pooling
                                                        2d[0][0]']              
================================================================================
Total params: 297697 (1.14 MB)
Trainable params: 297697 (1.14 MB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________</code></pre>
</div>
</div>
<p>Dzięki połączeniom rezydualnym można budować sieci o dowolnej głębokości, bez konieczności martwienia się o znikające gradienty.</p>
</section><section id="normalizacja-partii" class="level3 page-columns page-full" data-number="14.1.2"><h3 data-number="14.1.2" class="anchored" data-anchor-id="normalizacja-partii">
<span class="header-section-number">14.1.2</span> Normalizacja partii</h3>
<p>Normalizacja jest szeroką kategorią metod, które mają na celu uczynienie różnych próbek widzianych przez model uczenia maszynowego bardziej podobnymi do siebie, co pomaga modelowi w uczeniu się i generalizacji na nowych danych. Najbardziej powszechną formą normalizacji danych jest ta, którą już widziałeś kilka razy w tej książce: wyśrodkowanie danych na zero poprzez odjęcie średniej od danych i nadanie danym jednostkowego odchylenia standardowego poprzez podzielenie danych przez ich odchylenie standardowe. W efekcie przyjmuje się założenie, że dane mają rozkład normalny (lub gaussowski) i upewnia się, że rozkład ten jest wyśrodkowany i przeskalowany do jednostkowej wariancji:</p>
<div class="cell">
<details open="" class="code-fold"><summary>Kod</summary><div class="sourceCode cell-code" id="cb22"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a>normalize_data <span class="ot">&lt;-</span> <span class="fu">apply</span>(data, <span class="sc">&lt;</span>axis<span class="sc">&gt;</span>, <span class="cf">function</span>(x) (x <span class="sc">-</span> <span class="fu">mean</span>(x)) <span class="sc">/</span> <span class="fu">sd</span>(x))</span></code><button title="Kopiuj do schowka" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>Poprzednie przykłady w tej książce normalizowały dane przed wprowadzeniem ich do modeli. Ale normalizacja danych może być interesująca po każdym przekształceniu dokonanym przez sieć: nawet jeśli dane wchodzące do sieci Dense lub Conv2D mają średnią 0 i jednostkową wariancję, nie ma powodu, by a priori oczekiwać, że tak będzie w przypadku danych wychodzących. Czy normalizacja aktywacji pośrednich mogłaby pomóc?</p>
<div class="quarto-figure quarto-figure-center page-columns page-full">
<figure class="figure page-columns page-full"><div class="page-columns page-full"><p></p><div class="no-row-height column-margin column-container"><img src="images/Bayu Angora.gif" class="img-fluid quarto-figure quarto-figure-center figure-img" width="400"></div></div>
</figure>
</div>
<p>Normalizacja partii danych jest to rodzaj warstwy (<code><a href="https://rdrr.io/pkg/keras/man/layer_batch_normalization.html">layer_batch_normalization()</a></code> w <code>keras</code>) wprowadzonej w 2015 roku przez <span class="citation" data-cites="ioffeBatchNormalizationAccelerating2015">Ioffe i Szegedy (<a href="references.html#ref-ioffeBatchNormalizationAccelerating2015" role="doc-biblioref">2015</a>)</span>; może ona adaptacyjnie normalizować dane, nawet gdy średnia i wariancja zmieniają się w czasie treningu. Podczas szkolenia używa średniej i wariancji bieżącej partii danych do normalizacji próbek, a podczas wnioskowania (gdy wystarczająco duża partia reprezentatywnych danych może nie być dostępna), używa wykładniczej średniej ruchomej i wariancji danych widzianych podczas szkolenia.</p>
<p>Chociaż w oryginalnym artykule stwierdzono, że normalizacja partii działa poprzez “redukcję wewnętrznego przesunięcia kowariancji”, nikt tak naprawdę nie wie na pewno, dlaczego normalizacja partii pomaga. Różne hipotezy istnieją, ale nie ma pewności.</p>
<p>W praktyce, głównym efektem normalizacji partii wydaje się być to, że pomaga ona w propagacji gradientu - podobnie jak połączenia resztkowe - i tym samym pozwala na tworzenie głębszych sieci. Niektóre bardzo głębokie sieci mogą być trenowane tylko wtedy, gdy zawierają wiele warstw <em>BatchNormalization</em>. Na przykład, normalizacja partii jest szeroko stosowana w wielu zaawansowanych architekturach sieci konwolucyjnych, które są dostarczane z <code>keras</code>, takich jak ResNet50, EfficientNet i Xception.</p>
<p>Zarówno <code><a href="https://rdrr.io/pkg/keras/man/layer_dense.html">layer_dense()</a></code> jak i <code><a href="https://rdrr.io/pkg/keras/man/layer_conv_2d.html">layer_conv_2d()</a></code> wykorzystują wektor obciążeń (ang. <em>bias</em>), wyuczoną zmienną, której celem jest uczynienie warstwy afiniczną, a nie czysto liniową. Na przykład, funkcja <code>layer_ conv_2d()</code> zwraca, <code>y = conv(x, kernel) + bias</code>, a <code><a href="https://rdrr.io/pkg/keras/man/layer_dense.html">layer_dense()</a></code> zwraca <code>y = dot(x, kernel) + bias</code>. Ponieważ krok normalizacji zajmie się wyśrodkowaniem wyjścia warstwy na zero, wektor obciążenia nie jest już potrzebny w użyciu funkcji <code><a href="https://rdrr.io/pkg/keras/man/layer_batch_normalization.html">layer_batch_normalization()</a></code>, a warstwę można utworzyć bez niego za pomocą opcji <code>use_bias = FALSE</code>.</p>
<p>Co ważne, generalnie zalecałbym umieszczanie aktywacji poprzedniej warstwy po warstwie normalizacji wsadowej (choć to wciąż temat do dyskusji).</p>
<div class="cell">
<details open="" class="code-fold"><summary>Kod</summary><div class="sourceCode" id="cb23"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">x</span> <span class="op">|&gt;</span></span>
<span> <span class="fu"><a href="https://rdrr.io/pkg/keras/man/layer_conv_2d.html">layer_conv_2d</a></span><span class="op">(</span><span class="fl">32</span>, <span class="fl">3</span>, activation <span class="op">=</span> <span class="st">"relu"</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span> <span class="fu"><a href="https://rdrr.io/pkg/keras/man/layer_batch_normalization.html">layer_batch_normalization</a></span><span class="op">(</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># lub</span></span>
<span></span>
<span><span class="va">x</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/pkg/keras/man/layer_conv_2d.html">layer_conv_2d</a></span><span class="op">(</span><span class="fl">32</span>, <span class="fl">3</span>, use_bias <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/pkg/keras/man/layer_batch_normalization.html">layer_batch_normalization</a></span><span class="op">(</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/pkg/keras/man/layer_activation.html">layer_activation</a></span><span class="op">(</span><span class="st">"relu"</span><span class="op">)</span></span></code><button title="Kopiuj do schowka" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>Intuicyjnym powodem tego podejścia jest to, że normalizacja partii skupi naszes wejścia na zerze, podczas gdy nasza aktywacja <code>relu</code> używa zera jako punktu zwrotnego dla utrzymania lub porzucenia aktywowanych kanałów: robienie normalizacji przed aktywacją maksymalizuje wykorzystanie <code>relu</code>.</p>
<p>Normalizacja partii wiążę się też z szeregiem pułapek. Jedna z głównych dotyczy dostrajania: podczas dostrajania modelu, który zawiera warstwy BatchNormalization, zaleca się pozostawienie tych warstw zamrożonymi (wywołaj <code><a href="https://rdrr.io/pkg/keras/man/freeze_weights.html">freeze_weights()</a></code>, aby ustawić ich atrybut <code>trainable</code> na <code>FALSE</code>). W przeciwnym razie, będą one aktualizować swoją wewnętrzną średnią i wariancję, co może kolidować z bardzo małymi aktualizacjami zastosowanymi w otaczających warstwach Conv2D:</p>
<div class="cell">
<details open="" class="code-fold"><summary>Kod</summary><div class="sourceCode" id="cb24"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">batch_norm_layer_s3_classname</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/class.html">class</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/pkg/keras/man/layer_batch_normalization.html">layer_batch_normalization</a></span><span class="op">(</span><span class="op">)</span><span class="op">)</span><span class="op">[</span><span class="fl">1</span><span class="op">]</span></span>
<span><span class="va">batch_norm_layer_s3_classname</span></span></code><button title="Kopiuj do schowka" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>[1] "keras.layers.normalization.batch_normalization.BatchNormalization"</code></pre>
</div>
<details open="" class="code-fold"><summary>Kod</summary><div class="sourceCode" id="cb26"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">is_batch_norm_layer</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">x</span><span class="op">)</span> <span class="fu"><a href="https://rdrr.io/r/base/class.html">inherits</a></span><span class="op">(</span><span class="va">x</span>, <span class="va">batch_norm_layer_s3_classname</span><span class="op">)</span></span>
<span></span>
<span><span class="va">model</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/keras/man/application_efficientnet.html">application_efficientnet_b0</a></span><span class="op">(</span><span class="op">)</span></span>
<span></span>
<span><span class="kw">for</span> <span class="op">(</span><span class="va">layer</span> <span class="kw">in</span> <span class="va">model</span><span class="op">$</span><span class="va">layers</span><span class="op">)</span> <span class="op">{</span></span>
<span>  <span class="kw">if</span> <span class="op">(</span><span class="fu">is_batch_norm_layer</span><span class="op">(</span><span class="va">layer</span><span class="op">)</span><span class="op">)</span> <span class="op">{</span></span>
<span>    <span class="va">layer</span><span class="op">$</span><span class="va">trainable</span> <span class="op">&lt;-</span> <span class="cn">FALSE</span></span>
<span>  <span class="op">}</span></span>
<span><span class="op">}</span></span>
<span></span>
<span><span class="va">model</span></span></code><button title="Kopiuj do schowka" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>Model: "efficientnetb0"
________________________________________________________________________________
 Layer (type)       Output Shape         Para   Connected to         Trainable  
                                         m #                                    
================================================================================
 input_5 (InputLay  [(None, 224, 224,    0      []                   Y          
 er)                3)]                                                         
 rescaling_2 (Resc  (None, 224, 224, 3   0      ['input_5[0][0]']    Y          
 aling)             )                                                           
 normalization (No  (None, 224, 224, 3   7      ['rescaling_2[0][0   Y          
 rmalization)       )                           ]']                             
 rescaling_3 (Resc  (None, 224, 224, 3   0      ['normalization[0]   Y          
 aling)             )                           [0]']                           
 stem_conv_pad (Ze  (None, 225, 225, 3   0      ['rescaling_3[0][0   Y          
 roPadding2D)       )                           ]']                             
 stem_conv (Conv2D  (None, 112, 112, 3   864    ['stem_conv_pad[0]   Y          
 )                  2)                          [0]']                           
 stem_bn (BatchNor  (None, 112, 112, 3   128    ['stem_conv[0][0]'   N          
 malization)        2)                          ]                               
 stem_activation (  (None, 112, 112, 3   0      ['stem_bn[0][0]']    Y          
 Activation)        2)                                                          
 block1a_dwconv (D  (None, 112, 112, 3   288    ['stem_activation[   Y          
 epthwiseConv2D)    2)                          0][0]']                         
 block1a_bn (Batch  (None, 112, 112, 3   128    ['block1a_dwconv[0   N          
 Normalization)     2)                          ][0]']                          
 block1a_activatio  (None, 112, 112, 3   0      ['block1a_bn[0][0]   Y          
 n (Activation)     2)                          ']                              
 block1a_se_squeez  (None, 32)           0      ['block1a_activati   Y          
 e (GlobalAverageP                              on[0][0]']                      
 ooling2D)                                                                      
 block1a_se_reshap  (None, 1, 1, 32)     0      ['block1a_se_squee   Y          
 e (Reshape)                                    ze[0][0]']                      
 block1a_se_reduce  (None, 1, 1, 8)      264    ['block1a_se_resha   Y          
  (Conv2D)                                      pe[0][0]']                      
 block1a_se_expand  (None, 1, 1, 32)     288    ['block1a_se_reduc   Y          
  (Conv2D)                                      e[0][0]']                       
 block1a_se_excite  (None, 112, 112, 3   0      ['block1a_activati   Y          
  (Multiply)        2)                          on[0][0]',                      
                                                 'block1a_se_expan              
                                                d[0][0]']                       
 block1a_project_c  (None, 112, 112, 1   512    ['block1a_se_excit   Y          
 onv (Conv2D)       6)                          e[0][0]']                       
 block1a_project_b  (None, 112, 112, 1   64     ['block1a_project_   N          
 n (BatchNormaliza  6)                          conv[0][0]']                    
 tion)                                                                          
 block2a_expand_co  (None, 112, 112, 9   1536   ['block1a_project_   Y          
 nv (Conv2D)        6)                          bn[0][0]']                      
 block2a_expand_bn  (None, 112, 112, 9   384    ['block2a_expand_c   N          
  (BatchNormalizat  6)                          onv[0][0]']                     
 ion)                                                                           
 block2a_expand_ac  (None, 112, 112, 9   0      ['block2a_expand_b   Y          
 tivation (Activat  6)                          n[0][0]']                       
 ion)                                                                           
 block2a_dwconv_pa  (None, 113, 113, 9   0      ['block2a_expand_a   Y          
 d (ZeroPadding2D)  6)                          ctivation[0][0]']               
 block2a_dwconv (D  (None, 56, 56, 96)   864    ['block2a_dwconv_p   Y          
 epthwiseConv2D)                                ad[0][0]']                      
 block2a_bn (Batch  (None, 56, 56, 96)   384    ['block2a_dwconv[0   N          
 Normalization)                                 ][0]']                          
 block2a_activatio  (None, 56, 56, 96)   0      ['block2a_bn[0][0]   Y          
 n (Activation)                                 ']                              
 block2a_se_squeez  (None, 96)           0      ['block2a_activati   Y          
 e (GlobalAverageP                              on[0][0]']                      
 ooling2D)                                                                      
 block2a_se_reshap  (None, 1, 1, 96)     0      ['block2a_se_squee   Y          
 e (Reshape)                                    ze[0][0]']                      
 block2a_se_reduce  (None, 1, 1, 4)      388    ['block2a_se_resha   Y          
  (Conv2D)                                      pe[0][0]']                      
 block2a_se_expand  (None, 1, 1, 96)     480    ['block2a_se_reduc   Y          
  (Conv2D)                                      e[0][0]']                       
 block2a_se_excite  (None, 56, 56, 96)   0      ['block2a_activati   Y          
  (Multiply)                                    on[0][0]',                      
                                                 'block2a_se_expan              
                                                d[0][0]']                       
 block2a_project_c  (None, 56, 56, 24)   2304   ['block2a_se_excit   Y          
 onv (Conv2D)                                   e[0][0]']                       
 block2a_project_b  (None, 56, 56, 24)   96     ['block2a_project_   N          
 n (BatchNormaliza                              conv[0][0]']                    
 tion)                                                                          
 block2b_expand_co  (None, 56, 56, 144   3456   ['block2a_project_   Y          
 nv (Conv2D)        )                           bn[0][0]']                      
 block2b_expand_bn  (None, 56, 56, 144   576    ['block2b_expand_c   N          
  (BatchNormalizat  )                           onv[0][0]']                     
 ion)                                                                           
 block2b_expand_ac  (None, 56, 56, 144   0      ['block2b_expand_b   Y          
 tivation (Activat  )                           n[0][0]']                       
 ion)                                                                           
 block2b_dwconv (D  (None, 56, 56, 144   1296   ['block2b_expand_a   Y          
 epthwiseConv2D)    )                           ctivation[0][0]']               
 block2b_bn (Batch  (None, 56, 56, 144   576    ['block2b_dwconv[0   N          
 Normalization)     )                           ][0]']                          
 block2b_activatio  (None, 56, 56, 144   0      ['block2b_bn[0][0]   Y          
 n (Activation)     )                           ']                              
 block2b_se_squeez  (None, 144)          0      ['block2b_activati   Y          
 e (GlobalAverageP                              on[0][0]']                      
 ooling2D)                                                                      
 block2b_se_reshap  (None, 1, 1, 144)    0      ['block2b_se_squee   Y          
 e (Reshape)                                    ze[0][0]']                      
 block2b_se_reduce  (None, 1, 1, 6)      870    ['block2b_se_resha   Y          
  (Conv2D)                                      pe[0][0]']                      
 block2b_se_expand  (None, 1, 1, 144)    1008   ['block2b_se_reduc   Y          
  (Conv2D)                                      e[0][0]']                       
 block2b_se_excite  (None, 56, 56, 144   0      ['block2b_activati   Y          
  (Multiply)        )                           on[0][0]',                      
                                                 'block2b_se_expan              
                                                d[0][0]']                       
 block2b_project_c  (None, 56, 56, 24)   3456   ['block2b_se_excit   Y          
 onv (Conv2D)                                   e[0][0]']                       
 block2b_project_b  (None, 56, 56, 24)   96     ['block2b_project_   N          
 n (BatchNormaliza                              conv[0][0]']                    
 tion)                                                                          
 block2b_drop (Dro  (None, 56, 56, 24)   0      ['block2b_project_   Y          
 pout)                                          bn[0][0]']                      
 block2b_add (Add)  (None, 56, 56, 24)   0      ['block2b_drop[0][   Y          
                                                0]',                            
                                                 'block2a_project_              
                                                bn[0][0]']                      
 block3a_expand_co  (None, 56, 56, 144   3456   ['block2b_add[0][0   Y          
 nv (Conv2D)        )                           ]']                             
 block3a_expand_bn  (None, 56, 56, 144   576    ['block3a_expand_c   N          
  (BatchNormalizat  )                           onv[0][0]']                     
 ion)                                                                           
 block3a_expand_ac  (None, 56, 56, 144   0      ['block3a_expand_b   Y          
 tivation (Activat  )                           n[0][0]']                       
 ion)                                                                           
 block3a_dwconv_pa  (None, 59, 59, 144   0      ['block3a_expand_a   Y          
 d (ZeroPadding2D)  )                           ctivation[0][0]']               
 block3a_dwconv (D  (None, 28, 28, 144   3600   ['block3a_dwconv_p   Y          
 epthwiseConv2D)    )                           ad[0][0]']                      
 block3a_bn (Batch  (None, 28, 28, 144   576    ['block3a_dwconv[0   N          
 Normalization)     )                           ][0]']                          
 block3a_activatio  (None, 28, 28, 144   0      ['block3a_bn[0][0]   Y          
 n (Activation)     )                           ']                              
 block3a_se_squeez  (None, 144)          0      ['block3a_activati   Y          
 e (GlobalAverageP                              on[0][0]']                      
 ooling2D)                                                                      
 block3a_se_reshap  (None, 1, 1, 144)    0      ['block3a_se_squee   Y          
 e (Reshape)                                    ze[0][0]']                      
 block3a_se_reduce  (None, 1, 1, 6)      870    ['block3a_se_resha   Y          
  (Conv2D)                                      pe[0][0]']                      
 block3a_se_expand  (None, 1, 1, 144)    1008   ['block3a_se_reduc   Y          
  (Conv2D)                                      e[0][0]']                       
 block3a_se_excite  (None, 28, 28, 144   0      ['block3a_activati   Y          
  (Multiply)        )                           on[0][0]',                      
                                                 'block3a_se_expan              
                                                d[0][0]']                       
 block3a_project_c  (None, 28, 28, 40)   5760   ['block3a_se_excit   Y          
 onv (Conv2D)                                   e[0][0]']                       
 block3a_project_b  (None, 28, 28, 40)   160    ['block3a_project_   N          
 n (BatchNormaliza                              conv[0][0]']                    
 tion)                                                                          
 block3b_expand_co  (None, 28, 28, 240   9600   ['block3a_project_   Y          
 nv (Conv2D)        )                           bn[0][0]']                      
 block3b_expand_bn  (None, 28, 28, 240   960    ['block3b_expand_c   N          
  (BatchNormalizat  )                           onv[0][0]']                     
 ion)                                                                           
 block3b_expand_ac  (None, 28, 28, 240   0      ['block3b_expand_b   Y          
 tivation (Activat  )                           n[0][0]']                       
 ion)                                                                           
 block3b_dwconv (D  (None, 28, 28, 240   6000   ['block3b_expand_a   Y          
 epthwiseConv2D)    )                           ctivation[0][0]']               
 block3b_bn (Batch  (None, 28, 28, 240   960    ['block3b_dwconv[0   N          
 Normalization)     )                           ][0]']                          
 block3b_activatio  (None, 28, 28, 240   0      ['block3b_bn[0][0]   Y          
 n (Activation)     )                           ']                              
 block3b_se_squeez  (None, 240)          0      ['block3b_activati   Y          
 e (GlobalAverageP                              on[0][0]']                      
 ooling2D)                                                                      
 block3b_se_reshap  (None, 1, 1, 240)    0      ['block3b_se_squee   Y          
 e (Reshape)                                    ze[0][0]']                      
 block3b_se_reduce  (None, 1, 1, 10)     2410   ['block3b_se_resha   Y          
  (Conv2D)                                      pe[0][0]']                      
 block3b_se_expand  (None, 1, 1, 240)    2640   ['block3b_se_reduc   Y          
  (Conv2D)                                      e[0][0]']                       
 block3b_se_excite  (None, 28, 28, 240   0      ['block3b_activati   Y          
  (Multiply)        )                           on[0][0]',                      
                                                 'block3b_se_expan              
                                                d[0][0]']                       
 block3b_project_c  (None, 28, 28, 40)   9600   ['block3b_se_excit   Y          
 onv (Conv2D)                                   e[0][0]']                       
 block3b_project_b  (None, 28, 28, 40)   160    ['block3b_project_   N          
 n (BatchNormaliza                              conv[0][0]']                    
 tion)                                                                          
 block3b_drop (Dro  (None, 28, 28, 40)   0      ['block3b_project_   Y          
 pout)                                          bn[0][0]']                      
 block3b_add (Add)  (None, 28, 28, 40)   0      ['block3b_drop[0][   Y          
                                                0]',                            
                                                 'block3a_project_              
                                                bn[0][0]']                      
 block4a_expand_co  (None, 28, 28, 240   9600   ['block3b_add[0][0   Y          
 nv (Conv2D)        )                           ]']                             
 block4a_expand_bn  (None, 28, 28, 240   960    ['block4a_expand_c   N          
  (BatchNormalizat  )                           onv[0][0]']                     
 ion)                                                                           
 block4a_expand_ac  (None, 28, 28, 240   0      ['block4a_expand_b   Y          
 tivation (Activat  )                           n[0][0]']                       
 ion)                                                                           
 block4a_dwconv_pa  (None, 29, 29, 240   0      ['block4a_expand_a   Y          
 d (ZeroPadding2D)  )                           ctivation[0][0]']               
 block4a_dwconv (D  (None, 14, 14, 240   2160   ['block4a_dwconv_p   Y          
 epthwiseConv2D)    )                           ad[0][0]']                      
 block4a_bn (Batch  (None, 14, 14, 240   960    ['block4a_dwconv[0   N          
 Normalization)     )                           ][0]']                          
 block4a_activatio  (None, 14, 14, 240   0      ['block4a_bn[0][0]   Y          
 n (Activation)     )                           ']                              
 block4a_se_squeez  (None, 240)          0      ['block4a_activati   Y          
 e (GlobalAverageP                              on[0][0]']                      
 ooling2D)                                                                      
 block4a_se_reshap  (None, 1, 1, 240)    0      ['block4a_se_squee   Y          
 e (Reshape)                                    ze[0][0]']                      
 block4a_se_reduce  (None, 1, 1, 10)     2410   ['block4a_se_resha   Y          
  (Conv2D)                                      pe[0][0]']                      
 block4a_se_expand  (None, 1, 1, 240)    2640   ['block4a_se_reduc   Y          
  (Conv2D)                                      e[0][0]']                       
 block4a_se_excite  (None, 14, 14, 240   0      ['block4a_activati   Y          
  (Multiply)        )                           on[0][0]',                      
                                                 'block4a_se_expan              
                                                d[0][0]']                       
 block4a_project_c  (None, 14, 14, 80)   1920   ['block4a_se_excit   Y          
 onv (Conv2D)                            0      e[0][0]']                       
 block4a_project_b  (None, 14, 14, 80)   320    ['block4a_project_   N          
 n (BatchNormaliza                              conv[0][0]']                    
 tion)                                                                          
 block4b_expand_co  (None, 14, 14, 480   3840   ['block4a_project_   Y          
 nv (Conv2D)        )                    0      bn[0][0]']                      
 block4b_expand_bn  (None, 14, 14, 480   1920   ['block4b_expand_c   N          
  (BatchNormalizat  )                           onv[0][0]']                     
 ion)                                                                           
 block4b_expand_ac  (None, 14, 14, 480   0      ['block4b_expand_b   Y          
 tivation (Activat  )                           n[0][0]']                       
 ion)                                                                           
 block4b_dwconv (D  (None, 14, 14, 480   4320   ['block4b_expand_a   Y          
 epthwiseConv2D)    )                           ctivation[0][0]']               
 block4b_bn (Batch  (None, 14, 14, 480   1920   ['block4b_dwconv[0   N          
 Normalization)     )                           ][0]']                          
 block4b_activatio  (None, 14, 14, 480   0      ['block4b_bn[0][0]   Y          
 n (Activation)     )                           ']                              
 block4b_se_squeez  (None, 480)          0      ['block4b_activati   Y          
 e (GlobalAverageP                              on[0][0]']                      
 ooling2D)                                                                      
 block4b_se_reshap  (None, 1, 1, 480)    0      ['block4b_se_squee   Y          
 e (Reshape)                                    ze[0][0]']                      
 block4b_se_reduce  (None, 1, 1, 20)     9620   ['block4b_se_resha   Y          
  (Conv2D)                                      pe[0][0]']                      
 block4b_se_expand  (None, 1, 1, 480)    1008   ['block4b_se_reduc   Y          
  (Conv2D)                               0      e[0][0]']                       
 block4b_se_excite  (None, 14, 14, 480   0      ['block4b_activati   Y          
  (Multiply)        )                           on[0][0]',                      
                                                 'block4b_se_expan              
                                                d[0][0]']                       
 block4b_project_c  (None, 14, 14, 80)   3840   ['block4b_se_excit   Y          
 onv (Conv2D)                            0      e[0][0]']                       
 block4b_project_b  (None, 14, 14, 80)   320    ['block4b_project_   N          
 n (BatchNormaliza                              conv[0][0]']                    
 tion)                                                                          
 block4b_drop (Dro  (None, 14, 14, 80)   0      ['block4b_project_   Y          
 pout)                                          bn[0][0]']                      
 block4b_add (Add)  (None, 14, 14, 80)   0      ['block4b_drop[0][   Y          
                                                0]',                            
                                                 'block4a_project_              
                                                bn[0][0]']                      
 block4c_expand_co  (None, 14, 14, 480   3840   ['block4b_add[0][0   Y          
 nv (Conv2D)        )                    0      ]']                             
 block4c_expand_bn  (None, 14, 14, 480   1920   ['block4c_expand_c   N          
  (BatchNormalizat  )                           onv[0][0]']                     
 ion)                                                                           
 block4c_expand_ac  (None, 14, 14, 480   0      ['block4c_expand_b   Y          
 tivation (Activat  )                           n[0][0]']                       
 ion)                                                                           
 block4c_dwconv (D  (None, 14, 14, 480   4320   ['block4c_expand_a   Y          
 epthwiseConv2D)    )                           ctivation[0][0]']               
 block4c_bn (Batch  (None, 14, 14, 480   1920   ['block4c_dwconv[0   N          
 Normalization)     )                           ][0]']                          
 block4c_activatio  (None, 14, 14, 480   0      ['block4c_bn[0][0]   Y          
 n (Activation)     )                           ']                              
 block4c_se_squeez  (None, 480)          0      ['block4c_activati   Y          
 e (GlobalAverageP                              on[0][0]']                      
 ooling2D)                                                                      
 block4c_se_reshap  (None, 1, 1, 480)    0      ['block4c_se_squee   Y          
 e (Reshape)                                    ze[0][0]']                      
 block4c_se_reduce  (None, 1, 1, 20)     9620   ['block4c_se_resha   Y          
  (Conv2D)                                      pe[0][0]']                      
 block4c_se_expand  (None, 1, 1, 480)    1008   ['block4c_se_reduc   Y          
  (Conv2D)                               0      e[0][0]']                       
 block4c_se_excite  (None, 14, 14, 480   0      ['block4c_activati   Y          
  (Multiply)        )                           on[0][0]',                      
                                                 'block4c_se_expan              
                                                d[0][0]']                       
 block4c_project_c  (None, 14, 14, 80)   3840   ['block4c_se_excit   Y          
 onv (Conv2D)                            0      e[0][0]']                       
 block4c_project_b  (None, 14, 14, 80)   320    ['block4c_project_   N          
 n (BatchNormaliza                              conv[0][0]']                    
 tion)                                                                          
 block4c_drop (Dro  (None, 14, 14, 80)   0      ['block4c_project_   Y          
 pout)                                          bn[0][0]']                      
 block4c_add (Add)  (None, 14, 14, 80)   0      ['block4c_drop[0][   Y          
                                                0]',                            
                                                 'block4b_add[0][0              
                                                ]']                             
 block5a_expand_co  (None, 14, 14, 480   3840   ['block4c_add[0][0   Y          
 nv (Conv2D)        )                    0      ]']                             
 block5a_expand_bn  (None, 14, 14, 480   1920   ['block5a_expand_c   N          
  (BatchNormalizat  )                           onv[0][0]']                     
 ion)                                                                           
 block5a_expand_ac  (None, 14, 14, 480   0      ['block5a_expand_b   Y          
 tivation (Activat  )                           n[0][0]']                       
 ion)                                                                           
 block5a_dwconv (D  (None, 14, 14, 480   1200   ['block5a_expand_a   Y          
 epthwiseConv2D)    )                    0      ctivation[0][0]']               
 block5a_bn (Batch  (None, 14, 14, 480   1920   ['block5a_dwconv[0   N          
 Normalization)     )                           ][0]']                          
 block5a_activatio  (None, 14, 14, 480   0      ['block5a_bn[0][0]   Y          
 n (Activation)     )                           ']                              
 block5a_se_squeez  (None, 480)          0      ['block5a_activati   Y          
 e (GlobalAverageP                              on[0][0]']                      
 ooling2D)                                                                      
 block5a_se_reshap  (None, 1, 1, 480)    0      ['block5a_se_squee   Y          
 e (Reshape)                                    ze[0][0]']                      
 block5a_se_reduce  (None, 1, 1, 20)     9620   ['block5a_se_resha   Y          
  (Conv2D)                                      pe[0][0]']                      
 block5a_se_expand  (None, 1, 1, 480)    1008   ['block5a_se_reduc   Y          
  (Conv2D)                               0      e[0][0]']                       
 block5a_se_excite  (None, 14, 14, 480   0      ['block5a_activati   Y          
  (Multiply)        )                           on[0][0]',                      
                                                 'block5a_se_expan              
                                                d[0][0]']                       
 block5a_project_c  (None, 14, 14, 112   5376   ['block5a_se_excit   Y          
 onv (Conv2D)       )                    0      e[0][0]']                       
 block5a_project_b  (None, 14, 14, 112   448    ['block5a_project_   N          
 n (BatchNormaliza  )                           conv[0][0]']                    
 tion)                                                                          
 block5b_expand_co  (None, 14, 14, 672   7526   ['block5a_project_   Y          
 nv (Conv2D)        )                    4      bn[0][0]']                      
 block5b_expand_bn  (None, 14, 14, 672   2688   ['block5b_expand_c   N          
  (BatchNormalizat  )                           onv[0][0]']                     
 ion)                                                                           
 block5b_expand_ac  (None, 14, 14, 672   0      ['block5b_expand_b   Y          
 tivation (Activat  )                           n[0][0]']                       
 ion)                                                                           
 block5b_dwconv (D  (None, 14, 14, 672   1680   ['block5b_expand_a   Y          
 epthwiseConv2D)    )                    0      ctivation[0][0]']               
 block5b_bn (Batch  (None, 14, 14, 672   2688   ['block5b_dwconv[0   N          
 Normalization)     )                           ][0]']                          
 block5b_activatio  (None, 14, 14, 672   0      ['block5b_bn[0][0]   Y          
 n (Activation)     )                           ']                              
 block5b_se_squeez  (None, 672)          0      ['block5b_activati   Y          
 e (GlobalAverageP                              on[0][0]']                      
 ooling2D)                                                                      
 block5b_se_reshap  (None, 1, 1, 672)    0      ['block5b_se_squee   Y          
 e (Reshape)                                    ze[0][0]']                      
 block5b_se_reduce  (None, 1, 1, 28)     1884   ['block5b_se_resha   Y          
  (Conv2D)                               4      pe[0][0]']                      
 block5b_se_expand  (None, 1, 1, 672)    1948   ['block5b_se_reduc   Y          
  (Conv2D)                               8      e[0][0]']                       
 block5b_se_excite  (None, 14, 14, 672   0      ['block5b_activati   Y          
  (Multiply)        )                           on[0][0]',                      
                                                 'block5b_se_expan              
                                                d[0][0]']                       
 block5b_project_c  (None, 14, 14, 112   7526   ['block5b_se_excit   Y          
 onv (Conv2D)       )                    4      e[0][0]']                       
 block5b_project_b  (None, 14, 14, 112   448    ['block5b_project_   N          
 n (BatchNormaliza  )                           conv[0][0]']                    
 tion)                                                                          
 block5b_drop (Dro  (None, 14, 14, 112   0      ['block5b_project_   Y          
 pout)              )                           bn[0][0]']                      
 block5b_add (Add)  (None, 14, 14, 112   0      ['block5b_drop[0][   Y          
                    )                           0]',                            
                                                 'block5a_project_              
                                                bn[0][0]']                      
 block5c_expand_co  (None, 14, 14, 672   7526   ['block5b_add[0][0   Y          
 nv (Conv2D)        )                    4      ]']                             
 block5c_expand_bn  (None, 14, 14, 672   2688   ['block5c_expand_c   N          
  (BatchNormalizat  )                           onv[0][0]']                     
 ion)                                                                           
 block5c_expand_ac  (None, 14, 14, 672   0      ['block5c_expand_b   Y          
 tivation (Activat  )                           n[0][0]']                       
 ion)                                                                           
 block5c_dwconv (D  (None, 14, 14, 672   1680   ['block5c_expand_a   Y          
 epthwiseConv2D)    )                    0      ctivation[0][0]']               
 block5c_bn (Batch  (None, 14, 14, 672   2688   ['block5c_dwconv[0   N          
 Normalization)     )                           ][0]']                          
 block5c_activatio  (None, 14, 14, 672   0      ['block5c_bn[0][0]   Y          
 n (Activation)     )                           ']                              
 block5c_se_squeez  (None, 672)          0      ['block5c_activati   Y          
 e (GlobalAverageP                              on[0][0]']                      
 ooling2D)                                                                      
 block5c_se_reshap  (None, 1, 1, 672)    0      ['block5c_se_squee   Y          
 e (Reshape)                                    ze[0][0]']                      
 block5c_se_reduce  (None, 1, 1, 28)     1884   ['block5c_se_resha   Y          
  (Conv2D)                               4      pe[0][0]']                      
 block5c_se_expand  (None, 1, 1, 672)    1948   ['block5c_se_reduc   Y          
  (Conv2D)                               8      e[0][0]']                       
 block5c_se_excite  (None, 14, 14, 672   0      ['block5c_activati   Y          
  (Multiply)        )                           on[0][0]',                      
                                                 'block5c_se_expan              
                                                d[0][0]']                       
 block5c_project_c  (None, 14, 14, 112   7526   ['block5c_se_excit   Y          
 onv (Conv2D)       )                    4      e[0][0]']                       
 block5c_project_b  (None, 14, 14, 112   448    ['block5c_project_   N          
 n (BatchNormaliza  )                           conv[0][0]']                    
 tion)                                                                          
 block5c_drop (Dro  (None, 14, 14, 112   0      ['block5c_project_   Y          
 pout)              )                           bn[0][0]']                      
 block5c_add (Add)  (None, 14, 14, 112   0      ['block5c_drop[0][   Y          
                    )                           0]',                            
                                                 'block5b_add[0][0              
                                                ]']                             
 block6a_expand_co  (None, 14, 14, 672   7526   ['block5c_add[0][0   Y          
 nv (Conv2D)        )                    4      ]']                             
 block6a_expand_bn  (None, 14, 14, 672   2688   ['block6a_expand_c   N          
  (BatchNormalizat  )                           onv[0][0]']                     
 ion)                                                                           
 block6a_expand_ac  (None, 14, 14, 672   0      ['block6a_expand_b   Y          
 tivation (Activat  )                           n[0][0]']                       
 ion)                                                                           
 block6a_dwconv_pa  (None, 17, 17, 672   0      ['block6a_expand_a   Y          
 d (ZeroPadding2D)  )                           ctivation[0][0]']               
 block6a_dwconv (D  (None, 7, 7, 672)    1680   ['block6a_dwconv_p   Y          
 epthwiseConv2D)                         0      ad[0][0]']                      
 block6a_bn (Batch  (None, 7, 7, 672)    2688   ['block6a_dwconv[0   N          
 Normalization)                                 ][0]']                          
 block6a_activatio  (None, 7, 7, 672)    0      ['block6a_bn[0][0]   Y          
 n (Activation)                                 ']                              
 block6a_se_squeez  (None, 672)          0      ['block6a_activati   Y          
 e (GlobalAverageP                              on[0][0]']                      
 ooling2D)                                                                      
 block6a_se_reshap  (None, 1, 1, 672)    0      ['block6a_se_squee   Y          
 e (Reshape)                                    ze[0][0]']                      
 block6a_se_reduce  (None, 1, 1, 28)     1884   ['block6a_se_resha   Y          
  (Conv2D)                               4      pe[0][0]']                      
 block6a_se_expand  (None, 1, 1, 672)    1948   ['block6a_se_reduc   Y          
  (Conv2D)                               8      e[0][0]']                       
 block6a_se_excite  (None, 7, 7, 672)    0      ['block6a_activati   Y          
  (Multiply)                                    on[0][0]',                      
                                                 'block6a_se_expan              
                                                d[0][0]']                       
 block6a_project_c  (None, 7, 7, 192)    1290   ['block6a_se_excit   Y          
 onv (Conv2D)                            24     e[0][0]']                       
 block6a_project_b  (None, 7, 7, 192)    768    ['block6a_project_   N          
 n (BatchNormaliza                              conv[0][0]']                    
 tion)                                                                          
 block6b_expand_co  (None, 7, 7, 1152)   2211   ['block6a_project_   Y          
 nv (Conv2D)                             84     bn[0][0]']                      
 block6b_expand_bn  (None, 7, 7, 1152)   4608   ['block6b_expand_c   N          
  (BatchNormalizat                              onv[0][0]']                     
 ion)                                                                           
 block6b_expand_ac  (None, 7, 7, 1152)   0      ['block6b_expand_b   Y          
 tivation (Activat                              n[0][0]']                       
 ion)                                                                           
 block6b_dwconv (D  (None, 7, 7, 1152)   2880   ['block6b_expand_a   Y          
 epthwiseConv2D)                         0      ctivation[0][0]']               
 block6b_bn (Batch  (None, 7, 7, 1152)   4608   ['block6b_dwconv[0   N          
 Normalization)                                 ][0]']                          
 block6b_activatio  (None, 7, 7, 1152)   0      ['block6b_bn[0][0]   Y          
 n (Activation)                                 ']                              
 block6b_se_squeez  (None, 1152)         0      ['block6b_activati   Y          
 e (GlobalAverageP                              on[0][0]']                      
 ooling2D)                                                                      
 block6b_se_reshap  (None, 1, 1, 1152)   0      ['block6b_se_squee   Y          
 e (Reshape)                                    ze[0][0]']                      
 block6b_se_reduce  (None, 1, 1, 48)     5534   ['block6b_se_resha   Y          
  (Conv2D)                               4      pe[0][0]']                      
 block6b_se_expand  (None, 1, 1, 1152)   5644   ['block6b_se_reduc   Y          
  (Conv2D)                               8      e[0][0]']                       
 block6b_se_excite  (None, 7, 7, 1152)   0      ['block6b_activati   Y          
  (Multiply)                                    on[0][0]',                      
                                                 'block6b_se_expan              
                                                d[0][0]']                       
 block6b_project_c  (None, 7, 7, 192)    2211   ['block6b_se_excit   Y          
 onv (Conv2D)                            84     e[0][0]']                       
 block6b_project_b  (None, 7, 7, 192)    768    ['block6b_project_   N          
 n (BatchNormaliza                              conv[0][0]']                    
 tion)                                                                          
 block6b_drop (Dro  (None, 7, 7, 192)    0      ['block6b_project_   Y          
 pout)                                          bn[0][0]']                      
 block6b_add (Add)  (None, 7, 7, 192)    0      ['block6b_drop[0][   Y          
                                                0]',                            
                                                 'block6a_project_              
                                                bn[0][0]']                      
 block6c_expand_co  (None, 7, 7, 1152)   2211   ['block6b_add[0][0   Y          
 nv (Conv2D)                             84     ]']                             
 block6c_expand_bn  (None, 7, 7, 1152)   4608   ['block6c_expand_c   N          
  (BatchNormalizat                              onv[0][0]']                     
 ion)                                                                           
 block6c_expand_ac  (None, 7, 7, 1152)   0      ['block6c_expand_b   Y          
 tivation (Activat                              n[0][0]']                       
 ion)                                                                           
 block6c_dwconv (D  (None, 7, 7, 1152)   2880   ['block6c_expand_a   Y          
 epthwiseConv2D)                         0      ctivation[0][0]']               
 block6c_bn (Batch  (None, 7, 7, 1152)   4608   ['block6c_dwconv[0   N          
 Normalization)                                 ][0]']                          
 block6c_activatio  (None, 7, 7, 1152)   0      ['block6c_bn[0][0]   Y          
 n (Activation)                                 ']                              
 block6c_se_squeez  (None, 1152)         0      ['block6c_activati   Y          
 e (GlobalAverageP                              on[0][0]']                      
 ooling2D)                                                                      
 block6c_se_reshap  (None, 1, 1, 1152)   0      ['block6c_se_squee   Y          
 e (Reshape)                                    ze[0][0]']                      
 block6c_se_reduce  (None, 1, 1, 48)     5534   ['block6c_se_resha   Y          
  (Conv2D)                               4      pe[0][0]']                      
 block6c_se_expand  (None, 1, 1, 1152)   5644   ['block6c_se_reduc   Y          
  (Conv2D)                               8      e[0][0]']                       
 block6c_se_excite  (None, 7, 7, 1152)   0      ['block6c_activati   Y          
  (Multiply)                                    on[0][0]',                      
                                                 'block6c_se_expan              
                                                d[0][0]']                       
 block6c_project_c  (None, 7, 7, 192)    2211   ['block6c_se_excit   Y          
 onv (Conv2D)                            84     e[0][0]']                       
 block6c_project_b  (None, 7, 7, 192)    768    ['block6c_project_   N          
 n (BatchNormaliza                              conv[0][0]']                    
 tion)                                                                          
 block6c_drop (Dro  (None, 7, 7, 192)    0      ['block6c_project_   Y          
 pout)                                          bn[0][0]']                      
 block6c_add (Add)  (None, 7, 7, 192)    0      ['block6c_drop[0][   Y          
                                                0]',                            
                                                 'block6b_add[0][0              
                                                ]']                             
 block6d_expand_co  (None, 7, 7, 1152)   2211   ['block6c_add[0][0   Y          
 nv (Conv2D)                             84     ]']                             
 block6d_expand_bn  (None, 7, 7, 1152)   4608   ['block6d_expand_c   N          
  (BatchNormalizat                              onv[0][0]']                     
 ion)                                                                           
 block6d_expand_ac  (None, 7, 7, 1152)   0      ['block6d_expand_b   Y          
 tivation (Activat                              n[0][0]']                       
 ion)                                                                           
 block6d_dwconv (D  (None, 7, 7, 1152)   2880   ['block6d_expand_a   Y          
 epthwiseConv2D)                         0      ctivation[0][0]']               
 block6d_bn (Batch  (None, 7, 7, 1152)   4608   ['block6d_dwconv[0   N          
 Normalization)                                 ][0]']                          
 block6d_activatio  (None, 7, 7, 1152)   0      ['block6d_bn[0][0]   Y          
 n (Activation)                                 ']                              
 block6d_se_squeez  (None, 1152)         0      ['block6d_activati   Y          
 e (GlobalAverageP                              on[0][0]']                      
 ooling2D)                                                                      
 block6d_se_reshap  (None, 1, 1, 1152)   0      ['block6d_se_squee   Y          
 e (Reshape)                                    ze[0][0]']                      
 block6d_se_reduce  (None, 1, 1, 48)     5534   ['block6d_se_resha   Y          
  (Conv2D)                               4      pe[0][0]']                      
 block6d_se_expand  (None, 1, 1, 1152)   5644   ['block6d_se_reduc   Y          
  (Conv2D)                               8      e[0][0]']                       
 block6d_se_excite  (None, 7, 7, 1152)   0      ['block6d_activati   Y          
  (Multiply)                                    on[0][0]',                      
                                                 'block6d_se_expan              
                                                d[0][0]']                       
 block6d_project_c  (None, 7, 7, 192)    2211   ['block6d_se_excit   Y          
 onv (Conv2D)                            84     e[0][0]']                       
 block6d_project_b  (None, 7, 7, 192)    768    ['block6d_project_   N          
 n (BatchNormaliza                              conv[0][0]']                    
 tion)                                                                          
 block6d_drop (Dro  (None, 7, 7, 192)    0      ['block6d_project_   Y          
 pout)                                          bn[0][0]']                      
 block6d_add (Add)  (None, 7, 7, 192)    0      ['block6d_drop[0][   Y          
                                                0]',                            
                                                 'block6c_add[0][0              
                                                ]']                             
 block7a_expand_co  (None, 7, 7, 1152)   2211   ['block6d_add[0][0   Y          
 nv (Conv2D)                             84     ]']                             
 block7a_expand_bn  (None, 7, 7, 1152)   4608   ['block7a_expand_c   N          
  (BatchNormalizat                              onv[0][0]']                     
 ion)                                                                           
 block7a_expand_ac  (None, 7, 7, 1152)   0      ['block7a_expand_b   Y          
 tivation (Activat                              n[0][0]']                       
 ion)                                                                           
 block7a_dwconv (D  (None, 7, 7, 1152)   1036   ['block7a_expand_a   Y          
 epthwiseConv2D)                         8      ctivation[0][0]']               
 block7a_bn (Batch  (None, 7, 7, 1152)   4608   ['block7a_dwconv[0   N          
 Normalization)                                 ][0]']                          
 block7a_activatio  (None, 7, 7, 1152)   0      ['block7a_bn[0][0]   Y          
 n (Activation)                                 ']                              
 block7a_se_squeez  (None, 1152)         0      ['block7a_activati   Y          
 e (GlobalAverageP                              on[0][0]']                      
 ooling2D)                                                                      
 block7a_se_reshap  (None, 1, 1, 1152)   0      ['block7a_se_squee   Y          
 e (Reshape)                                    ze[0][0]']                      
 block7a_se_reduce  (None, 1, 1, 48)     5534   ['block7a_se_resha   Y          
  (Conv2D)                               4      pe[0][0]']                      
 block7a_se_expand  (None, 1, 1, 1152)   5644   ['block7a_se_reduc   Y          
  (Conv2D)                               8      e[0][0]']                       
 block7a_se_excite  (None, 7, 7, 1152)   0      ['block7a_activati   Y          
  (Multiply)                                    on[0][0]',                      
                                                 'block7a_se_expan              
                                                d[0][0]']                       
 block7a_project_c  (None, 7, 7, 320)    3686   ['block7a_se_excit   Y          
 onv (Conv2D)                            40     e[0][0]']                       
 block7a_project_b  (None, 7, 7, 320)    1280   ['block7a_project_   N          
 n (BatchNormaliza                              conv[0][0]']                    
 tion)                                                                          
 top_conv (Conv2D)  (None, 7, 7, 1280)   4096   ['block7a_project_   Y          
                                         00     bn[0][0]']                      
 top_bn (BatchNorm  (None, 7, 7, 1280)   5120   ['top_conv[0][0]']   N          
 alization)                                                                     
 top_activation (A  (None, 7, 7, 1280)   0      ['top_bn[0][0]']     Y          
 ctivation)                                                                     
 avg_pool (GlobalA  (None, 1280)         0      ['top_activation[0   Y          
 veragePooling2D)                               ][0]']                          
 top_dropout (Drop  (None, 1280)         0      ['avg_pool[0][0]']   Y          
 out)                                                                           
 predictions (Dens  (None, 1000)         1281   ['top_dropout[0][0   Y          
 e)                                      000    ]']                             
================================================================================
Total params: 5330571 (20.33 MB)
Trainable params: 5246532 (20.01 MB)
Non-trainable params: 84039 (328.28 KB)
________________________________________________________________________________</code></pre>
</div>
</div>
</section><section id="konwolucje-separowalne" class="level3 page-columns page-full" data-number="14.1.3"><h3 data-number="14.1.3" class="anchored" data-anchor-id="konwolucje-separowalne">
<span class="header-section-number">14.1.3</span> Konwolucje separowalne</h3>
<p>A gdybym powiedział, że istnieje warstwa, której możemy użyć jako zamiennika <code>layer_ conv_2d()</code>, która sprawi, że nasz model będzie mniejszy (mniej trenowanych parametrów) i szczuplejszy (mniej operacji zmiennoprzecinkowych) i spowoduje, że wykona kilka punktów procentowych lepiej swoje zadanie? To właśnie robi warstwa konwolucji separowalnej wgłębnie (<code><a href="https://rdrr.io/pkg/keras/man/layer_separable_conv_2d.html">layer_separable_conv_2d()</a></code> w <code>keras</code>). Warstwa ta wykonuje konwolucję przestrzenną na każdym kanale swojego wejścia, niezależnie, przed zmieszaniem kanałów wyjściowych poprzez konwolucję punktową (konwolucja 1 × 1), jak pokazano na <a href="#fig-seg8" class="quarto-xref">Rysunek&nbsp;<span>14.8</span></a></p>
<div id="fig-seg8" class="quarto-figure quarto-figure-center quarto-float anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure"><div aria-describedby="fig-seg8-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="images/Zrzut ekranu 2023-03-18 o 16.05.49.png" class="img-fluid quarto-figure quarto-figure-center figure-img" width="600">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-seg8-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Rysunek&nbsp;14.8: Konwolucja separowalna
</figcaption></figure>
</div>
<p>Jest to równoznaczne z rozdzieleniem uczenia się cech przestrzennych i uczenia się cech kanałowych. W podobny sposób, jak konwolucja opiera się na założeniu, że wzory w obrazach nie są związane z konkretnymi lokalizacjami, konwolucja separowalna wgłębnie opiera się na założeniu, że lokalizacje przestrzenne w aktywacjach pośrednich są wysoce skorelowane, ale różne kanały są wysoce niezależne . Ponieważ założenie to jest generalnie prawdziwe dla reprezentacji obrazów uczonych przez głębokie sieci neuronowe, służy jako użyteczne założenie, które pomaga modelowi bardziej efektywnie wykorzystać dane treningowe. Model z silniejszymi założeniami dotyczącymi struktury informacji, które będzie musiał przetworzyć, jest lepszym modelem - o ile założenia te są poprawne.</p>
<div class="quarto-figure quarto-figure-center page-columns page-full">
<figure class="figure page-columns page-full"><div class="page-columns page-full"><p></p><div class="no-row-height column-margin column-container"><img src="https://media.giphy.com/media/3ohfFoXZskaNkuCR32/giphy.gif" class="img-fluid quarto-figure quarto-figure-center figure-img" width="400"></div></div>
</figure>
</div>
<p>Konwolucja separowalna wymaga znacznie mniej parametrów i wymaga mniejszej ilości obliczeń niż zwykła konwolucja, a jednocześnie ma porównywalną moc reprezentacji. W rezultacie otrzymujemy mniejsze modele, które szybciej osiągają zbieżność i są mniej podatne na <em>overfitting</em>. Te zalety stają się szczególnie ważne, gdy trenujemy małe modele od podstaw na ograniczonych zbiorach danych.</p>
<p>Konwolucje separowalne wgłębnie są podstawą architektury Xception, wysokowydajnej sieci splotowej.</p>
</section><section id="przykład-wykorzystania-sieci-xception" class="level3" data-number="14.1.4"><h3 data-number="14.1.4" class="anchored" data-anchor-id="przykład-wykorzystania-sieci-xception">
<span class="header-section-number">14.1.4</span> Przykład wykorzystania sieci Xception</h3>
<p>Dla przypomnienia, oto zasady architektury sieci splotowej, które poznaliśmy do tej pory:</p>
<ul>
<li>Nasz model powinien być zorganizowany w powtarzające się bloki warstw, zwykle składających się z wielu warstw konwolucji i warstwy <em>max pooling</em>.</li>
<li>Liczba filtrów w naszych warstwach powinna rosnąć wraz ze zmniejszaniem się rozmiaru przestrzennych map cech.</li>
<li>Głębokie i wąskie sieci są lepsze niż szerokie i płytkie.</li>
<li>Wprowadzenie połączeń rezydualnych wokół bloków warstw pomaga trenować głębsze sieci.</li>
<li>Korzystne może być wprowadzenie warstw normalizacji partii po twoich warstwach konwolucji.</li>
<li>Korzystne może być zastąpienie <code><a href="https://rdrr.io/pkg/keras/man/layer_conv_2d.html">layer_conv_2d()</a></code> przez <code><a href="https://rdrr.io/pkg/keras/man/layer_separable_conv_2d.html">layer_separable_conv_2d()</a></code>, które są bardziej wydajne pod względem parametrów.</li>
</ul>
<p>Zbierzmy te pomysły razem w jeden model. Jego architektura będzie przypominać sieć Xception. Zastosujemy ją do zadania psy vs.&nbsp;koty z poprzedniego rozdziału.</p>
<div class="cell">
<details open="" class="code-fold"><summary>Kod</summary><div class="sourceCode" id="cb28"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">data_augmentation</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/keras/man/keras_model_sequential.html">keras_model_sequential</a></span><span class="op">(</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/pkg/keras/man/layer_random_flip.html">layer_random_flip</a></span><span class="op">(</span><span class="st">"horizontal"</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/pkg/keras/man/layer_random_rotation.html">layer_random_rotation</a></span><span class="op">(</span><span class="fl">0.1</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/pkg/keras/man/layer_random_zoom.html">layer_random_zoom</a></span><span class="op">(</span><span class="fl">0.2</span><span class="op">)</span></span>
<span></span>
<span><span class="va">inputs</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/keras/man/layer_input.html">layer_input</a></span><span class="op">(</span>shape <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">180</span>, <span class="fl">180</span>, <span class="fl">3</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="va">x</span> <span class="op">&lt;-</span> <span class="va">inputs</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu">data_augmentation</span><span class="op">(</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/pkg/keras/man/layer_rescaling.html">layer_rescaling</a></span><span class="op">(</span>scale <span class="op">=</span> <span class="fl">1</span> <span class="op">/</span> <span class="fl">255</span><span class="op">)</span></span>
<span></span>
<span><span class="va">x</span> <span class="op">&lt;-</span> <span class="va">x</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/pkg/keras/man/layer_conv_2d.html">layer_conv_2d</a></span><span class="op">(</span><span class="fl">32</span>, <span class="fl">5</span>, use_bias <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span></span>
<span></span>
<span><span class="kw">for</span> <span class="op">(</span><span class="va">size</span> <span class="kw">in</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">32</span>, <span class="fl">64</span>, <span class="fl">128</span>, <span class="fl">256</span>, <span class="fl">512</span><span class="op">)</span><span class="op">)</span> <span class="op">{</span></span>
<span>  <span class="va">residual</span> <span class="op">&lt;-</span> <span class="va">x</span></span>
<span></span>
<span>  <span class="va">x</span> <span class="op">&lt;-</span> <span class="va">x</span> <span class="op">|&gt;</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/pkg/keras/man/layer_batch_normalization.html">layer_batch_normalization</a></span><span class="op">(</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/pkg/keras/man/layer_activation.html">layer_activation</a></span><span class="op">(</span><span class="st">"relu"</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/pkg/keras/man/layer_separable_conv_2d.html">layer_separable_conv_2d</a></span><span class="op">(</span><span class="va">size</span>, <span class="fl">3</span>, padding <span class="op">=</span> <span class="st">"same"</span>, use_bias <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/pkg/keras/man/layer_batch_normalization.html">layer_batch_normalization</a></span><span class="op">(</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/pkg/keras/man/layer_activation.html">layer_activation</a></span><span class="op">(</span><span class="st">"relu"</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/pkg/keras/man/layer_separable_conv_2d.html">layer_separable_conv_2d</a></span><span class="op">(</span><span class="va">size</span>, <span class="fl">3</span>, padding <span class="op">=</span> <span class="st">"same"</span>, use_bias <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/pkg/keras/man/layer_max_pooling_2d.html">layer_max_pooling_2d</a></span><span class="op">(</span>pool_size <span class="op">=</span> <span class="fl">3</span>, strides <span class="op">=</span> <span class="fl">2</span>, padding <span class="op">=</span> <span class="st">"same"</span><span class="op">)</span></span>
<span></span>
<span>  <span class="va">residual</span> <span class="op">&lt;-</span> <span class="va">residual</span> <span class="op">|&gt;</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/pkg/keras/man/layer_conv_2d.html">layer_conv_2d</a></span><span class="op">(</span><span class="va">size</span>, <span class="fl">1</span>, strides <span class="op">=</span> <span class="fl">2</span>, padding <span class="op">=</span> <span class="st">"same"</span>, use_bias <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span></span>
<span></span>
<span>  <span class="va">x</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/keras/man/layer_add.html">layer_add</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span><span class="va">x</span>, <span class="va">residual</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="op">}</span></span>
<span></span>
<span><span class="va">outputs</span> <span class="op">&lt;-</span> <span class="va">x</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/pkg/keras/man/layer_global_average_pooling_2d.html">layer_global_average_pooling_2d</a></span><span class="op">(</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/pkg/keras/man/layer_dropout.html">layer_dropout</a></span><span class="op">(</span><span class="fl">0.5</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/pkg/keras/man/layer_dense.html">layer_dense</a></span><span class="op">(</span><span class="fl">1</span>, activation <span class="op">=</span> <span class="st">"sigmoid"</span><span class="op">)</span></span>
<span></span>
<span><span class="va">model</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/keras/man/keras_model.html">keras_model</a></span><span class="op">(</span><span class="va">inputs</span>, <span class="va">outputs</span><span class="op">)</span></span>
<span></span>
<span><span class="va">train_dataset</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/keras/man/image_dataset_from_directory.html">image_dataset_from_directory</a></span><span class="op">(</span></span>
<span>  <span class="st">"/Users/majerek/Downloads/cats_and_dogs_small/train/"</span>,</span>
<span>  image_size <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">180</span>, <span class="fl">180</span><span class="op">)</span>,</span>
<span>  batch_size <span class="op">=</span> <span class="fl">32</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="va">validation_dataset</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/keras/man/image_dataset_from_directory.html">image_dataset_from_directory</a></span><span class="op">(</span></span>
<span>  <span class="st">"/Users/majerek/Downloads/cats_and_dogs_small/validation"</span>,</span>
<span>  image_size <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">180</span>, <span class="fl">180</span><span class="op">)</span>,</span>
<span>  batch_size <span class="op">=</span> <span class="fl">32</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="va">callbacks</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/pkg/keras/man/callback_model_checkpoint.html">callback_model_checkpoint</a></span><span class="op">(</span>filepath <span class="op">=</span> <span class="st">"models/vgg16_cat_dog.keras"</span>, save_best_only <span class="op">=</span> <span class="cn">T</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="va">model</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu">keras</span><span class="fu">::</span><span class="fu"><a href="https://generics.r-lib.org/reference/compile.html">compile</a></span><span class="op">(</span></span>
<span>    loss <span class="op">=</span> <span class="st">"binary_crossentropy"</span>,</span>
<span>    optimizer <span class="op">=</span> <span class="st">"rmsprop"</span>,</span>
<span>    metrics <span class="op">=</span> <span class="st">"accuracy"</span></span>
<span>  <span class="op">)</span></span>
<span></span>
<span><span class="va">history</span> <span class="op">&lt;-</span> <span class="va">model</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu"><a href="https://generics.r-lib.org/reference/fit.html">fit</a></span><span class="op">(</span></span>
<span>    <span class="va">train_dataset</span>,</span>
<span>    epochs <span class="op">=</span> <span class="fl">90</span>,</span>
<span>    callbacks <span class="op">=</span> <span class="va">callbacks</span>,</span>
<span>    validation_data <span class="op">=</span> <span class="va">validation_dataset</span></span>
<span>  <span class="op">)</span></span></code><button title="Kopiuj do schowka" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div class="cell">
<details open="" class="code-fold"><summary>Kod</summary><div class="sourceCode" id="cb29"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">model</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/keras/man/save_model_tf.html">load_model_tf</a></span><span class="op">(</span><span class="st">"models/vgg16_cat_dog.keras"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/load.html">load</a></span><span class="op">(</span><span class="st">"models/vgg16_cat_dog_hist.rda"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="va">history</span><span class="op">)</span></span></code><button title="Kopiuj do schowka" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output-display">
<div>
<figure class="figure"><p><img src="segmentation_files/figure-html/unnamed-chunk-19-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<p>Nasz nowy model osiąga dokładność testu 90,2%, w porównaniu z 83% dla modelu z poprzedniego rozdziału. Jak widać, stosowanie najlepszych architektur ma natychmiastowy, znaczący wpływ na wydajność modelu! Chcąc jeszcze bardziej poprawić wydajność, powinniśmy zacząć systematycznie dostrajać hiperparametry naszej architektury.</p>
</section></section><section id="co-widzi-sieć-konwolucyjna" class="level2 page-columns page-full" data-number="14.2"><h2 data-number="14.2" class="anchored" data-anchor-id="co-widzi-sieć-konwolucyjna">
<span class="header-section-number">14.2</span> Co widzi sieć konwolucyjna?</h2>
<p>Podstawowym problemem podczas budowania aplikacji wizji komputerowej jest kwestia możliwości interpretacji: dlaczego nasz klasyfikator uznał, że dany obraz zawiera lodówkę, podczas gdy wszystko, co widzimy, to ciężarówka? Jest to szczególnie istotne w przypadkach użycia, w których głębokie uczenie jest wykorzystywane do uzupełnienia ludzkiej wiedzy, jak na przykład w przypadkach użycia obrazowania medycznego. Zakończymy ten rozdział zapoznając Cię z szeregiem różnych technik wizualizacji tego, czego uczą się sieci splotowe i zrozumienia podejmowanych przez nie decyzji.</p>
<div class="quarto-figure quarto-figure-center page-columns page-full">
<figure class="figure page-columns page-full"><div class="page-columns page-full"><p></p><div class="no-row-height column-margin column-container"><img src="https://media.giphy.com/media/ZNMa7ocjGc0PTlHrP4/giphy.gif" class="img-fluid quarto-figure quarto-figure-center figure-img"></div></div>
</figure>
</div>
<p>Często mówi się, że modele głębokiego uczenia są “czarnymi skrzynkami”: uczą się reprezentacji, które są trudne do wyodrębnienia i przedstawienia w formie czytelnej dla człowieka. Chociaż jest to częściowo prawdą w przypadku niektórych typów modeli głębokiego uczenia, to zdecydowanie nie jest to prawdą w przypadku sieci splotowych. Reprezentacje uczone przez sieci konwolucyjne są wygodne w wizualizacji, w dużej mierze dlatego, że są to reprezentacje wizualnych koncepcji. Od 2013 roku opracowano szeroki wachlarz technik wizualizacji i interpretacji tych reprezentacji. Nie będziemy badać ich wszystkich, ale omówimy trzy z najbardziej przystępnych i użytecznych:</p>
<ul>
<li>Wizualizacja pośrednich wyjść sieci (pośrednich aktywacji) - przydatna do zrozumienia, jak kolejne warstwy sieci przekształcają swoje dane wejściowe, oraz do uzyskania pierwszego wyobrażenia o znaczeniu poszczególnych filtrów sieci.</li>
<li>Wizualizacja filtrów sieci splotowych - przydatna do dokładnego zrozumienia, na jaki wzór wizualny lub pojęcie reaguje każdy filtr w sieci.</li>
<li>Wizualizacja map ciepła aktywacji klas w obrazie - przydatna do zrozumienia, które części obrazu zostały zidentyfikowane jako należące do danej klasy, co pozwala na lokalizację obiektów w obrazach.</li>
</ul>
<p>Do pierwszej metody - wizualizacji aktywacji - użyjemy małej sieci, którą wytrenowaliśmy od podstaw na problemie klasyfikacji psy-vs-koty. W przypadku dwóch kolejnych metod użyjemy wstępnie wytrenowanego modelu Xception.</p>
<section id="wizualizacja-aktywacji-pośrednich" class="level4 page-columns page-full" data-number="14.2.0.1"><h4 data-number="14.2.0.1" class="anchored" data-anchor-id="wizualizacja-aktywacji-pośrednich">
<span class="header-section-number">14.2.0.1</span> Wizualizacja aktywacji pośrednich</h4>
<p>Wizualizacja pośrednich aktywacji polega na wyświetleniu wartości zwracanych przez różne warstwy konwolucji i łączenia w modelu, przy określonym wejściu (wyjście warstwy często nazywane jest jej aktywacją, wyjściem funkcji aktywacji). Daje to wgląd w to, jak dane wejściowe są rozkładane na różne filtry uczone przez sieć. Chcemy wizualizować mapy cech o trzech wymiarach: szerokości, wysokości i głębokości (kanały). Każdy kanał koduje względnie niezależne cechy, więc właściwym sposobem wizualizacji tych map cech jest niezależne wykreślenie zawartości każdego kanału jako obrazu 2D. Zacznijmy od załadowania modelu:</p>
<div class="cell">
<details open="" class="code-fold"><summary>Kod</summary><div class="sourceCode" id="cb30"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">model</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/keras/man/save_model_tf.html">load_model_tf</a></span><span class="op">(</span><span class="st">"models/convnet_from_scratch_with_augmentation.keras"</span><span class="op">)</span></span>
<span><span class="va">model</span></span></code><button title="Kopiuj do schowka" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>Model: "model"
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 input_1 (InputLayer)               [(None, 180, 180, 3)]           0           
 sequential (Sequential)            (None, 180, 180, 3)             0           
 rescaling (Rescaling)              (None, 180, 180, 3)             0           
 conv2d_4 (Conv2D)                  (None, 178, 178, 32)            896         
 max_pooling2d_3 (MaxPooling2D)     (None, 89, 89, 32)              0           
 conv2d_3 (Conv2D)                  (None, 87, 87, 64)              18496       
 max_pooling2d_2 (MaxPooling2D)     (None, 43, 43, 64)              0           
 conv2d_2 (Conv2D)                  (None, 41, 41, 128)             73856       
 max_pooling2d_1 (MaxPooling2D)     (None, 20, 20, 128)             0           
 conv2d_1 (Conv2D)                  (None, 18, 18, 256)             295168      
 max_pooling2d (MaxPooling2D)       (None, 9, 9, 256)               0           
 conv2d (Conv2D)                    (None, 7, 7, 256)               590080      
 flatten (Flatten)                  (None, 12544)                   0           
 dropout (Dropout)                  (None, 12544)                   0           
 dense (Dense)                      (None, 1)                       12545       
================================================================================
Total params: 991041 (3.78 MB)
Trainable params: 991041 (3.78 MB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________</code></pre>
</div>
</div>
<p>Następnie pobieramy obraz wejściowy - zdjęcie kota, które nie jest częścią obrazów, na których sieć była trenowana.</p>
<div class="cell">
<details open="" class="code-fold"><summary>Kod</summary><div class="sourceCode" id="cb32"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">img_path</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/keras/man/get_file.html">get_file</a></span><span class="op">(</span></span>
<span>  fname <span class="op">=</span> <span class="st">"cat.jpg"</span>,</span>
<span>  origin <span class="op">=</span> <span class="st">"https://img-datasets.s3.amazonaws.com/cat.jpg"</span><span class="op">)</span></span>
<span></span>
<span><span class="va">img_tensor</span> <span class="op">&lt;-</span> <span class="va">img_path</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu">tf_read_image</span><span class="op">(</span>resize <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">180</span>, <span class="fl">180</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="fu">display_image_tensor</span><span class="op">(</span><span class="va">img_tensor</span><span class="op">)</span></span></code><button title="Kopiuj do schowka" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output-display">
<div>
<figure class="figure"><p><img src="segmentation_files/figure-html/unnamed-chunk-21-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<p>Aby wyodrębnić mapy cech, które chcemy obejrzeć, stworzymy model Keras, który przyjmuje partie obrazów jako dane wejściowe i który wyprowadza aktywacje wszystkich warstw konwolucji.</p>
<div class="cell">
<details open="" class="code-fold"><summary>Kod</summary><div class="sourceCode" id="cb33"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">conv_layer_s3_classname</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/class.html">class</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/pkg/keras/man/layer_conv_2d.html">layer_conv_2d</a></span><span class="op">(</span><span class="cn">NULL</span>, <span class="fl">1</span>, <span class="fl">1</span><span class="op">)</span><span class="op">)</span><span class="op">[</span><span class="fl">1</span><span class="op">]</span></span>
<span><span class="va">pooling_layer_s3_classname</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/class.html">class</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/pkg/keras/man/layer_max_pooling_2d.html">layer_max_pooling_2d</a></span><span class="op">(</span><span class="cn">NULL</span><span class="op">)</span><span class="op">)</span><span class="op">[</span><span class="fl">1</span><span class="op">]</span></span>
<span></span>
<span><span class="va">is_conv_layer</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">x</span><span class="op">)</span> <span class="fu"><a href="https://rdrr.io/r/base/class.html">inherits</a></span><span class="op">(</span><span class="va">x</span>, <span class="va">conv_layer_s3_classname</span><span class="op">)</span></span>
<span><span class="va">is_pooling_layer</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">x</span><span class="op">)</span> <span class="fu"><a href="https://rdrr.io/r/base/class.html">inherits</a></span><span class="op">(</span><span class="va">x</span>, <span class="va">pooling_layer_s3_classname</span><span class="op">)</span></span>
<span></span>
<span><span class="va">layer_outputs</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span><span class="op">)</span></span>
<span><span class="kw">for</span> <span class="op">(</span><span class="va">layer</span> <span class="kw">in</span> <span class="va">model</span><span class="op">$</span><span class="va">layers</span><span class="op">)</span></span>
<span>  <span class="kw">if</span> <span class="op">(</span><span class="fu">is_conv_layer</span><span class="op">(</span><span class="va">layer</span><span class="op">)</span> <span class="op">||</span> <span class="fu">is_pooling_layer</span><span class="op">(</span><span class="va">layer</span><span class="op">)</span><span class="op">)</span></span>
<span>    <span class="va">layer_outputs</span><span class="op">[[</span><span class="va">layer</span><span class="op">$</span><span class="va">name</span><span class="op">]</span><span class="op">]</span> <span class="op">&lt;-</span> <span class="va">layer</span><span class="op">$</span><span class="va">output</span></span>
<span></span>
<span><span class="va">activation_model</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/keras/man/keras_model.html">keras_model</a></span><span class="op">(</span>inputs <span class="op">=</span> <span class="va">model</span><span class="op">$</span><span class="va">input</span>,</span>
<span>                                outputs <span class="op">=</span> <span class="va">layer_outputs</span><span class="op">)</span></span></code><button title="Kopiuj do schowka" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>Po podaniu obrazu wejściowego, model ten zwraca wartości aktywacji warstw w oryginalnym modelu, w postaci listy. Ten model ma jedno wejście i osiem wyjść: jedno wyjście na każdą aktywację warstwy.</p>
<div class="cell">
<details open="" class="code-fold"><summary>Kod</summary><div class="sourceCode" id="cb34"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">activations</span> <span class="op">&lt;-</span> <span class="va">activation_model</span> <span class="op">|&gt;</span> </span>
<span>  <span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span><span class="op">(</span><span class="va">img_tensor</span><span class="op">[</span><span class="va">tf</span><span class="op">$</span><span class="va">newaxis</span>,,,<span class="op">]</span><span class="op">)</span></span></code><button title="Kopiuj do schowka" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>1/1 - 0s - 69ms/epoch - 69ms/step</code></pre>
</div>
<details open="" class="code-fold"><summary>Kod</summary><div class="sourceCode" id="cb36"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/utils/str.html">str</a></span><span class="op">(</span><span class="va">activations</span><span class="op">)</span></span></code><button title="Kopiuj do schowka" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>List of 9
 $ conv2d_4       : num [1, 1:178, 1:178, 1:32] 0 0 0 0 0 0 0 0 0 0 ...
 $ max_pooling2d_3: num [1, 1:89, 1:89, 1:32] 0 0 0 0 0 0 0 0 0 0 ...
 $ conv2d_3       : num [1, 1:87, 1:87, 1:64] 0.0393 0.0651 0.0795 0.0466 0.0943 ...
 $ max_pooling2d_2: num [1, 1:43, 1:43, 1:64] 0.0651 0.0795 0.0961 0.0799 0.1202 ...
 $ conv2d_2       : num [1, 1:41, 1:41, 1:128] 0.1349 0.1584 0.1228 0.0913 0 ...
 $ max_pooling2d_1: num [1, 1:20, 1:20, 1:128] 0.16708 0.12279 0.00736 0 0 ...
 $ conv2d_1       : num [1, 1:18, 1:18, 1:256] 0 0 0 0 0 0 0 0 0 0 ...
 $ max_pooling2d  : num [1, 1:9, 1:9, 1:256] 0 0 0 0 0 0 0 0 0 0 ...
 $ conv2d         : num [1, 1:7, 1:7, 1:256] 0 0 0 0 0.102 ...</code></pre>
</div>
</div>
<p>Przyjrzyjmy się bliżej aktywacjom pierwszej warstwy.</p>
<div class="cell">
<details open="" class="code-fold"><summary>Kod</summary><div class="sourceCode" id="cb38"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">first_layer_activation</span> <span class="op">&lt;-</span> <span class="va">activations</span><span class="op">[[</span><span class="fu"><a href="https://rdrr.io/r/base/names.html">names</a></span><span class="op">(</span><span class="va">layer_outputs</span><span class="op">)</span><span class="op">[</span><span class="fl">1</span><span class="op">]</span><span class="op">]</span><span class="op">]</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/dim.html">dim</a></span><span class="op">(</span><span class="va">first_layer_activation</span><span class="op">)</span></span></code><button title="Kopiuj do schowka" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>[1]   1 178 178  32</code></pre>
</div>
</div>
<p>Jest to mapa funkcji o wymiarach 178 × 178 z 32 kanałami. Spróbujmy wykreślić trzeci kanał aktywacji pierwszej warstwy oryginalnego modelu (patrz <a href="#fig-seg9" class="quarto-xref">Rysunek&nbsp;<span>14.9</span></a>).</p>
<div class="cell">
<details open="" class="code-fold"><summary>Kod</summary><div class="sourceCode" id="cb40"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">plot_activations</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">x</span>, <span class="va">...</span><span class="op">)</span> <span class="op">{</span></span>
<span></span>
<span>  <span class="va">x</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/array.html">as.array</a></span><span class="op">(</span><span class="va">x</span><span class="op">)</span></span>
<span></span>
<span>  <span class="kw">if</span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="va">x</span><span class="op">)</span> <span class="op">==</span> <span class="fl">0</span><span class="op">)</span></span>
<span>      <span class="kw"><a href="https://rdrr.io/r/base/function.html">return</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/grDevices/as.raster.html">as.raster</a></span><span class="op">(</span><span class="st">"gray"</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span>  <span class="va">rotate</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">x</span><span class="op">)</span> <span class="fu"><a href="https://rdrr.io/r/base/t.html">t</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/apply.html">apply</a></span><span class="op">(</span><span class="va">x</span>, <span class="fl">2</span>, <span class="va">rev</span><span class="op">)</span><span class="op">)</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/graphics/image.html">image</a></span><span class="op">(</span><span class="fu">rotate</span><span class="op">(</span><span class="va">x</span><span class="op">)</span>, asp <span class="op">=</span> <span class="fl">1</span>, axes <span class="op">=</span> <span class="cn">FALSE</span>, useRaster <span class="op">=</span> <span class="cn">TRUE</span>,</span>
<span>        col <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/grDevices/palettes.html">terrain.colors</a></span><span class="op">(</span><span class="fl">256</span><span class="op">)</span>, <span class="va">...</span><span class="op">)</span></span>
<span><span class="op">}</span></span>
<span></span>
<span><span class="fu">plot_activations</span><span class="op">(</span><span class="va">first_layer_activation</span><span class="op">[</span>, , , <span class="fl">3</span><span class="op">]</span><span class="op">)</span></span></code><button title="Kopiuj do schowka" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output-display">
<div id="fig-seg9" class="quarto-figure quarto-figure-center quarto-float anchored">
<figure class="quarto-float quarto-float-fig figure"><div aria-describedby="fig-seg9-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="segmentation_files/figure-html/fig-seg9-1.png" class="img-fluid figure-img" width="672">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-seg9-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Rysunek&nbsp;14.9: Wykres wartości trzeciego kanału pierwszej warstwy aktywacji
</figcaption></figure>
</div>
</div>
</div>
<p>Kanał ten wydaje się kodować krawędzi ukośne - ale zauważmy, że nasze kanały mogą się różnić, ponieważ konkretne filtry uczone przez warstwy konwolucji nie są deterministyczne.</p>
<p>Wykreślmy teraz pełną wizualizację wszystkich aktywacji w sieci. Wyodrębnimy i wykreślimy każdy kanał w każdej z warstw aktywacji, a następnie ułożymy wyniki w jedną dużą siatkę, z kanałami ułożonymi obok siebie.</p>
<div class="cell">
<details open="" class="code-fold"><summary>Kod</summary><div class="sourceCode" id="cb41"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="kw">for</span> <span class="op">(</span><span class="va">layer_name</span> <span class="kw">in</span> <span class="fu"><a href="https://rdrr.io/r/base/names.html">names</a></span><span class="op">(</span><span class="va">layer_outputs</span><span class="op">)</span><span class="op">)</span> <span class="op">{</span></span>
<span>  <span class="va">layer_output</span> <span class="op">&lt;-</span> <span class="va">activations</span><span class="op">[[</span><span class="va">layer_name</span><span class="op">]</span><span class="op">]</span></span>
<span></span>
<span>  <span class="va">n_features</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/dim.html">dim</a></span><span class="op">(</span><span class="va">layer_output</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> <span class="fu"><a href="https://rdrr.io/r/utils/head.html">tail</a></span><span class="op">(</span><span class="fl">1</span><span class="op">)</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/graphics/par.html">par</a></span><span class="op">(</span>mfrow <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/grDevices/n2mfrow.html">n2mfrow</a></span><span class="op">(</span><span class="va">n_features</span>, asp <span class="op">=</span> <span class="fl">1.75</span><span class="op">)</span>,</span>
<span>      mar <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep</a></span><span class="op">(</span><span class="fl">.1</span>, <span class="fl">4</span><span class="op">)</span>, oma <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">0</span>, <span class="fl">1.5</span>, <span class="fl">0</span><span class="op">)</span><span class="op">)</span></span>
<span>  <span class="kw">for</span> <span class="op">(</span><span class="va">j</span> <span class="kw">in</span> <span class="fl">1</span><span class="op">:</span><span class="va">n_features</span><span class="op">)</span></span>
<span>    <span class="fu">plot_activations</span><span class="op">(</span><span class="va">layer_output</span><span class="op">[</span>, , , <span class="va">j</span><span class="op">]</span><span class="op">)</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/graphics/title.html">title</a></span><span class="op">(</span>main <span class="op">=</span> <span class="va">layer_name</span>, outer <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span>
<span><span class="op">}</span></span></code><button title="Kopiuj do schowka" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output-display">
<div>
<figure class="figure"><p><img src="segmentation_files/figure-html/unnamed-chunk-26-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
<div class="cell-output-display">
<div>
<figure class="figure"><p><img src="segmentation_files/figure-html/unnamed-chunk-26-2.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
<div class="cell-output-display">
<div>
<figure class="figure"><p><img src="segmentation_files/figure-html/unnamed-chunk-26-3.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
<div class="cell-output-display">
<div>
<figure class="figure"><p><img src="segmentation_files/figure-html/unnamed-chunk-26-4.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
<div class="cell-output-display">
<div>
<figure class="figure"><p><img src="segmentation_files/figure-html/unnamed-chunk-26-5.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
<div class="cell-output-display">
<div>
<figure class="figure"><p><img src="segmentation_files/figure-html/unnamed-chunk-26-6.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
<div class="cell-output-display">
<div>
<figure class="figure"><p><img src="segmentation_files/figure-html/unnamed-chunk-26-7.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
<div class="cell-output-display">
<div>
<figure class="figure"><p><img src="segmentation_files/figure-html/unnamed-chunk-26-8.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
<div class="cell-output-display">
<div>
<figure class="figure"><p><img src="segmentation_files/figure-html/unnamed-chunk-26-9.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<p>Należy tu zwrócić uwagę na kilka rzeczy:</p>
<ul>
<li>Pierwsza warstwa działa jako zbiór różnych detektorów krawędzi. Na tym etapie, aktywacje zachowują prawie wszystkie informacje obecne na początkowym obrazie.</li>
<li>W miarę zagłębiania się, aktywacje stają się coraz bardziej abstrakcyjne i mniej wizualnie interpretowalne. Zaczynają kodować pojęcia wyższego rzędu, takie jak “kocie ucho” czy “kocie oko”. Głębsze prezentacje niosą coraz mniej informacji o wizualnej zawartości obrazu, a coraz więcej informacji związanych z klasą obrazu.</li>
<li>Rozproszenie aktywacji rośnie wraz z głębokością warstwy: w pierwszej warstwie prawie wszystkie filtry są aktywowane przez obraz wejściowy, ale w kolejnych warstwach coraz więcej filtrów jest pustych. Oznacza to, że wzór zakodowany przez filtr nie występuje na obrazie wejściowym.</li>
</ul>
<p>Wykazaliśmy właśnie ważną, uniwersalną cechę reprezentacji uczonych przez głębokie sieci neuronowe: cechy wydobywane przez warstwę stają się coraz bardziej abstrakcyjne wraz z głębokością warstwy. Aktywacje wyższych warstw niosą coraz mniej informacji o konkretnym widzianym wejściu, a coraz więcej informacji o celu (w tym przypadku klasie obrazu: kot czy pies). Głęboka sieć neuronowa działa jak przebieg destylacji informacji, w którym surowe dane (w tym przypadku obrazy RGB) są wielokrotnie przekształcane w taki sposób, że nieistotne informacje są odfiltrowywane (np. specyficzny wygląd wizualny obrazu), a użyteczne informacje są eksponowane i udoskonalane.</p>
<div class="quarto-figure quarto-figure-center page-columns page-full">
<figure class="figure page-columns page-full"><div class="page-columns page-full"><p></p><div class="no-row-height column-margin column-container"><img src="https://media.giphy.com/media/l46CuDUhXNUx1Bm5G/giphy.gif" class="img-fluid quarto-figure quarto-figure-center figure-img" width="400"></div></div>
</figure>
</div>
<p>Jest to podobne do sposobu, w jaki ludzie i zwierzęta postrzegają świat: po obserwacji sceny przez kilka sekund człowiek może pamiętać, jakie abstrakcyjne obiekty były w niej obecne (rower, drzewo), ale może nie pamiętać konkretnego wyglądu tych obiektów. W rzeczywistości, gdybyśmy próbowali narysować z pamięci ogólny rower, istnieje prawdopodobieństwo, że nie udałoby się to nawet w najmniejszym stopniu, mimo że w swoim życiu widzieliśmy tysiące rowerów. Nasz mózg nauczył się całkowicie abstrahować od informacji wizualnych - przekształcać je w wysokopoziomowe koncepcje wizualne, jednocześnie odfiltrowując nieistotne szczegóły wizualne - co sprawia, że zapamiętanie wyglądu rzeczy wokół nas jest niezwykle trudne.</p>
</section><section id="wizualizacja-filtrów-sieci-splotowych" class="level4" data-number="14.2.0.2"><h4 data-number="14.2.0.2" class="anchored" data-anchor-id="wizualizacja-filtrów-sieci-splotowych">
<span class="header-section-number">14.2.0.2</span> Wizualizacja filtrów sieci splotowych</h4>
<p>Innym prostym sposobem na sprawdzenie filtrów wyuczonych przez sieci splotowe jest wyświetlenie wzorca wizualnego, na który każdy filtr ma reagować. Można to zrobić za pomocą spadku gradientu w przestrzeni wejściowej: zastosowanie spadku gradientu do wartości obrazu wejściowego sieci splotowej tak, aby zmaksymalizować odpowiedź określonego filtra, zaczynając od pustego obrazu wejściowego. Wynikowy obraz wejściowy będzie taki, na który wybrany filtr maksymalnie reaguje.</p>
<p>Spróbujmy to zrobić z filtrami modelu Xception, wytrenowanego na <em>ImageNet</em>. Proces jest prosty: zbudujemy funkcję straty, która maksymalizuje wartość danego filtra w danej warstwie konwolucji, a następnie użyjemy stochastycznego spadku gradientu, aby dopasować wartości obrazu wejściowego tak, by zmaksymalizować tę wartość aktywacji. Najpierw zainicjujmy model Xception, załadowany wagami wytrenowanymi na zbiorze danych <em>ImageNet</em>.</p>
<div class="cell">
<details open="" class="code-fold"><summary>Kod</summary><div class="sourceCode" id="cb42"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">model</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/keras/man/application_xception.html">application_xception</a></span><span class="op">(</span></span>
<span>  weights <span class="op">=</span> <span class="st">"imagenet"</span>,</span>
<span>  include_top <span class="op">=</span> <span class="cn">FALSE</span></span>
<span><span class="op">)</span></span></code><button title="Kopiuj do schowka" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>Interesują nas warstwy konwolucyjne modelu - Conv2D i SeparableConv2D. Musimy znać ich nazwy, aby móc pobrać ich dane wyjściowe. Wypiszmy ich nazwy, w kolejności głębokości.</p>
<div class="cell">
<details open="" class="code-fold"><summary>Kod</summary><div class="sourceCode" id="cb43"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="kw">for</span> <span class="op">(</span><span class="va">layer</span> <span class="kw">in</span> <span class="va">model</span><span class="op">$</span><span class="va">layers</span><span class="op">)</span></span>
<span> <span class="kw">if</span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/any.html">any</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/grep.html">grepl</a></span><span class="op">(</span><span class="st">"Conv2D"</span>, <span class="fu"><a href="https://rdrr.io/r/base/class.html">class</a></span><span class="op">(</span><span class="va">layer</span><span class="op">)</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span>
<span>   <span class="fu"><a href="https://rdrr.io/r/base/print.html">print</a></span><span class="op">(</span><span class="va">layer</span><span class="op">$</span><span class="va">name</span><span class="op">)</span></span></code><button title="Kopiuj do schowka" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>[1] "block1_conv1"
[1] "block1_conv2"
[1] "block2_sepconv1"
[1] "block2_sepconv2"
[1] "conv2d_23"
[1] "block3_sepconv1"
[1] "block3_sepconv2"
[1] "conv2d_24"
[1] "block4_sepconv1"
[1] "block4_sepconv2"
[1] "conv2d_25"
[1] "block5_sepconv1"
[1] "block5_sepconv2"
[1] "block5_sepconv3"
[1] "block6_sepconv1"
[1] "block6_sepconv2"
[1] "block6_sepconv3"
[1] "block7_sepconv1"
[1] "block7_sepconv2"
[1] "block7_sepconv3"
[1] "block8_sepconv1"
[1] "block8_sepconv2"
[1] "block8_sepconv3"
[1] "block9_sepconv1"
[1] "block9_sepconv2"
[1] "block9_sepconv3"
[1] "block10_sepconv1"
[1] "block10_sepconv2"
[1] "block10_sepconv3"
[1] "block11_sepconv1"
[1] "block11_sepconv2"
[1] "block11_sepconv3"
[1] "block12_sepconv1"
[1] "block12_sepconv2"
[1] "block12_sepconv3"
[1] "block13_sepconv1"
[1] "block13_sepconv2"
[1] "conv2d_26"
[1] "block14_sepconv1"
[1] "block14_sepconv2"</code></pre>
</div>
</div>
<p>Zauważmy, że separowalne warstwy <code>conv2D</code> tutaj są nazwane <code>block6_sepconv1</code>, <code>block7_sepconv2</code>, i tak dalej. Xception jest zorganizowany w bloki, z których każdy zawiera kilka warstw konwolucyjnych. Teraz stwórzmy drugi model, który zwraca wyjście konkretnej warstwy - model ekstraktora cech. Ponieważ nasz model jest modelem zbudowanym za pomocą API, jest on inspekcyjny: możemy zapytać o wyjście jednej z jego warstw i ponownie użyć go w nowym modelu. Nie trzeba kopiować całego kodu Xception.</p>
<div class="cell">
<details open="" class="code-fold"><summary>Kod</summary><div class="sourceCode" id="cb45"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">layer_name</span> <span class="op">&lt;-</span> <span class="st">"block3_sepconv1"</span></span>
<span><span class="va">layer</span> <span class="op">&lt;-</span> <span class="va">model</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> <span class="fu">keras</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/keras/man/get_layer.html">get_layer</a></span><span class="op">(</span>name <span class="op">=</span> <span class="va">layer_name</span><span class="op">)</span></span>
<span><span class="va">feature_extractor</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/keras/man/keras_model.html">keras_model</a></span><span class="op">(</span>inputs <span class="op">=</span> <span class="va">model</span><span class="op">$</span><span class="va">input</span>,</span>
<span>                                 outputs <span class="op">=</span> <span class="va">layer</span><span class="op">$</span><span class="va">output</span><span class="op">)</span></span></code><button title="Kopiuj do schowka" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>Aby użyć ekstraktora, wystarczy wywołać go na jakichś danych wejściowych (zauważmy, że Xception wymaga, aby dane wejściowe były wstępnie przetworzone za pomocą funkcji <code><a href="https://rdrr.io/pkg/keras/man/application_xception.html">xception_preprocess_input()</a></code>).</p>
<div class="cell">
<details open="" class="code-fold"><summary>Kod</summary><div class="sourceCode" id="cb46"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">activation</span> <span class="op">&lt;-</span> <span class="va">img_tensor</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>   <span class="va">.</span><span class="op">[</span><span class="va">tf</span><span class="op">$</span><span class="va">newaxis</span>, , , <span class="op">]</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>   <span class="fu"><a href="https://rdrr.io/pkg/keras/man/application_xception.html">xception_preprocess_input</a></span><span class="op">(</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>   <span class="fu">feature_extractor</span><span class="op">(</span><span class="op">)</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/str.html">str</a></span><span class="op">(</span><span class="va">activation</span><span class="op">)</span></span></code><button title="Kopiuj do schowka" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>&lt;tf.Tensor: shape=(1, 44, 44, 256), dtype=float32, numpy=…&gt;</code></pre>
</div>
</div>
<p>Użyjmy naszego modelu ekstraktora cech do zdefiniowania funkcji, która zwraca wartość skalarną określającą, jak bardzo dany obraz wejściowy “aktywuje” dany filtr w warstwie. Jest to “funkcja straty”, którą będziemy maksymalizować podczas procesu wznoszenia gradientu:</p>
<div class="cell">
<details open="" class="code-fold"><summary>Kod</summary><div class="sourceCode" id="cb48"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">compute_loss</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">image</span>, <span class="va">filter_index</span><span class="op">)</span> <span class="op">{</span></span>
<span>  <span class="va">activation</span> <span class="op">&lt;-</span> <span class="fu">feature_extractor</span><span class="op">(</span><span class="va">image</span><span class="op">)</span></span>
<span></span>
<span>  <span class="va">filter_index</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/tensorflow/man/as_tensor.html">as_tensor</a></span><span class="op">(</span><span class="va">filter_index</span>, <span class="st">"int32"</span><span class="op">)</span></span>
<span>  <span class="va">filter_activation</span> <span class="op">&lt;-</span></span>
<span>      <span class="va">activation</span><span class="op">[</span>, , , <span class="va">filter_index</span>, style <span class="op">=</span> <span class="st">"python"</span><span class="op">]</span> <span class="co"># aby program wiedział, że kodowanie pierwszego indeksu zaczyna się od 0 - jak w Python</span></span>
<span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">filter_activation</span><span class="op">[</span>, <span class="fl">3</span><span class="op">:</span><span class="op">-</span><span class="fl">3</span>, <span class="fl">3</span><span class="op">:</span><span class="op">-</span><span class="fl">3</span><span class="op">]</span><span class="op">)</span></span>
<span><span class="op">}</span></span></code><button title="Kopiuj do schowka" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>Ustawmy funkcję krokową gradientu zstępującego, korzystając z funkcji <code>GradientTape()</code>. Nieoczywistą sztuczką pomagającą w płynnym przebiegu procesu spadku gradientu jest normalizacja tensora gradientu poprzez podzielenie go przez jego normę L2 (pierwiastek kwadratowy ze średniej kwadratowej wartości w tensorze). Dzięki temu wielkość aktualizacji obrazu wejściowego jest zawsze w tym samym zakresie.</p>
<div class="cell">
<details open="" class="code-fold"><summary>Kod</summary><div class="sourceCode" id="cb49"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">gradient_ascent_step</span> <span class="op">&lt;-</span></span>
<span>  <span class="kw">function</span><span class="op">(</span><span class="va">image</span>, <span class="va">filter_index</span>, <span class="va">learning_rate</span><span class="op">)</span> <span class="op">{</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/r/base/with.html">with</a></span><span class="op">(</span><span class="va">tf</span><span class="op">$</span><span class="fu">GradientTape</span><span class="op">(</span><span class="op">)</span> <span class="op"><a href="https://rstudio.github.io/reticulate/reference/with-as-operator.html">%as%</a></span> <span class="va">tape</span>, <span class="op">{</span></span>
<span>      <span class="va">tape</span><span class="op">$</span><span class="fu">watch</span><span class="op">(</span><span class="va">image</span><span class="op">)</span></span>
<span>      <span class="va">loss</span> <span class="op">&lt;-</span> <span class="fu">compute_loss</span><span class="op">(</span><span class="va">image</span>, <span class="va">filter_index</span><span class="op">)</span></span>
<span>    <span class="op">}</span><span class="op">)</span></span>
<span>    <span class="va">grads</span> <span class="op">&lt;-</span> <span class="va">tape</span><span class="op">$</span><span class="fu">gradient</span><span class="op">(</span><span class="va">loss</span>, <span class="va">image</span><span class="op">)</span></span>
<span>    <span class="va">grads</span> <span class="op">&lt;-</span> <span class="va">tf</span><span class="op">$</span><span class="va">math</span><span class="op">$</span><span class="fu">l2_normalize</span><span class="op">(</span><span class="va">grads</span><span class="op">)</span></span>
<span>    <span class="va">image</span> <span class="op">+</span> <span class="op">(</span><span class="va">learning_rate</span> <span class="op">*</span> <span class="va">grads</span><span class="op">)</span></span>
<span>  <span class="op">}</span></span></code><button title="Kopiuj do schowka" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>Teraz mamy już wszystkie elementy. Połączmy je w funkcję R, która pobiera jako dane wejściowe nazwę warstwy i indeks filtra i zwraca tensor reprezentujący wzór, który maksymalizuje aktywację określonego filtra. Zauważmy, że użyjemy funkcji <code><a href="https://rdrr.io/pkg/tensorflow/man/tf_function.html">tf_function()</a></code>, aby przyspieszyć działanie.</p>
<div class="cell">
<details open="" class="code-fold"><summary>Kod</summary><div class="sourceCode" id="cb50"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="va">img_width</span>, <span class="va">img_height</span><span class="op">)</span> <span class="op"><a href="https://rdrr.io/pkg/zeallot/man/operator.html">%&lt;-%</a></span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">200</span>, <span class="fl">200</span><span class="op">)</span></span>
<span></span>
<span><span class="va">generate_filter_pattern</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/tensorflow/man/tf_function.html">tf_function</a></span><span class="op">(</span><span class="kw">function</span><span class="op">(</span><span class="va">filter_index</span><span class="op">)</span> <span class="op">{</span></span>
<span>  <span class="va">iterations</span> <span class="op">&lt;-</span> <span class="fl">30</span></span>
<span>  <span class="va">learning_rate</span> <span class="op">&lt;-</span> <span class="fl">10</span></span>
<span>  <span class="va">image</span> <span class="op">&lt;-</span> <span class="va">tf</span><span class="op">$</span><span class="va">random</span><span class="op">$</span><span class="fu">uniform</span><span class="op">(</span></span>
<span>    minval <span class="op">=</span> <span class="fl">0.4</span>, maxval <span class="op">=</span> <span class="fl">0.6</span>,</span>
<span>    shape <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/pkg/tensorflow/man/shape.html">shape</a></span><span class="op">(</span><span class="fl">1</span>, <span class="va">img_width</span>, <span class="va">img_height</span>, <span class="fl">3</span><span class="op">)</span></span>
<span>  <span class="op">)</span></span>
<span></span>
<span>  <span class="kw">for</span> <span class="op">(</span><span class="va">i</span> <span class="kw">in</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq</a></span><span class="op">(</span><span class="va">iterations</span><span class="op">)</span><span class="op">)</span></span>
<span>      <span class="va">image</span> <span class="op">&lt;-</span> <span class="fu">gradient_ascent_step</span><span class="op">(</span><span class="va">image</span>, <span class="va">filter_index</span>, <span class="va">learning_rate</span><span class="op">)</span></span>
<span>  <span class="va">image</span><span class="op">[</span><span class="fl">1</span>, , , <span class="op">]</span></span>
<span><span class="op">}</span><span class="op">)</span></span></code><button title="Kopiuj do schowka" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>Wynikowy tensor obrazu jest tablicą zmiennoprzecinkową o kształcie (200, 200, 3), z wartościami, które nie mogą być liczbami całkowitymi z zakresu [0, 255]. Dlatego też musimy poddać ten tensor postprocessingowi, aby przekształcić go w obraz możliwy do wyświetlenia. Zrobimy to za pomocą operacji na tensorach i zawiniemy w <code><a href="https://rdrr.io/pkg/tensorflow/man/tf_function.html">tf_function()</a></code>, aby również przyspieszyć.</p>
<div class="cell">
<details open="" class="code-fold"><summary>Kod</summary><div class="sourceCode" id="cb51"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">deprocess_image</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/tensorflow/man/tf_function.html">tf_function</a></span><span class="op">(</span><span class="kw">function</span><span class="op">(</span><span class="va">image</span>, <span class="va">crop</span> <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span> <span class="op">{</span></span>
<span>  <span class="va">image</span> <span class="op">&lt;-</span> <span class="va">image</span> <span class="op">-</span> <span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">image</span><span class="op">)</span></span>
<span>  <span class="va">image</span> <span class="op">&lt;-</span> <span class="va">image</span> <span class="op">/</span> <span class="va">tf</span><span class="op">$</span><span class="va">math</span><span class="op">$</span><span class="fu">reduce_std</span><span class="op">(</span><span class="va">image</span><span class="op">)</span></span>
<span>  <span class="va">image</span> <span class="op">&lt;-</span> <span class="op">(</span><span class="va">image</span> <span class="op">*</span> <span class="fl">64</span><span class="op">)</span> <span class="op">+</span> <span class="fl">128</span></span>
<span>  <span class="va">image</span> <span class="op">&lt;-</span> <span class="va">tf</span><span class="op">$</span><span class="fu">clip_by_value</span><span class="op">(</span><span class="va">image</span>, <span class="fl">0</span>, <span class="fl">255</span><span class="op">)</span></span>
<span>  <span class="kw">if</span><span class="op">(</span><span class="va">crop</span><span class="op">)</span></span>
<span>    <span class="va">image</span> <span class="op">&lt;-</span> <span class="va">image</span><span class="op">[</span><span class="fl">26</span><span class="op">:</span><span class="op">-</span><span class="fl">26</span>, <span class="fl">26</span><span class="op">:</span><span class="op">-</span><span class="fl">26</span>, <span class="op">]</span></span>
<span>  <span class="va">image</span></span>
<span><span class="op">}</span><span class="op">)</span></span>
<span></span>
<span><span class="fu">generate_filter_pattern</span><span class="op">(</span>filter_index <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/pkg/tensorflow/man/as_tensor.html">as_tensor</a></span><span class="op">(</span><span class="fl">2L</span><span class="op">)</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span> <span class="fu">deprocess_image</span><span class="op">(</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu">display_image_tensor</span><span class="op">(</span><span class="op">)</span></span></code><button title="Kopiuj do schowka" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output-display">
<div>
<figure class="figure"><p><img src="segmentation_files/figure-html/unnamed-chunk-34-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<p>Zauważmy, że złożyliśmy tutaj <code>filter_index</code> z <code><a href="https://rdrr.io/pkg/tensorflow/man/as_tensor.html">as_tensor()</a></code>. Robimy to, ponieważ <code>tf_funkcja()</code> kompiluje oddzielną zoptymalizowaną funkcję dla każdego unikalnego sposobu jej wywoływana, a różne stałe liczą się jako unikalna sygnatura wywołania. Wygląda na to, że trzeci filtr w warstwie <code>block3_sepconv1</code> reaguje na wzór poziomych linii, nieco przypominający wodę.</p>
<div class="cell">
<details open="" class="code-fold"><summary>Kod</summary><div class="sourceCode" id="cb52"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/par.html">par</a></span><span class="op">(</span>mfrow <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">8</span>, <span class="fl">8</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="kw">for</span> <span class="op">(</span><span class="va">i</span> <span class="kw">in</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">63</span><span class="op">)</span><span class="op">)</span> <span class="op">{</span></span>
<span>  <span class="fu">generate_filter_pattern</span><span class="op">(</span>filter_index <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/pkg/tensorflow/man/as_tensor.html">as_tensor</a></span><span class="op">(</span><span class="va">i</span><span class="op">)</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>    <span class="fu">deprocess_image</span><span class="op">(</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>    <span class="fu">display_image_tensor</span><span class="op">(</span>plot_margins <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep</a></span><span class="op">(</span><span class="fl">.1</span>, <span class="fl">4</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="op">}</span></span></code><button title="Kopiuj do schowka" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output-display">
<div id="fig-seg11" class="quarto-figure quarto-figure-center quarto-float anchored">
<figure class="quarto-float quarto-float-fig figure"><div aria-describedby="fig-seg11-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="segmentation_files/figure-html/fig-seg11-1.png" class="img-fluid figure-img" width="672">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-seg11-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Rysunek&nbsp;14.10: Kilka wzorów filtrów dla warstw <code>block2_sepconv1</code>, <code>block4_sepconv1</code> i <code>block8_sepconv1</code>
</figcaption></figure>
</div>
</div>
</div>
<p>Te wizualizacje filtrów (patrz <a href="#fig-seg11" class="quarto-xref">Rysunek&nbsp;<span>14.10</span></a>) mówią wiele o tym, jak warstwy sieci splotowej widzą świat: każda warstwa w sieci splotowej uczy się zbioru filtrów w taki sposób, że jej dane wejściowe mogą być wyrażone jako kombinacja filtrów. Jest to podobne do tego, jak transformata Fouriera rozkłada sygnały na funkcje trygonometryczne. Filtry w tych blokach filtrów sieci splotowej stają się coraz bardziej złożone i wyrafinowane, gdy zagłębiamy się w model:</p>
<ul>
<li>Filtry z pierwszych warstw w modelu kodują proste krawędzie kierunkowe i kolory (lub kolorowe krawędzie, w niektórych przypadkach).</li>
<li>Filtry z warstw położonych nieco dalej w górę stosu, takich jak <code>block4_sepconv1</code>, kodują proste tekstury wykonane z kombinacji krawędzi i kolorów.</li>
<li>Filtry z wyższych warstw zaczynają przypominać tekstury występujące w naturalnych obrazach: pióra, oczy, liście i tak dalej.</li>
</ul></section><section id="wizualizacja-map-ciepła-aktywacji-klasowych" class="level4 page-columns page-full" data-number="14.2.0.3"><h4 data-number="14.2.0.3" class="anchored" data-anchor-id="wizualizacja-map-ciepła-aktywacji-klasowych">
<span class="header-section-number">14.2.0.3</span> Wizualizacja map ciepła aktywacji klasowych</h4>
<p>Przedstawimy jeszcze jedną technikę wizualizacji - przydatną do zrozumienia, które części danego obrazu doprowadziły sieci splotowe do ostatecznej decyzji klasyfikacyjnej. Jest to pomocne w “debugowaniu” procesu decyzyjnego sieci konwolucyjnych, szczególnie w przypadku błędu klasyfikacji (problem nazywany interpretacją modelu). Może to również pozwolić na zlokalizowanie konkretnych obiektów na obrazie.</p>
<div class="quarto-figure quarto-figure-center page-columns page-full">
<figure class="figure page-columns page-full"><div class="page-columns page-full"><p></p><div class="no-row-height column-margin column-container"><img src="https://media.giphy.com/media/VFSexwZVYCeuDwqRF5/giphy.gif" class="img-fluid quarto-figure quarto-figure-center figure-img" width="400"></div></div>
</figure>
</div>
<p>Ta ogólna kategoria technik nazywana jest wizualizacją mapy aktywacji klas (ang. <em>Class Activation Map -</em> CAM) i polega na tworzeniu map ciepła aktywacji klas na obrazach wejściowych. Mapa ciepła aktywacji klas to dwuwymiarowa siatka wyników związanych z konkretną klasą wyjściową, obliczona dla każdej lokalizacji na dowolnym obrazie wejściowym, wskazująca jak ważna jest każda lokalizacja w odniesieniu do rozważanej klasy. Na przykład, biorąc pod uwagę obrazek wprowadzony do sieci splotowej psy-vs-koty, wizualizacja CAM pozwoli nam wygenerować mapę ciepła dla klasy “kot”, wskazując jak podobne do kotów są różne części obrazka, a także mapę ciepła dla klasy “pies”, wskazując jak podobne do psów są części obrazka.</p>
<p>Konkretna implementacja, której użyjemy, to ta opisana w artykule zatytułowanym “Grad-CAM: Visual Explanations from Deep Networks via Gradient-based Localization”<span class="citation" data-cites="selvarajuGradCAMVisualExplanations2020">(<a href="references.html#ref-selvarajuGradCAMVisualExplanations2020" role="doc-biblioref">Selvaraju i in. 2020</a>)</span>.</p>
<p>Grad-CAM polega na tym, że bierzemy wyjściową mapę cech warstwy konwolucji, daną obrazowi wejściowemu, i ważymy każdy kanał w tej mapie cech przez gradient klasy względem kanału. Intuicyjnie, jednym ze sposobów zrozumienia tej sztuczki jest wyobrażenie sobie, że ważymy przestrzenną mapę “jak intensywnie obraz wejściowy aktywuje różne kanały” przez “jak ważny jest każdy kanał w odniesieniu do klasy”, w wyniku czego otrzymujemy przestrzenną mapę “jak intensywnie obraz wejściowy aktywuje klasę”. Zademonstrujmy tę technikę przy użyciu wstępnie wytrenowanego modelu Xception.</p>
<div class="cell">
<details open="" class="code-fold"><summary>Kod</summary><div class="sourceCode" id="cb53"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">model</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/keras/man/application_xception.html">application_xception</a></span><span class="op">(</span>weights <span class="op">=</span> <span class="st">"imagenet"</span><span class="op">)</span></span></code><button title="Kopiuj do schowka" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>Rozważmy obraz dwóch słoni afrykańskich pokazany na <a href="#fig-seg12" class="quarto-xref">Rysunek&nbsp;<span>14.11</span></a>. Przekształćmy ten obraz w coś, co model Xception może odczytać: model był trenowany na obrazach o rozmiarze 299 × 299, wstępnie przetworzonych zgodnie z kilkoma regułami, które są spakowane w funkcji użytkowej <code><a href="https://rdrr.io/pkg/keras/man/application_xception.html">xception_preprocess_input()</a></code>.</p>
<div class="cell">
<details open="" class="code-fold"><summary>Kod</summary><div class="sourceCode" id="cb54"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">img_path</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/keras/man/get_file.html">get_file</a></span><span class="op">(</span></span>
<span>  fname <span class="op">=</span> <span class="st">"elephant.jpg"</span>,</span>
<span>  origin <span class="op">=</span> <span class="st">"https://img-datasets.s3.amazonaws.com/elephant.jpg"</span><span class="op">)</span></span>
<span><span class="va">img_tensor</span> <span class="op">&lt;-</span> <span class="fu">tf_read_image</span><span class="op">(</span><span class="va">img_path</span>, resize <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">299</span>, <span class="fl">299</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">preprocessed_img</span> <span class="op">&lt;-</span> <span class="va">img_tensor</span><span class="op">[</span><span class="va">tf</span><span class="op">$</span><span class="va">newaxis</span>, , , <span class="op">]</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://rdrr.io/pkg/keras/man/application_xception.html">xception_preprocess_input</a></span><span class="op">(</span><span class="op">)</span></span>
<span></span>
<span><span class="fu">display_image_tensor</span><span class="op">(</span><span class="va">img_tensor</span><span class="op">)</span></span></code><button title="Kopiuj do schowka" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output-display">
<div id="fig-seg12" class="quarto-figure quarto-figure-center quarto-float anchored">
<figure class="quarto-float quarto-float-fig figure"><div aria-describedby="fig-seg12-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="segmentation_files/figure-html/fig-seg12-1.png" class="img-fluid figure-img" width="672">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-seg12-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Rysunek&nbsp;14.11: Przykładowy obraz słoni
</figcaption></figure>
</div>
</div>
</div>
<p>Możemy teraz uruchomić wstępnie wytrenowaną sieć na obrazie i zdekodować jej wektor predykcji z powrotem do formatu czytelnego dla człowieka:</p>
<div class="cell">
<details open="" class="code-fold"><summary>Kod</summary><div class="sourceCode" id="cb55"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">preds</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span><span class="op">(</span><span class="va">model</span>, <span class="va">preprocessed_img</span><span class="op">)</span></span></code><button title="Kopiuj do schowka" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>1/1 - 1s - 517ms/epoch - 517ms/step</code></pre>
</div>
<details open="" class="code-fold"><summary>Kod</summary><div class="sourceCode" id="cb57"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/utils/str.html">str</a></span><span class="op">(</span><span class="va">preds</span><span class="op">)</span></span></code><button title="Kopiuj do schowka" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code> num [1, 1:1000] 5.51e-06 2.75e-05 1.73e-05 1.19e-05 1.15e-05 ...</code></pre>
</div>
<details open="" class="code-fold"><summary>Kod</summary><div class="sourceCode" id="cb59"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/pkg/keras/man/imagenet_decode_predictions.html">imagenet_decode_predictions</a></span><span class="op">(</span><span class="va">preds</span>, top<span class="op">=</span><span class="fl">3</span><span class="op">)</span><span class="op">[[</span><span class="fl">1</span><span class="op">]</span><span class="op">]</span></span></code><button title="Kopiuj do schowka" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>  class_name class_description      score
1  n02504458  African_elephant 0.90519828
2  n01871265            tusker 0.05259836
3  n02504013   Indian_elephant 0.01615973</code></pre>
</div>
</div>
<p>Trzy najlepsze klasy przewidywane dla tego obrazu to:</p>
<ul>
<li>Słoń afrykański (z 90% prawdopodobieństwem)</li>
<li>Tusker (z 5% prawdopodobieństwem)</li>
<li>Słoń indyjski (z niemal 2% prawdopodobieństwem)</li>
</ul>
<p>Sieć rozpoznała obraz jako zawierający nieokreśloną ilość słoni afrykańskich. Wpisem w wektorze predykcji, który został maksymalnie aktywowany, jest wpis odpowiadający klasie “słoń afrykański”, o indeksie 387:</p>
<div class="cell">
<details open="" class="code-fold"><summary>Kod</summary><div class="sourceCode" id="cb61"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/which.min.html">which.max</a></span><span class="op">(</span><span class="va">preds</span><span class="op">[</span><span class="fl">1</span>, <span class="op">]</span><span class="op">)</span></span></code><button title="Kopiuj do schowka" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>[1] 387</code></pre>
</div>
</div>
<p>Aby zwizualizować, które części obrazu są najbardziej podobne do afrykańskich słoni, skonfigurujmy proces Grad-CAM. Najpierw tworzymy model, który mapuje obraz wejściowy na aktywacje ostatniej warstwy konwolucyjnej.</p>
<div class="cell">
<details open="" class="code-fold"><summary>Kod</summary><div class="sourceCode" id="cb63"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">last_conv_layer_name</span> <span class="op">&lt;-</span> <span class="st">"block14_sepconv2_act"</span></span>
<span><span class="va">classifier_layer_names</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"avg_pool"</span>, <span class="st">"predictions"</span><span class="op">)</span></span>
<span><span class="va">last_conv_layer</span> <span class="op">&lt;-</span> <span class="va">model</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> <span class="fu"><a href="https://rdrr.io/pkg/keras/man/get_layer.html">get_layer</a></span><span class="op">(</span><span class="va">last_conv_layer_name</span><span class="op">)</span></span>
<span><span class="va">last_conv_layer_model</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/keras/man/keras_model.html">keras_model</a></span><span class="op">(</span><span class="va">model</span><span class="op">$</span><span class="va">inputs</span>,</span>
<span>                                     <span class="va">last_conv_layer</span><span class="op">$</span><span class="va">output</span><span class="op">)</span></span></code><button title="Kopiuj do schowka" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>Po drugie, tworzymy model, który odwzorowuje aktywacje ostatniej warstwy konwolucyjnej na końcowe predykcje klas.</p>
<div class="cell">
<details open="" class="code-fold"><summary>Kod</summary><div class="sourceCode" id="cb64"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">classifier_input</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/keras/man/layer_input.html">layer_input</a></span><span class="op">(</span>batch_shape <span class="op">=</span> <span class="va">last_conv_layer</span><span class="op">$</span><span class="va">output</span><span class="op">$</span><span class="va">shape</span><span class="op">)</span></span>
<span></span>
<span><span class="va">x</span> <span class="op">&lt;-</span> <span class="va">classifier_input</span></span>
<span><span class="kw">for</span> <span class="op">(</span><span class="va">layer_name</span> <span class="kw">in</span> <span class="va">classifier_layer_names</span><span class="op">)</span></span>
<span> <span class="va">x</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/keras/man/get_layer.html">get_layer</a></span><span class="op">(</span><span class="va">model</span>, <span class="va">layer_name</span><span class="op">)</span><span class="op">(</span><span class="va">x</span><span class="op">)</span></span>
<span></span>
<span><span class="va">classifier_model</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/keras/man/keras_model.html">keras_model</a></span><span class="op">(</span><span class="va">classifier_input</span>, <span class="va">x</span><span class="op">)</span></span></code><button title="Kopiuj do schowka" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>Następnie obliczamy gradient najwyższej przewidywanej klasy dla naszego obrazu wejściowego w odniesieniu do aktywacji ostatniej warstwy konwolucji.</p>
<div class="cell">
<details open="" class="code-fold"><summary>Kod</summary><div class="sourceCode" id="cb65"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/with.html">with</a></span> <span class="op">(</span><span class="va">tf</span><span class="op">$</span><span class="fu">GradientTape</span><span class="op">(</span><span class="op">)</span> <span class="op"><a href="https://rstudio.github.io/reticulate/reference/with-as-operator.html">%as%</a></span> <span class="va">tape</span>, <span class="op">{</span></span>
<span>  <span class="va">last_conv_layer_output</span> <span class="op">&lt;-</span> <span class="fu">last_conv_layer_model</span><span class="op">(</span><span class="va">preprocessed_img</span><span class="op">)</span></span>
<span>  <span class="va">tape</span><span class="op">$</span><span class="fu">watch</span><span class="op">(</span><span class="va">last_conv_layer_output</span><span class="op">)</span></span>
<span>  <span class="va">preds</span> <span class="op">&lt;-</span> <span class="fu">classifier_model</span><span class="op">(</span><span class="va">last_conv_layer_output</span><span class="op">)</span></span>
<span>  <span class="va">top_pred_index</span> <span class="op">&lt;-</span> <span class="va">tf</span><span class="op">$</span><span class="fu">argmax</span><span class="op">(</span><span class="va">preds</span><span class="op">[</span><span class="fl">1</span>, <span class="op">]</span><span class="op">)</span></span>
<span>  <span class="va">top_class_channel</span> <span class="op">&lt;-</span> <span class="va">preds</span><span class="op">[</span>, <span class="va">top_pred_index</span>, style <span class="op">=</span> <span class="st">"python"</span><span class="op">]</span></span>
<span><span class="op">}</span><span class="op">)</span></span>
<span></span>
<span><span class="va">grads</span> <span class="op">&lt;-</span> <span class="va">tape</span><span class="op">$</span><span class="fu">gradient</span><span class="op">(</span><span class="va">top_class_channel</span>, <span class="va">last_conv_layer_output</span><span class="op">)</span></span></code><button title="Kopiuj do schowka" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>Teraz zastosujemy łączenie i ważenie ważności do tensora gradientu, aby uzyskać naszą mapę ciepła aktywacji klas.</p>
<div class="cell">
<details open="" class="code-fold"><summary>Kod</summary><div class="sourceCode" id="cb66"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">pooled_grads</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">grads</span>, axis <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">1</span>,<span class="fl">2</span>,<span class="fl">3</span><span class="op">)</span>, keepdims <span class="op">=</span> <span class="cn">T</span><span class="op">)</span></span>
<span><span class="va">heatmap</span> <span class="op">&lt;-</span> <span class="op">(</span><span class="va">last_conv_layer_output</span> <span class="op">*</span> <span class="va">pooled_grads</span><span class="op">)</span> <span class="op">|&gt;</span> </span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span>axis <span class="op">=</span> <span class="op">-</span><span class="fl">1</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="va">.</span><span class="op">[</span><span class="fl">1</span>,,<span class="op">]</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/par.html">par</a></span><span class="op">(</span>mar <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">0</span>, <span class="fl">0</span>, <span class="fl">0</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="fu">plot_activations</span><span class="op">(</span><span class="va">heatmap</span><span class="op">)</span></span></code><button title="Kopiuj do schowka" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output-display">
<div>
<figure class="figure"><p><img src="segmentation_files/figure-html/unnamed-chunk-43-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<p>Na koniec, nałóżmy mapę ciepła aktywacji na oryginalny obraz. Wycinamy wartości mapy ciepła do palety kolorów, a następnie konwertujemy do obiektu rastrowego R. Zwróćmy uwagę, że upewniliśmy się, że przekazaliśmy <code>alfa = .4</code> do palety, tak abyśmy nadal widzieli oryginalny obraz, gdy nałożymy na niego mapę ciepła (Zobacz <a href="#fig-seg13" class="quarto-xref">Rysunek&nbsp;<span>14.12</span></a>).</p>
<div class="cell">
<details open="" class="code-fold"><summary>Kod</summary><div class="sourceCode" id="cb67"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">pal</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/grDevices/palettes.html">hcl.colors</a></span><span class="op">(</span><span class="fl">256</span>, palette <span class="op">=</span> <span class="st">"Spectral"</span>, alpha <span class="op">=</span> <span class="fl">.4</span>, rev <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span>
<span><span class="va">heatmap</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/array.html">as.array</a></span><span class="op">(</span><span class="va">heatmap</span><span class="op">)</span></span>
<span><span class="va">heatmap</span><span class="op">[</span><span class="op">]</span> <span class="op">&lt;-</span> <span class="va">pal</span><span class="op">[</span><span class="fu"><a href="https://rdrr.io/r/base/cut.html">cut</a></span><span class="op">(</span><span class="va">heatmap</span>, <span class="fl">256</span><span class="op">)</span><span class="op">]</span></span>
<span><span class="va">heatmap</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/grDevices/as.raster.html">as.raster</a></span><span class="op">(</span><span class="va">heatmap</span><span class="op">)</span></span>
<span></span>
<span><span class="va">img</span> <span class="op">&lt;-</span> <span class="fu">tf_read_image</span><span class="op">(</span><span class="va">img_path</span>, resize <span class="op">=</span> <span class="cn">NULL</span><span class="op">)</span></span>
<span><span class="fu">display_image_tensor</span><span class="op">(</span><span class="va">img</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/rasterImage.html">rasterImage</a></span><span class="op">(</span><span class="va">heatmap</span>, <span class="fl">0</span>, <span class="fl">0</span>, <span class="fu"><a href="https://rdrr.io/r/base/nrow.html">ncol</a></span><span class="op">(</span><span class="va">img</span><span class="op">)</span>, <span class="fu"><a href="https://rdrr.io/r/base/nrow.html">nrow</a></span><span class="op">(</span><span class="va">img</span><span class="op">)</span>, interpolate <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span></span></code><button title="Kopiuj do schowka" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output-display">
<div id="fig-seg13" class="quarto-figure quarto-figure-center quarto-float anchored">
<figure class="quarto-float quarto-float-fig figure"><div aria-describedby="fig-seg13-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="segmentation_files/figure-html/fig-seg13-1.png" class="img-fluid figure-img" width="672">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-seg13-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Rysunek&nbsp;14.12: Mapa cieplna aktywacji klasy słonia afrykańskiego na zdjęciu testowym
</figcaption></figure>
</div>
</div>
</div>
<p>Ta technika wizualizacji odpowiada na dwa ważne pytania:</p>
<ul>
<li>Dlaczego sieć uznała, że ten obraz zawiera słonia afrykańskiego?</li>
<li>Gdzie na obrazie znajduje się słoń afrykański?</li>
</ul>
<p>W szczególności interesujące jest to, że uszy słoniowego malca są silnie aktywowane: prawdopodobnie w ten sposób sieć potrafi odróżnić słonie afrykańskie od indyjskich.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure"><p><img src="https://media.giphy.com/media/DAtJCG1t3im1G/giphy.gif" class="img-fluid quarto-figure quarto-figure-center figure-img"></p>
</figure>
</div>


<div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list" style="display: none">
<div id="ref-heDeepResidualLearning2015" class="csl-entry" role="listitem">
He, Kaiming, Xiangyu Zhang, Shaoqing Ren, i Jian Sun. 2015. <span>„Deep <span>Residual Learning</span> for <span>Image Recognition</span>”</span>. <span>arXiv</span>. <a href="https://doi.org/10.48550/arXiv.1512.03385">https://doi.org/10.48550/arXiv.1512.03385</a>.
</div>
<div id="ref-ioffeBatchNormalizationAccelerating2015" class="csl-entry" role="listitem">
Ioffe, Sergey, i Christian Szegedy. 2015. <span>„Batch <span>Normalization</span>: <span>Accelerating Deep Network Training</span> by <span>Reducing Internal Covariate Shift</span>”</span>. <span>arXiv</span>. <a href="https://doi.org/10.48550/arXiv.1502.03167">https://doi.org/10.48550/arXiv.1502.03167</a>.
</div>
<div id="ref-selvarajuGradCAMVisualExplanations2020" class="csl-entry" role="listitem">
Selvaraju, Ramprasaath R., Michael Cogswell, Abhishek Das, Ramakrishna Vedantam, Devi Parikh, i Dhruv Batra. 2020. <span>„Grad-<span>CAM</span>: <span>Visual Explanations</span> from <span>Deep Networks</span> via <span>Gradient-based Localization</span>”</span>. <em>International Journal of Computer Vision</em> 128 (2): 336–59. <a href="https://doi.org/10.1007/s11263-019-01228-7">https://doi.org/10.1007/s11263-019-01228-7</a>.
</div>
</div>
</section></section></main><!-- /main --><script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const disableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'prefetch';
    }
  }
  const enableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'stylesheet';
    }
  }
  const manageTransitions = (selector, allowTransitions) => {
    const els = window.document.querySelectorAll(selector);
    for (let i=0; i < els.length; i++) {
      const el = els[i];
      if (allowTransitions) {
        el.classList.remove('notransition');
      } else {
        el.classList.add('notransition');
      }
    }
  }
  const toggleGiscusIfUsed = (isAlternate, darkModeDefault) => {
    const baseTheme = document.querySelector('#giscus-base-theme')?.value ?? 'light';
    const alternateTheme = document.querySelector('#giscus-alt-theme')?.value ?? 'dark';
    let newTheme = '';
    if(darkModeDefault) {
      newTheme = isAlternate ? baseTheme : alternateTheme;
    } else {
      newTheme = isAlternate ? alternateTheme : baseTheme;
    }
    const changeGiscusTheme = () => {
      // From: https://github.com/giscus/giscus/issues/336
      const sendMessage = (message) => {
        const iframe = document.querySelector('iframe.giscus-frame');
        if (!iframe) return;
        iframe.contentWindow.postMessage({ giscus: message }, 'https://giscus.app');
      }
      sendMessage({
        setConfig: {
          theme: newTheme
        }
      });
    }
    const isGiscussLoaded = window.document.querySelector('iframe.giscus-frame') !== null;
    if (isGiscussLoaded) {
      changeGiscusTheme();
    }
  }
  const toggleColorMode = (alternate) => {
    // Switch the stylesheets
    const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
    manageTransitions('#quarto-margin-sidebar .nav-link', false);
    if (alternate) {
      enableStylesheet(alternateStylesheets);
      for (const sheetNode of alternateStylesheets) {
        if (sheetNode.id === "quarto-bootstrap") {
          toggleBodyColorMode(sheetNode);
        }
      }
    } else {
      disableStylesheet(alternateStylesheets);
      toggleBodyColorPrimary();
    }
    manageTransitions('#quarto-margin-sidebar .nav-link', true);
    // Switch the toggles
    const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
    for (let i=0; i < toggles.length; i++) {
      const toggle = toggles[i];
      if (toggle) {
        if (alternate) {
          toggle.classList.add("alternate");     
        } else {
          toggle.classList.remove("alternate");
        }
      }
    }
    // Hack to workaround the fact that safari doesn't
    // properly recolor the scrollbar when toggling (#1455)
    if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
      manageTransitions("body", false);
      window.scrollTo(0, 1);
      setTimeout(() => {
        window.scrollTo(0, 0);
        manageTransitions("body", true);
      }, 40);  
    }
  }
  const isFileUrl = () => { 
    return window.location.protocol === 'file:';
  }
  const hasAlternateSentinel = () => {  
    let styleSentinel = getColorSchemeSentinel();
    if (styleSentinel !== null) {
      return styleSentinel === "alternate";
    } else {
      return false;
    }
  }
  const setStyleSentinel = (alternate) => {
    const value = alternate ? "alternate" : "default";
    if (!isFileUrl()) {
      window.localStorage.setItem("quarto-color-scheme", value);
    } else {
      localAlternateSentinel = value;
    }
  }
  const getColorSchemeSentinel = () => {
    if (!isFileUrl()) {
      const storageValue = window.localStorage.getItem("quarto-color-scheme");
      return storageValue != null ? storageValue : localAlternateSentinel;
    } else {
      return localAlternateSentinel;
    }
  }
  const darkModeDefault = false;
  let localAlternateSentinel = darkModeDefault ? 'alternate' : 'default';
  // Dark / light mode switch
  window.quartoToggleColorScheme = () => {
    // Read the current dark / light value 
    let toAlternate = !hasAlternateSentinel();
    toggleColorMode(toAlternate);
    setStyleSentinel(toAlternate);
    toggleGiscusIfUsed(toAlternate, darkModeDefault);
  };
  // Ensure there is a toggle, if there isn't float one in the top right
  if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
    const a = window.document.createElement('a');
    a.classList.add('top-right');
    a.classList.add('quarto-color-scheme-toggle');
    a.href = "";
    a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
    const i = window.document.createElement("i");
    i.classList.add('bi');
    a.appendChild(i);
    window.document.body.appendChild(a);
  }
  // Switch to dark mode if need be
  if (hasAlternateSentinel()) {
    toggleColorMode(true);
  } else {
    toggleColorMode(false);
  }
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Skopiowano!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Skopiowano!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      const annoteTargets = window.document.querySelectorAll('.code-annotation-anchor');
      for (let i=0; i<annoteTargets.length; i++) {
        const annoteTarget = annoteTargets[i];
        const targetCell = annoteTarget.getAttribute("data-target-cell");
        const targetAnnotation = annoteTarget.getAttribute("data-target-annotation");
        const contentFn = () => {
          const content = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          if (content) {
            const tipContent = content.cloneNode(true);
            tipContent.classList.add("code-annotation-tip-content");
            return tipContent.outerHTML;
          }
        }
        const config = {
          allowHTML: true,
          content: contentFn,
          onShow: (instance) => {
            selectCodeLines(instance.reference);
            instance.reference.classList.add('code-annotation-active');
            window.tippy.hideAll();
          },
          onHide: (instance) => {
            unselectCodeLines();
            instance.reference.classList.remove('code-annotation-active');
          },
          maxWidth: 300,
          delay: [50, 0],
          duration: [200, 0],
          offset: [5, 10],
          arrow: true,
          appendTo: function(el) {
            return el.parentElement.parentElement.parentElement;
          },
          interactive: true,
          interactiveBorder: 10,
          theme: 'quarto',
          placement: 'right',
          popperOptions: {
            modifiers: [
            {
              name: 'flip',
              options: {
                flipVariations: false, // true by default
                allowedAutoPlacements: ['right'],
                fallbackPlacements: ['right', 'top', 'top-start', 'top-end', 'bottom', 'bottom-start', 'bottom-end', 'left'],
              },
            },
            {
              name: 'preventOverflow',
              options: {
                mainAxis: false,
                altAxis: false
              }
            }
            ]        
          }      
        };
        window.tippy(annoteTarget, config); 
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script><nav class="page-navigation"><div class="nav-page nav-page-previous">
      <a href="./example.html" class="pagination-link  aria-label=" uczenia="" sieci="" splotowej="">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Przykład uczenia sieci splotowej</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./references.html" class="pagination-link" aria-label="Bibliografia">
        <span class="nav-page-text">Bibliografia</span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->
<footer class="footer"><div class="nav-footer">
    <div class="nav-footer-left">
<p>Automatyczna analiza obrazu, Dariusz Majerek</p>
</div>   
    <div class="nav-footer-center">
      &nbsp;
    <div class="toc-actions d-sm-block d-md-none"><ul><li><a href="https://github.com/dax44/ComputerVision/issues/new" class="toc-action"><i class="bi bi-github"></i>Zgłoś problem</a></li></ul></div></div>
    <div class="nav-footer-right">
<p>Książka została napisana w <a href="https://quarto.org/">Quarto</a></p>
</div>
  </div>
</footer>


</body></html>