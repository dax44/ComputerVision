[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Automatyczna analiza obrazu",
    "section": "",
    "text": "Wstęp\nNiniejsza książka powstała na potrzeby prowadzenia wykładu z Automatycznej analizy obrazu. Jest wynikiem moich doświadczeń z automatyczną analizą obrazu. W pisaniu tego kompendium wiedzy na temat Computer Vision bardzo pomocne były dwie pozycje literaturowe (Burger i Burge 2016; Szeliski 2022). Oprócz wspomnianych książek poświęconych wizji komputerowej, ważne są również pozycje objaśniające arkana deep learning. Wśród nich należy wymienić (Goodfellow, Bengio, i Courville 2016; Ketkar i Santana 2017; „Deep Learning with Python, Second Edition”, b.d.; Chollet i Allaire 2018). Ponadto zostaną wykorzystane nieprzebrane zasoby internetu - na stronach takich jak https://stackoverflow.com czy https://github.com można znaleźć rozwiązania do niemal każdego zadania.\nNa potrzeby zajęć laboratoryjnych będą dodatkowo potrzebne pewne programy komputerowe i biblioteki:\n\nFiji - darmowy program będący nakładką na program ImageJ. Służy on do operacji na zdjęciach. Do pobrania ze strony https://fiji.sc/;\nPython - język programowania, w którym można wykonać niemal dowolne zadanie z zakresu automatycznej analizy obrazu. Przez instalacje Python-a rozumiem zainstalowanie odpowiedniej dystrybucji tego programu (np. dla Windows zaleca się instalację dystrybucji Anconda lub Miniconda). Po szczegóły dotyczące instalacji Pythona na Windows odsyłam na stronę https://support.posit.co/hc/en-us/articles/1500007929061-Using-Python-with-the-RStudio-IDE;\nPo zainstalowaniu Pythona, trzeba też zainstalować dwie bardzo ważne biblioteki pythonowe do budowania i uczenia sieci głębokiego uczenia:\n\ntensorflow - jest end-to-end platformą typu open-source do uczenia maszynowego. Jest to kompleksowy i elastyczny ekosystem narzędzi, bibliotek i innych zasobów, które zapewniają przepływy pracy z wysokopoziomowymi interfejsami API. Ramy oferują różne poziomy koncepcji, abyś mógł wybrać ten, którego potrzebujesz do budowania i wdrażania modeli uczenia maszynowego;\nkeras - jest wysokopoziomową biblioteką do budowy sieci neuronowych, która działa na bazie TensorFlow, CNTK i Theano. Wykorzystanie Keras w deep learningu pozwala na łatwe i szybkie prototypowanie, a także płynne działanie na CPU i GPU. Aby zainstalować zarówno tensorflow, jak i keras z obsługo CPU lub GPU polecam instrukcję w filmie https://youtu.be/PnK1jO2kXOQ;\n\nOpenCV - jest biblioteką (ale nie programu R) funkcji programistycznych skierowanych głównie do wizji komputerowej czasu rzeczywistego. Instalację w Windows można znaleźć pod adresem https://docs.opencv.org/4.x/d3/d52/tutorial_windows_install.html;\nBiblioteki R-owe potrzebne do budowy modeli i obsługi obrazów, to:\n\nreticulate - biblioteka pozwalająca na wykorzystanie bibliotek i funkcji Python-a w R;\nmagick - biblioteka potrzebna do różnego rodzaju transformacji obrazów;\ntensorflow - biblioteka R-owa pozwalająca na wykorzystanie funkcji tensorflow Pythona;\nkeras - biblioteka R-owa pozwalająca na korzystanie z funkcji pakietu keras Pythonowego.\n\n\n\n\n\n\nBurger, Wilhelm, i Mark J. Burge. 2016. Digital Image Processing: An Algorithmic Introduction Using Java. Texts w Computer Science. London: Springer. https://doi.org/10.1007/978-1-4471-6684-9.\n\n\nChollet, Francois, i J. J. Allaire. 2018. Deep Learning with R. Manning Publications.\n\n\n„Deep Learning with Python, Second Edition”. b.d. Manning Publications. https://www.manning.com/books/deep-learning-with-python-second-edition.\n\n\nGoodfellow, Ian, Yoshua Bengio, i Aaron Courville. 2016. Deep Learning. Illustrated edition. Cambridge, Massachusetts: The MIT Press.\n\n\nKetkar, Nikhil, i Eder Santana. 2017. Deep Learning with Python. T. 1. Springer.\n\n\nSzeliski, Richard. 2022. Computer Vision: Algorithms and Applications. Texts w Computer Science. Cham: Springer International Publishing. https://doi.org/10.1007/978-3-030-34372-9."
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "1  Wprowadzenie",
    "section": "",
    "text": "Automatyczna analiza obrazu jest znana również pod inną nazwą wizja komputerowa (ang. Computer Vision). Można powiedzieć też, że AAO1 jest częścią jeszcze szerszej dziedziny automatycznej analizy sygnałów. Ponieważ różnice pomiędzy analizą obrazu i dźwięku w niektórych zadaniach będą się zacierać, to poznane metody w toku tego wykładu będzie można śmiało przenieść na inne dziedziny. Oczywiście uwzględniając szereg podobieństw pomiędzy analizą obrazu i analizą dźwięku, istniej wiele dedykowanych modeli stosowanych tylko w domenie fal dźwiękowych.1 skrót od Automatyczna Analiza Obrazu\n\n\n\n\n\nW ramach zadań realizowanych przez wizję komputerową można wymienić:\n\npozyskiwanie obrazów (opis procesu “robienia zdjęcia” cyfrowego);\nprzetwarzanie obrazów w celu zmiany ich parametrów (np. poprawy ostrości, usuwania szumów, itp);\nanalizowania zdjęć w celu poszukiwania wzorców:\n\nzastosowanie ML2 do klasyfikacji obiektów na zdjęciach;\nzastosowanie ML do zadań regresyjnych (np. wyznaczanie poziomu wylania na podstawie zdjęć satelitarnych);\nzastosowanie ML w lokalizacji obiektów na obrazie (np. wskazanie położenia samolotu na zdjęciu w postaci ujęcia go w prostokątną ramkę);\nautoidentyfikacja (np. rozpoznawanie twarzy czy odcisku palca);\ntworzenie obrazów na podstawie fraz (istnieją sieci np. GAN, które są w stanie wygenerować całkowicie fikcyjny obraz na podstawie zdania opisującego co ma się na nim znaleźć);\nśledzenie ruchów na podstawie obrazu wideo (np. automatyczne kadrowanie obrazu wideo na podstawie położenia twarzy podczas rozmowy przez komunikator);\nsegmentacja obrazu;\ni wiele innych\n\n\n2 Machine LearningŚmiało można stwierdzić, że AAO towarzyszy nam codziennie i na każdym kroku. Czasami nie jesteśmy nawet tego świadomi.\n\nPoniżej przedstawiam listę wybranych zastosowań AAO:\n\nTransport - Rosnące wymagania sektora transportowego napędzają rozwój technologiczny w tej branży, w którego centrum znajduje się wizja komputerowa. Od pojazdów autonomicznych po wykrywanie zajętości miejsc parkingowych, Inteligentny System Transportowy (ITS) stał się krytycznym obszarem promowania wydajności, efektywności i bezpieczeństwa transportu.\n\n\n\n\n\nMonitorowanie zajętości miejsc na parkingu\n\n\n\nMedycyna. Dane z obrazowania medycznego są jednym z najbogatszych źródeł informacji. Bez odpowiedniej technologii lekarze są zmuszeni spędzać godziny na ręcznym analizowaniu danych pacjentów i wykonywaniu prac administracyjnych. Na szczęście, wraz z upływem lat i rozwojem technologii, branża opieki zdrowotnej stała się jedną z najszybciej przyjmujących nowe rozwiązania automatyzacji, w tym wizję komputerową.\n\n\n\n\n\nSegmentacja obrazu MRI\n\n\n\nProdukcja. Przemysł produkcyjny przyjął już szeroką gamę rozwiązań automatyzacji z wizją komputerową w centrum. Pomaga ona zautomatyzować kontrolę jakości, zminimalizować zagrożenia bezpieczeństwa i zwiększyć wydajność produkcji. Oto niektóre z najczęstszych zastosowań wizji komputerowej w przemyśle produkcyjnym.\n\n\n\n\nAAO w kontroli jakości\n\n\n\n\n\nAAO w procesie magazynowania\n\n\n\nBudowa. Sektor budowlany szybko przyjmuje technologię wizji komputerowej i wykorzystuje ją do wykrywania sprzętu ochrony osobistej, kontroli aktywów infrastruktury, wykrywania zagrożeń w miejscu pracy lub konserwacji.\n\n\n\n\nWykrywanie zużytych części\n\n\n\n\n\nNaruszenia procedur bezpieczeństwa\n\n\n\nRolnictwo. Sektor rolniczy był świadkiem kilku przypadków zastosowania modeli sztucznej inteligencji (w tym wizji komputerowej) w takich dziedzinach, jak monitorowanie upraw i plonów, zautomatyzowane zbiory, analiza warunków pogodowych, monitorowanie zdrowia zwierząt gospodarskich czy wykrywanie chorób roślin. Technologia ta zdobyła już silną pozycję dzięki możliwościom automatyzacji i wykrywania, a jej zastosowania będą się tylko rozszerzać.\n\n\n\n\nWyrywanie nietypowych zachowań zwierząt\n\n\n\n\n\nChoroby roślin\n\n\n\nSprzedaż detaliczna. Kamery zainstalowane w sklepach detalicznych pozwalają sprzedawcom zbierać duże ilości danych wizualnych pomocnych w projektowaniu lepszych doświadczeń klientów i pracowników. Rozwój systemów wizji komputerowej do przetwarzania tych danych sprawia, że cyfrowa transformacja branży realnej staje się znacznie bardziej osiągalna.\n\n\n\n\nWykrywanie braków towaru\n\n\n\n\n\nWykrywanie nietypowych zachowań klientów lub badanie zatłoczenia\n\n\nPrzestrzeni do zastosowań AAO jest jeszcze dużo więcej ale nie sposób ich wszystkich opisać. Oto kilka przykładów z różnych kategorii.\n\n\n\nBadanie ruchu zawodnika\n\n\n\n\n\nWykrywanie naruszeń prawa\n\n\n\n\n\nWykrywanie twarzy\n\n\nMoże też służyć do zabawy\n\n\n\nKilka obrazów wygenerowanych jako wariacje na temat mojego zdjęcia z wakacji\n\n\n\n\n\nKilka przykładów obrazów wygenerowanych przez sieć DALL E2 jako odpowiedź na zdanie “narysuj bez odrywania ręki jedna linią misia na zakupach”\n\n\n\n\n\nTym razem sieć DALL E2 została poproszona o namalowanie kobiet w stylu Van Gogha"
  },
  {
    "objectID": "history.html#lata-70",
    "href": "history.html#lata-70",
    "title": "2  Historia wizji komputerowej",
    "section": "2.1 Lata ’70",
    "text": "2.1 Lata ’70\nKiedy wizja komputerowa po raz pierwszy pojawiła się na początku lat siedemdziesiątych, była postrzegana jako wizualny komponent percepcji ambitnego programu naśladowania ludzkiej inteligencji i obdarzenia robotów inteligentnym zachowaniem. W tym czasie niektórzy z pionierów sztucznej inteligencji i robotyki (w miejscach takich jak MIT, Stanford) wierzyli, że rozwiązanie problemu “wejścia wizualnego” będzie łatwym krokiem na drodze do rozwiązania trudniejszych problemów, takich jak rozumowanie na wyższym poziomie i planowanie. Według jednej ze znanych historii, w 1966 roku Marvin Minsky z MIT poprosił swojego studenta Geralda Jay Sussmana o “spędzenie lata na podłączeniu kamery do komputera i nakłonieniu komputera do opisania tego, co widział”. Obecnie wiemy, że problem jest nieco trudniejszy niż wówczas się wydawało.\nTym, co odróżniało widzenie komputerowe od istniejącej już dziedziny cyfrowej obróbki obrazów, była chęć odzyskania trójwymiarowej struktury świata z obrazów i wykorzystania tego jako kroku w kierunku pełnego zrozumienia prezentowanej sceny. Winston (1976) oraz Hanson (1978) dostarczają dwóch ładnych zbiorów klasycznych prac z tego wczesnego okresu. Wczesne próby zrozumienia sceny polegały na wyodrębnieniu krawędzi, a następnie wnioskowaniu o strukturze 3D obiektu lub “świata bloków” z topologicznej struktury linii 2D Roberts (1980).\nJakościowe podejście do rozumienia intensywności i zmienności cieniowania oraz wyjaśniania ich przez efekty zjawisk formowania się obrazu, takich jak orientacja powierzchni i cienie, zostało spopularyzowane przez Barrow i Tenenbaum (1981) w ich pracy na temat obrazów wewnętrznych. W tym czasie opracowano również bardziej ilościowe podejścia do wizji komputerowej, w tym pierwszy z wielu opartych na cechach algorytmów korespondencji stereo (Dev 1975; „Cooperative Computation of Stereo Disparity | Science”, b.d.; Barnard i Fischler 1982)."
  },
  {
    "objectID": "history.html#lata-80",
    "href": "history.html#lata-80",
    "title": "2  Historia wizji komputerowej",
    "section": "2.2 Lata ’80",
    "text": "2.2 Lata ’80\nW latach ’80 ubiegłego wieku wiele uwagi poświęcono bardziej wyrafinowanym technikom matematycznym służącym do przeprowadzania ilościowej analizy obrazów i scen. Piramidy obrazów zaczęły być powszechnie stosowane do wykonywania zadań takich jak mieszanie obrazów i wyszukiwanie korespondencji coarse-to-fine. Wykorzystanie stereo jako ilościowej wskazówki kształtu zostało rozszerzone o szeroką gamę technik shape-from-X, w tym shape from shading (Horn, b.d.; Blake, Zisserman, i Knowles 1985).\n\n\n\nRysunek 2.2: Przykład wykorzystania techniki piramid blending\n\n\nW tym okresie prowadzono również badania nad lepszym wykrywaniem krawędzi i konturów (Canny 1986; Nalwa i Binford 1986), stereografii fotometrycznej (Woodham 1981) oraz kształty z tekstur (Witkin 1981). W tym okresie prowadzono również badania nad lepszym wykrywaniem krawędzi i konturów, w tym wprowadzono dynamicznie ewoluujące trackery konturów, takie jak węże, a także trójwymiarowe modele oparte na fizyce. Naukowcy zauważyli, że wiele algorytmów detekcji stereoskopowej, przepływu, shape-from-X i krawędzi może być zunifikowanych lub przynajmniej opisanych przy użyciu tych samych ram matematycznych, jeśli zostaną one postawione jako problemy optymalizacji wariacyjnej i uodpornione (dobrze postawione) przy użyciu regularyzacji.\nNieco później wprowadzono warianty on-line algorytmów MRF (ang. Markov Random Field), które modelowały i aktualizowały niepewności za pomocą filtru Kalmana. Podjęto również próby odwzorowania zarówno algorytmów regularyzowanych jak i MRF na sprzęt zrównoleglony (ang. parallel). Książka (Fischler i Firschein 1987) zawiera zbiór artykułów skupiających się na wszystkich tych tematach (stereo, przepływ, regularność, MRF, a nawet widzenie wyższego poziomu)."
  },
  {
    "objectID": "history.html#lata-90",
    "href": "history.html#lata-90",
    "title": "2  Historia wizji komputerowej",
    "section": "2.3 Lata ’90",
    "text": "2.3 Lata ’90\nPodczas gdy wiele z wcześniej wymienionych tematów było nadal eksplorowanych, kilka z nich stało się znacznie bardziej aktywnych. Nagły wzrost aktywności w zakresie wykorzystania niezmienników projekcyjnych do celów rozpoznania (Mundy i Zisserman 1992) przerodził się w skoordynowane wysiłki zmierzające do rozwiązania problemu structure from motion. Wiele początkowych działań skierowanych było na rekonstrukcje rzutowe, które nie wymagają znajomości kalibracji kamery. Równolegle, techniki faktoryzacji zostały opracowane w celu efektywnego rozwiązywania problemów, dla których miały zastosowanie przybliżenia kamery ortograficznej, a następnie rozszerzone na przypadek perspektywiczny.\nW końcu zaczęto stosować pełną optymalizację globalną która później została uznana za tożsama z technikami dopasowania wiązki, tradycyjnie stosowanymi w fotogrametrii. W pełni zautomatyzowane systemy modelowania 3D zostały zbudowane przy użyciu tych technik.\nPrace rozpoczęte w latach 80-tych nad wykorzystaniem szczegółowych pomiarów barwy i natężenia światła w połączeniu z dokładnymi modelami fizycznymi transportu promieniowania i tworzenia kolorowych obrazów stworzyły własną dziedzinę znaną jako widzenie oparte na fizyce. Algorytmy stereo na podstawie wielu obrazów, które tworzą kompletne powierzchnie 3D były również aktywnym tematem badań, który jest aktualny do dziś.\nAlgorytmy śledzenia również uległy dużej poprawie, w tym śledzenie konturów z wykorzystaniem aktywnych konturów, takich jak węże (Kass, Witkin, i Terzopoulos 1988), filtry cząsteczkowe (Blake i Isard 2012) i zbiorów poziomnicowych (ang. level set) (Malladi, Sethian, i Vemuri 1995), a także techniki oparte na intensywności (bezpośrednie), często stosowane do śledzenia twarzy.\n\n\n\nRysunek 2.3: Przykład śledzenia twarzy przez algorytm\n\n\nSegmentacja obrazów, temat, który jest aktywny od początku wizji komputerowej, był również aktywnym tematem badań, produkując techniki oparte na minimalnej energii i minimalnej długości opisu, znormalizowanych cięciach i średnim przesunięciu.\nZaczęły pojawiać się techniki uczenia statystycznego, najpierw w zastosowaniu analizy składowych głównych, eigenface do rozpoznawania twarzy oraz liniowych systemów dynamicznych do śledzenia krzywych.\nByć może najbardziej zauważalnym rozwojem w dziedzinie widzenia komputerowego w tej dekadzie była zwiększona interakcja z grafiką komputerową, zwłaszcza w interdyscyplinarnym obszarze modelowania i renderowania opartego na obrazach. Pomysł manipulowania obrazami świata rzeczywistego bezpośrednio w celu tworzenia nowych animacji po raz pierwszy stał się znany dzięki technikom morfingu obrazu."
  },
  {
    "objectID": "history.html#lata-00",
    "href": "history.html#lata-00",
    "title": "2  Historia wizji komputerowej",
    "section": "2.4 Lata ’00",
    "text": "2.4 Lata ’00\nTa dekada kontynuowała pogłębianie interakcji pomiędzy dziedzinami wizji i grafiki, ale co ważniejsze, przyjęła podejścia oparte na danych i uczeniu się jako kluczowe komponenty wizji. Wiele z tematów wprowadzonych w rubryce renderingu opartego na obrazie, takich jak zszywanie obrazów, przechwytywanie i renderowanie pola świetlnego oraz przechwytywanie obrazów o wysokim zakresie dynamicznym (HDR) poprzez bracketing ekspozycji, zostało ponownie ochrzczonych mianem fotografii obliczeniowej, aby potwierdzić zwiększone wykorzystanie takich technik w codziennej fotografii cyfrowej. Na przykład, szybkie przyjęcie bracketingu ekspozycji do tworzenia obrazów o wysokim zakresie dynamicznym wymagało opracowania algorytmów kompresji dynamiki, aby przekształcić takie obrazy z powrotem do wyników możliwych do wyświetlenia. Oprócz łączenia wielu ekspozycji, opracowano techniki łączenia obrazów z lampą błyskową z ich odpowiednikami bez lampy błyskowej.\n\n\n\nRysunek 2.4: Przykład rozpoznawania obiektów\n\n\nDrugim wartym uwagi trendem w tej dekadzie było pojawienie się technik opartych na cechach (połączonych z uczeniem) do rozpoznawania obiektów. Niektóre z godnych uwagi prac w tej dziedzinie obejmują model konstelacji (Ponce i in. 2007; Fergus, Perona, i Zisserman 2007) oraz struktury obrazowe (Felzenszwalb i Huttenlocher 2005). Techniki oparte na cechach dominują również w innych zadaniach rozpoznawania, takich jak rozpoznawanie scen, panoram i lokalizacji. I chociaż cechy oparte na punktach zainteresowania (patch-based) dominują w obecnych badaniach, niektóre grupy zajmują się rozpoznawaniem na podstawie konturów i segmentacji regionów.\nInnym istotnym trendem tej dekady było opracowanie bardziej wydajnych algorytmów dla złożonych problemów optymalizacji globalnej. Chociaż trend ten rozpoczął się od prac nad cięciami grafów, duży postęp dokonał się również w algorytmach przekazywania wiadomości, takich jak loopy belief propagation (LBP).\nNajbardziej zauważalnym trendem tej dekady, który do tej pory całkowicie opanował rozpoznawanie obrazu i większość innych aspektów widzenia komputerowego, było zastosowanie zaawansowanych technik uczenia maszynowego do problemów widzenia komputerowego. Trend ten zbiegł się w czasie ze zwiększoną dostępnością ogromnych ilości częściowo oznakowanych danych w Internecie, a także ze znacznym wzrostem mocy obliczeniowej, co sprawiło, że uczenie się kategorii obiektów bez użycia starannego nadzoru człowieka stało się bardziej realne."
  },
  {
    "objectID": "history.html#lata-10",
    "href": "history.html#lata-10",
    "title": "2  Historia wizji komputerowej",
    "section": "2.5 Lata ’10",
    "text": "2.5 Lata ’10\nTrend do wykorzystywania dużych etykietowanych zbiorów danych do rozwoju algorytmów uczenia maszynowego stał się falą, która całkowicie zrewolucjonizowała rozwój algorytmów rozpoznawania obrazów, a także innych aplikacji, takich jak denoising i przepływ optyczny, które wcześniej wykorzystywały techniki Bayesa i optymalizacji globalnej. Tendencję tę umożliwił rozwój wysokiej jakości wielkoskalowych anotowanych zbiorów danych, takich jak ImageNet, Microsoft COCO i LVIS. Te zbiory danych dostarczyły nie tylko wiarygodnych metryk do śledzenia postępów algorytmów rozpoznawania i segmentacji semantycznej, ale co ważniejsze, wystarczającej ilości etykietowanych danych do opracowania kompletnych rozwiązań opartych na uczeniu maszynowym.\nInnym ważnym trendem był dramatyczny wzrost mocy obliczeniowej dostępny dzięki rozwojowi algorytmów ogólnego przeznaczenia (data-parallel) na jednostkach przetwarzania graficznego (GPGPU). Przełomowa głęboka sieć neuronowa SuperVision (“AlexNet”), która jako pierwsza wygrała coroczne zawody w rozpoznawaniu obrazów na dużą skalę ImageNet, opierała się na treningu na GPU, a także na szeregu usprawnień technicznych, które przyczyniły się dramatycznie do wzrostu jej wydajności. Po opublikowaniu tej pracy postęp w wykorzystaniu głębokich architektur konwolucyjnych gwałtownie przyspieszył, do tego stopnia, że obecnie są one jedyną architekturą braną pod uwagę w zadaniach rozpoznawania i segmentacji semantycznej, a także preferowaną architekturą w wielu innych zadaniach wizyjnych, w tym w zadaniach przepływu optycznego, denoisingu i wnioskowania o głębi monokularnej (LeCun, Bengio, i Hinton 2015).\nDuże zbiory danych i architektury GPU, w połączeniu z szybkim upowszechnianiem pomysłów poprzez pojawiające się w odpowiednim czasie publikacje na arXiv, a także rozwój języków głębokiego uczenia i otwarty dostęp do modeli sieci neuronowych, przyczyniły się do gwałtownego rozwoju tej dziedziny, zarówno pod względem szybkich postępów i możliwości, jak i samej liczby publikacji i badaczy zajmujących się obecnie tymi tematami. Umożliwiły one również rozszerzenie podejść do rozpoznawania obrazów na zadania związane z rozumieniem wideo, takie jak rozpoznawanie akcji, a także zadania regresji strukturalnej, takie jak estymacja w czasie rzeczywistym wieloosobowej pozy ciała.\nSpecjalistyczne czujniki i sprzęt do zadań związanych z widzeniem komputerowym również stale się rozwijały. Wprowadzona w 2010 r. kamera głębi Microsoft Kinect szybko stała się podstawowym elementem wielu systemów modelowania 3D i śledzenia osób. W ciągu dekady systemy modelowania i śledzenia kształtu ciała 3D nadal się rozwijały, do tego stopnia, że obecnie możliwe jest wnioskowanie o modelu 3D osoby wraz z gestami i ekspresją na podstawie jednego obrazu.\n\n\n\n\nBarnard, Stephen T., i Martin A. Fischler. 1982. „Computational Stereo”. ACM Computing Surveys 14 (4): 553–72. https://doi.org/10.1145/356893.356896.\n\n\nBarrow, H. G., i J. M. Tenenbaum. 1981. „Computational Vision”. Proceedings of the IEEE 69 (5): 572–95. https://doi.org/10.1109/PROC.1981.12026.\n\n\nBlake, Andrew, i Michael Isard. 2012. Active Contours: The Application of Techniques from Graphics, Vision, Control Theory and Statistics to Visual Tracking of Shapes in Motion. Springer Science & Business Media.\n\n\nBlake, Andrew, Andrew Zisserman, i Greg Knowles. 1985. „Surface Descriptions from Stereo and Shading”. Image and Vision Computing, Papers from the 1985 Alvey Computer Vision i Image Interpretation Meeting, 3 (4): 183–91. https://doi.org/10.1016/0262-8856(85)90006-X.\n\n\nCanny, John. 1986. „A Computational Approach to Edge Detection”. IEEE Transactions on Pattern Analysis and Machine Intelligence PAMI-8 (6): 679–98. https://doi.org/10.1109/TPAMI.1986.4767851.\n\n\n„Cooperative Computation of Stereo Disparity | Science”. b.d. https://www.science.org/doi/10.1126/science.968482.\n\n\nDev, Parvati. 1975. „Perception of Depth Surfaces in Random-Dot Stereograms : A Neural Model”. International Journal of Man-Machine Studies 7 (4): 511–28. https://doi.org/10.1016/S0020-7373(75)80030-7.\n\n\nFelzenszwalb, Pedro F., i Daniel P. Huttenlocher. 2005. „Pictorial Structures for Object Recognition”. International Journal of Computer Vision 61 (1): 55–79. https://doi.org/10.1023/B:VISI.0000042934.15159.49.\n\n\nFergus, R., P. Perona, i A. Zisserman. 2007. „Weakly Supervised Scale-Invariant Learning of Models for Visual Recognition”. International Journal of Computer Vision 71 (3): 273–303. https://doi.org/10.1007/s11263-006-8707-x.\n\n\nFischler, M., i O. Firschein. 1987. „Readings in Computer Vision: Issues, Problems, Principles, and Paradigms”. W.\n\n\nHanson, Allen. 1978. Computer Vision Systems. Elsevier.\n\n\nHorn, Berthold K P. b.d. „Obtaining Shape from Shading Information”.\n\n\nKass, Michael, Andrew Witkin, i Demetri Terzopoulos. 1988. „Snakes: Active Contour Models”. International Journal of Computer Vision 1 (4): 321–31. https://doi.org/10.1007/BF00133570.\n\n\nLeCun, Yann, Yoshua Bengio, i Geoffrey Hinton. 2015. „Deep Learning”. Nature 521 (7553): 436–44. https://doi.org/10.1038/nature14539.\n\n\nMalladi, R., J. A. Sethian, i B. C. Vemuri. 1995. „Shape Modeling with Front Propagation: A Level Set Approach”. IEEE Transactions on Pattern Analysis and Machine Intelligence 17 (2): 158–75. https://doi.org/10.1109/34.368173.\n\n\n„Mind as Machine: A History of Cognitive Science”. 2007. Choice Reviews Online 44 (11). https://doi.org/10.5860/choice.44-6202.\n\n\nMundy, Joseph L., i Andrew Zisserman, red. 1992. Geometric Invariance in Computer Vision. Cambridge, MA, USA: MIT Press.\n\n\nNalwa, Vishvjit S., i Thomas O. Binford. 1986. „On Detecting Edges”. IEEE Transactions on Pattern Analysis and Machine Intelligence PAMI-8 (6): 699–714. https://doi.org/10.1109/TPAMI.1986.4767852.\n\n\nPonce, Jean, Martial Hebert, Cordelia Schmid, i Andrew Zisserman. 2007. Toward Category-Level Object Recognition. Springer.\n\n\nRoberts, Lawrence G. 1980. Machine Perception of Three-Dimensional Solids. Garland Pub.\n\n\nWinston, Patrick Henry. 1976. „The Psychology of Computer Vision”. Pattern Recognition 8 (3): 193. https://doi.org/10.1016/0031-3203(76)90020-0.\n\n\nWitkin, Andrew P. 1981. „Recovering Surface Shape and Orientation from Texture”. Artificial Intelligence 17 (1): 17–45. https://doi.org/10.1016/0004-3702(81)90019-9.\n\n\nWoodham, Robert J. 1981. „Analysing Images of Curved Surfaces”. Artificial Intelligence 17 (1): 117–40. https://doi.org/10.1016/0004-3702(81)90022-9."
  },
  {
    "objectID": "summary.html",
    "href": "summary.html",
    "title": "4  Podsumowanie",
    "section": "",
    "text": "In summary, this book has no content whatsoever."
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "Bibliografia",
    "section": "",
    "text": "Barnard, Stephen T., and Martin A. Fischler. 1982. “Computational\nStereo.” ACM Computing Surveys 14 (4):\n553–72. https://doi.org/10.1145/356893.356896.\n\n\nBarrow, H. G., and J. M. Tenenbaum. 1981. “Computational\nVision.” Proceedings of the IEEE 69 (5): 572–95. https://doi.org/10.1109/PROC.1981.12026.\n\n\nBlake, Andrew, and Michael Isard. 2012. Active\nContours: The Application of\nTechniques from Graphics, Vision,\nControl Theory and Statistics to Visual\nTracking of Shapes in Motion.\nSpringer Science & Business Media.\n\n\nBlake, Andrew, Andrew Zisserman, and Greg Knowles. 1985. “Surface\nDescriptions from Stereo and Shading.” Image and Vision\nComputing, Papers from the 1985 Alvey Computer Vision\nand Image Interpretation Meeting, 3 (4): 183–91. https://doi.org/10.1016/0262-8856(85)90006-X.\n\n\nBurger, Wilhelm, and Mark J. Burge. 2016. Digital Image\nProcessing: An Algorithmic Introduction Using\nJava. Texts in Computer Science.\nLondon: Springer. https://doi.org/10.1007/978-1-4471-6684-9.\n\n\nCanny, John. 1986. “A Computational Approach to\nEdge Detection.” IEEE Transactions on Pattern\nAnalysis and Machine Intelligence PAMI-8 (6): 679–98. https://doi.org/10.1109/TPAMI.1986.4767851.\n\n\nChollet, Francois, and J. J. Allaire. 2018. Deep\nLearning with R. Manning\nPublications.\n\n\n“Cooperative Computation of Stereo\nDisparity | Science.” n.d.\nhttps://www.science.org/doi/10.1126/science.968482.\n\n\n“Deep Learning with Python, Second\nEdition.” n.d. Manning Publications.\nhttps://www.manning.com/books/deep-learning-with-python-second-edition.\n\n\nDev, Parvati. 1975. “Perception of Depth Surfaces in Random-Dot\nStereograms : A Neural Model.” International Journal of\nMan-Machine Studies 7 (4): 511–28. https://doi.org/10.1016/S0020-7373(75)80030-7.\n\n\nFelzenszwalb, Pedro F., and Daniel P. Huttenlocher. 2005.\n“Pictorial Structures for Object\nRecognition.” International Journal of Computer\nVision 61 (1): 55–79. https://doi.org/10.1023/B:VISI.0000042934.15159.49.\n\n\nFergus, R., P. Perona, and A. Zisserman. 2007. “Weakly\nSupervised Scale-Invariant Learning of Models\nfor Visual Recognition.” International Journal\nof Computer Vision 71 (3): 273–303. https://doi.org/10.1007/s11263-006-8707-x.\n\n\nFischler, M., and O. Firschein. 1987. “Readings in Computer\nVision: Issues, Problems, Principles, and Paradigms.” In.\n\n\nGoodfellow, Ian, Yoshua Bengio, and Aaron Courville. 2016. Deep\nLearning. Illustrated edition. Cambridge,\nMassachusetts: The MIT Press.\n\n\nHanson, Allen. 1978. Computer Vision Systems.\nElsevier.\n\n\nHorn, Berthold K P. n.d. “Obtaining Shape from\nShading Information.”\n\n\nKass, Michael, Andrew Witkin, and Demetri Terzopoulos. 1988.\n“Snakes: Active Contour Models.”\nInternational Journal of Computer Vision 1 (4): 321–31. https://doi.org/10.1007/BF00133570.\n\n\nKetkar, Nikhil, and Eder Santana. 2017. Deep Learning with\nPython. Vol. 1. Springer.\n\n\nLeCun, Yann, Yoshua Bengio, and Geoffrey Hinton. 2015. “Deep\nLearning.” Nature 521 (7553): 436–44. https://doi.org/10.1038/nature14539.\n\n\nMalladi, R., J. A. Sethian, and B. C. Vemuri. 1995. “Shape\nModeling with Front Propagation: A Level Set Approach.” IEEE\nTransactions on Pattern Analysis and Machine Intelligence 17 (2):\n158–75. https://doi.org/10.1109/34.368173.\n\n\n“Mind as Machine: A History of Cognitive Science.” 2007.\nChoice Reviews Online 44 (11). https://doi.org/10.5860/choice.44-6202.\n\n\nMundy, Joseph L., and Andrew Zisserman, eds. 1992. Geometric\nInvariance in Computer Vision. Cambridge, MA, USA:\nMIT Press.\n\n\nNalwa, Vishvjit S., and Thomas O. Binford. 1986. “On\nDetecting Edges.” IEEE Transactions on Pattern\nAnalysis and Machine Intelligence PAMI-8 (6): 699–714. https://doi.org/10.1109/TPAMI.1986.4767852.\n\n\nPonce, Jean, Martial Hebert, Cordelia Schmid, and Andrew Zisserman.\n2007. Toward Category-Level Object Recognition.\nSpringer.\n\n\nRoberts, Lawrence G. 1980. Machine Perception of Three-dimensional Solids. Garland\nPub.\n\n\nSzeliski, Richard. 2022. Computer Vision:\nAlgorithms and Applications. Texts in\nComputer Science. Cham: Springer\nInternational Publishing. https://doi.org/10.1007/978-3-030-34372-9.\n\n\nWinston, Patrick Henry. 1976. “The Psychology of Computer\nVision.” Pattern Recognition 8 (3): 193. https://doi.org/10.1016/0031-3203(76)90020-0.\n\n\nWitkin, Andrew P. 1981. “Recovering Surface Shape and Orientation\nfrom Texture.” Artificial Intelligence 17 (1): 17–45. https://doi.org/10.1016/0004-3702(81)90019-9.\n\n\nWoodham, Robert J. 1981. “Analysing Images of Curved\nSurfaces.” Artificial Intelligence 17 (1): 117–40. https://doi.org/10.1016/0004-3702(81)90022-9."
  }
]