<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="pl" xml:lang="pl"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.234">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Automatyczna analiza obrazu - 7&nbsp; Wykrywanie krawędzi i konturów</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./morpho.html" rel="next">
<link href="./filters.html" rel="prev">
<link href="./cover.png" rel="icon" type="image/png">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-dark.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="site_libs/bootstrap/bootstrap-dark.min.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 20,
  "language": {
    "search-no-results-text": "Brak wyników",
    "search-matching-documents-text": "dopasowane dokumenty",
    "search-copy-link-title": "Kopiuj link do wyszukiwania",
    "search-hide-matches-text": "Ukryj dodatkowe dopasowania",
    "search-more-match-text": "więcej dopasowań w tym dokumencie",
    "search-more-matches-text": "więcej dopasowań w tym dokumencie",
    "search-clear-button-title": "Wyczyść",
    "search-detached-cancel-button-title": "Anuluj",
    "search-submit-button-title": "Zatwierdź"
  }
}</script>

  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

</head>

<body class="nav-sidebar floating slimcontent">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Przełącz pasek boczny" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
      <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./edge.html"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Wykrywanie krawędzi i konturów</span></a></li></ol></nav>
      <a class="flex-grow-1" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Przełącz pasek boczny" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
      </a>
      <button type="button" class="btn quarto-search-button" aria-label="Szukaj" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header sidebar-header-stacked">
      <a href="./index.html" class="sidebar-logo-link">
      <img src="./images/logo.png" alt="" class="sidebar-logo py-0 d-lg-inline d-none">
      </a>
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Automatyczna analiza obrazu</a> 
        <div class="sidebar-tools-main tools-wide">
    <a href="https://twitter.com" title="" class="quarto-navigation-tool px-1" aria-label=""><i class="bi bi-twitter"></i></a>
    <a href="https://github.com/dax44/ComputerVision/" title="Source Code" class="quarto-navigation-tool px-1" aria-label="Source Code"><i class="bi bi-github"></i></a>
    <a href="https://twitter.com/intent/tweet?url=|url|" title="Twitter" class="quarto-navigation-tool px-1" aria-label="Twitter"><i class="bi bi-twitter"></i></a>
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Przełącz tryb ciemny"><i class="bi"></i></a>
  <a href="" class="quarto-reader-toggle quarto-navigation-tool px-1" onclick="window.quartoToggleReader(); return false;" title="Przełącz tryb czytnika">
  <div class="quarto-reader-toggle-btn">
  <i class="bi"></i>
  </div>
</a>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Szukaj"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">Wstęp</a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./intro.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Wprowadzenie</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./history.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Historia wizji komputerowej</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./digt_img.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Obrazy cyfrowe</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./transformations.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Transformacje geometryczne</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./point_trans.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Transformacje punktowe</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./filters.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Filtry</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./edge.html" class="sidebar-item-text sidebar-link active"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Wykrywanie krawędzi i konturów</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./morpho.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Filtry morfologiczne</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./fourier.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Transformata Fouriera</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./deeplearning.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Deep learning</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./fundamentals.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Fundamenty DNN</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./convolution.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Sieci splotowe</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./example.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Przykład uczenia sieci splotowej</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./references.html" class="sidebar-item-text sidebar-link">Bibliografia</a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Spis treści</h2>
   
  <ul>
  <li><a href="#wykrywanie-krawędzi-na-podstawie-gradientu" id="toc-wykrywanie-krawędzi-na-podstawie-gradientu" class="nav-link active" data-scroll-target="#wykrywanie-krawędzi-na-podstawie-gradientu"><span class="header-section-number">7.1</span> Wykrywanie krawędzi na podstawie gradientu</a>
  <ul class="collapse">
  <li><a href="#przegląd-filtrów-do-detekcji-krawędzi" id="toc-przegląd-filtrów-do-detekcji-krawędzi" class="nav-link" data-scroll-target="#przegląd-filtrów-do-detekcji-krawędzi"><span class="header-section-number">7.1.1</span> Przegląd filtrów do detekcji krawędzi</a></li>
  </ul></li>
  <li><a href="#wyostrzanie-obrazu" id="toc-wyostrzanie-obrazu" class="nav-link" data-scroll-target="#wyostrzanie-obrazu"><span class="header-section-number">7.2</span> Wyostrzanie obrazu</a>
  <ul class="collapse">
  <li><a href="#filtr-laplacea" id="toc-filtr-laplacea" class="nav-link" data-scroll-target="#filtr-laplacea"><span class="header-section-number">7.2.1</span> Filtr Laplace’a</a></li>
  <li><a href="#metoda-nieostrej-maski" id="toc-metoda-nieostrej-maski" class="nav-link" data-scroll-target="#metoda-nieostrej-maski"><span class="header-section-number">7.2.2</span> Metoda nieostrej maski</a></li>
  </ul></li>
  </ul>
<div class="toc-actions"><div><i class="bi bi-github"></i></div><div class="action-links"><p><a href="https://github.com/dax44/ComputerVision/issues/new" class="toc-action">Zgłoś problem</a></p></div></div></nav>
    </div>
<!-- main -->
<main class="content page-columns page-full" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Wykrywanie krawędzi i konturów</span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  

</header>

<p>Wyróżniające się “wtrącenia” obrazu, pochodzące z lokalnych zmian intensywności lub koloru, takie jak krawędzie i kontury, mają duże znaczenie dla wizualnej percepcji i interpretacji obrazów. Postrzegana ilość informacji w obrazie wydaje się być bezpośrednio związana z wyrazistością zawartych w nim struktur i nieciągłości. W rzeczywistości, struktury i kontury przypominające krawędzie wydają się być tak ważne dla naszego ludzkiego systemu wizualnego, że kilka linii na karykaturze lub ilustracji często wystarcza, aby jednoznacznie opisać obiekt lub scenę. Nie jest więc zaskoczeniem, że wzmacnianie i wykrywanie krawędzi jest tradycyjnym i ważnym tematem również w przetwarzaniu obrazów. W tym rozdziale najpierw przyjrzymy się prostym metodom lokalizacji krawędzi, a następnie zajmiemy się powiązanym z nimi zagadnieniem wyostrzania obrazu.</p>
<p>Krawędzie i kontury odgrywają dominującą rolę w ludzkim widzeniu i prawdopodobnie także w wielu innych biologicznych systemach widzenia. Krawędzie nie tylko rzucają się w oczy, ale często można opisać lub zrekonstruować całą figurę na podstawie kilku kluczowych linii, jak pokazuje przykład na <a href="#fig-contour1">Rysunek&nbsp;<span>7.1</span></a>. Jak jednak powstają krawędzie i jak można je technicznie zlokalizować w obrazie?</p>
<div class="cell">
<details>
<summary>Kod</summary>
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(imager)</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="fu">layout</span>(<span class="fu">t</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">2</span>))</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a>boats <span class="sc">|&gt;</span> </span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">grayscale</span>() <span class="sc">|&gt;</span> </span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">plot</span>()</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>boats <span class="sc">|&gt;</span> </span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">grayscale</span>() <span class="sc">|&gt;</span> </span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">cannyEdges</span>(<span class="at">alpha =</span> <span class="fl">0.5</span>) <span class="sc">|&gt;</span> </span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">plot</span>()</span></code><button title="Kopiuj do schowka" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div id="fig-contour1" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="edge_files/figure-html/fig-contour1-1.png" class="img-fluid figure-img" width="672"></p>
<p></p><figcaption class="figure-caption">Rysunek&nbsp;7.1: Przykład detekcji konturów</figcaption><p></p>
</figure>
</div>
</div>
</div>
<p>Krawędzie można z grubsza opisać jako miejsca na obrazie, w których natężenie światła zmienia się wyraźnie wzdłuż określonej orientacji. Im silniejsza jest lokalna zmiana intensywności, tym większy jest dowód na istnienie krawędzi w tym miejscu. W matematyce wielkość zmiany w odniesieniu do odległości przestrzennej jest znana jako pierwsza pochodna funkcji, dlatego wychodzimy od tego pojęcia, aby stworzyć nasz pierwszy prosty detektor krawędzi.</p>
<section id="wykrywanie-krawędzi-na-podstawie-gradientu" class="level2 page-columns page-full" data-number="7.1">
<h2 data-number="7.1" class="anchored" data-anchor-id="wykrywanie-krawędzi-na-podstawie-gradientu"><span class="header-section-number">7.1</span> Wykrywanie krawędzi na podstawie gradientu</h2>
<p>Dla uproszczenia, najpierw zbadamy sytuację tylko w jednym wymiarze, zakładając, że obraz zawiera pojedynczy jasny obszar w centrum otoczony ciemnym tłem (<a href="#fig-grad2">Rysunek&nbsp;<span>7.2</span></a> (a)). W tym przypadku profil natężenia wzdłuż jednej linii obrazu wyglądałby jak funkcja 1D <span class="math inline">\(f(x)\)</span>, jak pokazano na <a href="#fig-grad2">Rysunek&nbsp;<span>7.2</span></a> (b). Biorąc pierwszą pochodną funkcji <span class="math inline">\(f\)</span></p>
<p><span id="eq-gradient"><span class="math display">\[
f'(x)=\frac{df}{dx}(x),
\tag{7.1}\]</span></span></p>
<p>powoduje dodatnie wahnięcie w tych miejscach, gdzie intensywność wzrasta i ujemne wahnięcie tam, gdzie wartość funkcji spada (<a href="#fig-grad2">Rysunek&nbsp;<span>7.2</span></a> (c)).</p>
<div id="fig-grad2" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="images/Zrzut ekranu 2023-02-9 o 21.13.51.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">Rysunek&nbsp;7.2: Przykładowy obraz z wyraźną zmianą jasności</figcaption><p></p>
</figure>
</div>
<p>W przeciwieństwie do przypadku ciągłego, pierwsza pochodna jest nieokreślona dla funkcji dyskretnej <span class="math inline">\(f(u)\)</span> i potrzebna jest jakaś metoda, by ją oszacować. <a href="#fig-grad3">Rysunek&nbsp;<span>7.3</span></a> pokazuje podstawową ideę, ponownie dla przypadku 1D: pierwsza pochodna funkcji ciągłej w pozycji <span class="math inline">\(x\)</span> może być interpretowana jako nachylenie jej stycznej w tej pozycji. Jedną z prostych metod przybliżonego określenia nachylenia stycznej dla funkcji dyskretnej <span class="math inline">\(f(u)\)</span> jest dopasowanie linii prostej przechodzącej przez wartości funkcji <span class="math inline">\(f(u-1)\)</span> i <span class="math inline">\(f(u+1)\)</span> w sąsiedztwie <span class="math inline">\(u\)</span></p>
<p><span id="eq-grad2"><span class="math display">\[
\frac{df}{dx}(u)\approx\frac{f(u+1)-f(u-1)}{2}.
\tag{7.2}\]</span></span></p>
<p>Oczywiście tę samą metodę można zastosować w kierunku pionowym, aby oszacować pierwszą pochodną wzdłuż osi y, czyli wzdłuż kolumn obrazu.</p>
<div id="fig-grad3" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="images/Zrzut ekranu 2023-02-9 o 21.12.43.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">Rysunek&nbsp;7.3: Oszacowanie gradientu dla funkcji dyskretnej</figcaption><p></p>
</figure>
</div>
<p>W przypadku funkcji wielowymiarowej obliczamy pochodne cząstkowe <span class="math inline">\(I_u = \frac{\partial I(u,v)}{\partial u}\)</span> i <span class="math inline">\(I_v = \frac{\partial I(u,v)}{\partial v}\)</span> funkcji obrazu 2D <span class="math inline">\(I(u, v)\)</span> odpowiednio wzdłuż osi <span class="math inline">\(u\)</span> i <span class="math inline">\(v\)</span>. Wektor</p>
<p><span id="eq-grad3"><span class="math display">\[
\nabla I(u,v)= \begin{bmatrix}
  I_u(u,v)\\
  I_v(u,v)
\end{bmatrix}
\tag{7.3}\]</span></span></p>
<p>nazywamy gradientem funkcji <span class="math inline">\(I\)</span> w punkcie <span class="math inline">\((u, v)\)</span>. Długość gradientu</p>
<p><span id="eq-grad4"><span class="math display">\[
\vert \nabla I\vert = \sqrt{I_u^2+I_v^2}
\tag{7.4}\]</span></span></p>
<div class="page-columns page-full"><p>jest niezmienna ze względu na obroty obrazu, a więc niezależna od orientacji leżących u jego podstaw struktur. Własność ta jest istotna dla izotropowej<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a> lokalizacji krawędzi, a zatem <span class="math inline">\(\vert\nabla I\vert\)</span> jest podstawą wielu praktycznych metod detekcji krawędzi.</p><div class="no-row-height column-margin column-container"><li id="fn1"><p><sup>1</sup>&nbsp;we wszystkich kierunkach wykazują one te same właściwości fizyczne</p></li></div></div>
<p>Składowe funkcji gradientu (<a href="#eq-grad3">Równanie&nbsp;<span>7.3</span></a>) są po prostu pierwszymi pochodnymi wierszy i kolumn obrazu odpowiednio wzdłuż osi poziomej i pionowej. Aproksymacja pierwszych pochodnych poziomych (<a href="#eq-grad2">Równanie&nbsp;<span>7.2</span></a>) może być łatwo zrealizowana przez filtr liniowy z jądrem 1D</p>
<p><span id="eq-grad5"><span class="math display">\[
H_u^D = [-0.5,0,0.5]
\tag{7.5}\]</span></span></p>
<p>gdzie współczynniki -0.5 i 0.5 stosujemy do elementów obrazu <span class="math inline">\(I(u-1, v)\)</span> i <span class="math inline">\(I(u+1, v)\)</span> odpowiednio. Zauważmy, że sam piksel środkowy <span class="math inline">\(I(u, v)\)</span> jest z wagą zerową, a więc jest ignorowany. Analogicznie, pionowa składowa gradientu jest uzyskiwana za pomocą filtru liniowego</p>
<p><span id="eq-grad6"><span class="math display">\[
H^D_v= \begin{bmatrix}
  -0.5\\
  0\\
  0.5
\end{bmatrix}
\tag{7.6}\]</span></span></p>
<p>Rysunek 6.4 przedstawia wynik zastosowania filtrów gradientowych zdefiniowanych w <a href="#eq-grad5">Równanie&nbsp;<span>7.5</span></a> i <a href="#eq-grad6">Równanie&nbsp;<span>7.6</span></a> do syntetycznego obrazu testowego. Widać wyraźnie zależność odpowiedzi filtrów od orientacji. Filtr gradientu poziomego <span class="math inline">\(H_u^D\)</span> reaguje najsilniej na szybkie zmiany wzdłuż kierunku poziomego, (czyli na krawędzie pionowe); analogicznie filtr gradientu pionowego <span class="math inline">\(H_v^D\)</span> reaguje najsilniej na krawędzie poziome. W płaskich obszarach obrazu (przedstawionych jako szare na <a href="#fig-grad4">Rysunek&nbsp;<span>7.4</span></a> (b, c)) reakcja filtra jest zerowa.</p>
<div id="fig-grad4" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="images/Zrzut ekranu 2023-02-9 o 21.38.12.png" class="img-fluid figure-img" width="500"></p>
<p></p><figcaption class="figure-caption">Rysunek&nbsp;7.4: Zastosowanie metody gradientowej do obrazu 2D</figcaption><p></p>
</figure>
</div>
<p>Lokalne gradienty funkcji obrazu są podstawą wielu klasycznych operatorów detekcji krawędzi. Praktycznie różnią się one jedynie rodzajem filtra stosowanego do estymacji składowych gradientu oraz sposobem łączenia tych składowych. W wielu sytuacjach człowiek jest zainteresowany nie tylko natężeniem punktów krawędziowych, ale także lokalnym kierunkiem krawędzi. Oba rodzaje informacji zawarte są w funkcji gradientu i mogą być łatwo obliczone ze składowych kierunkowych. Poniższy niewielki zbiór opisuje kilka często używanych, prostych operatorów krawędziowych, które istnieją od wielu lat, a więc są interesujące również z historycznego punktu widzenia.</p>
<section id="przegląd-filtrów-do-detekcji-krawędzi" class="level3 page-columns page-full" data-number="7.1.1">
<h3 data-number="7.1.1" class="anchored" data-anchor-id="przegląd-filtrów-do-detekcji-krawędzi"><span class="header-section-number">7.1.1</span> Przegląd filtrów do detekcji krawędzi</h3>
<section id="filtry-prewitta-i-sobela" class="level4" data-number="7.1.1.1">
<h4 data-number="7.1.1.1" class="anchored" data-anchor-id="filtry-prewitta-i-sobela"><span class="header-section-number">7.1.1.1</span> Filtry Prewitta i Sobela</h4>
<p>Operatory krawędziowe autorstwa Prewitta <span class="citation" data-cites="PictureProcessingPsychopictorics">(<a href="references.html#ref-PictureProcessingPsychopictorics" role="doc-biblioref"><span>„Picture <span>Processing</span> and <span>Psychopictorics</span> - 1st <span>Edition</span>”</span>, b.d.</a>)</span> i Sobela <span class="citation" data-cites="davisSurveyEdgeDetection1975">(<a href="references.html#ref-davisSurveyEdgeDetection1975" role="doc-biblioref">Davis 1975</a>)</span> to dwie klasyczne metody, które różnią się tylko nieznacznie stosowanymi przez nie filtrami pochodnymi.</p>
<p>Oba operatory wykorzystują filtry liniowe, które rozciągają się odpowiednio na trzy sąsiednie wiersze i kolumny, aby przeciwdziałać wrażliwości na szumy prostych (pojedynczy wiersz/kolumna) operatorów gradientowych. Operator Prewitta wykorzystuje jądra postaci</p>
<p><span id="eq-prewitt"><span class="math display">\[
H^P_u= \begin{bmatrix}
  -1&amp; 0&amp; 1\\
  -1&amp; 0&amp; 1\\
  -1&amp; 0&amp; 1
\end{bmatrix}
\quad\text{i}\quad
H^P_v=\begin{bmatrix}
  -1&amp;-1&amp;-1\\
  0&amp;0&amp;0\\
  1&amp;1&amp;1
\end{bmatrix}
\tag{7.7}\]</span></span></p>
<p>które obliczają średnie gradientu odpowiednio w trzech sąsiednich wierszach lub kolumnach. Podczas gdy filtry Sobela definiuje się w postaci</p>
<p><span id="eq-sobel"><span class="math display">\[
H^S_u= \begin{bmatrix}
  -1&amp;0&amp;1\\
  -2&amp;0&amp;2\\
  -1&amp;0&amp;1
\end{bmatrix}
\quad \text{i}\quad
H^S_v=\begin{bmatrix}
  -1&amp;-2&amp;-1\\
  0&amp;0&amp;0\\
  1&amp;2&amp;1
\end{bmatrix}
\tag{7.8}\]</span></span></p>
<p>czyli jak widać są podobne do filtrów Prewitta z tą różnicą, że część wygładzająca przypisuje większą wagę do aktualnej linii środkowej i kolumny odpowiednio. W przypadku obu filtrów długość wektora gradientu krawędzi jest określona przez</p>
<p><span id="eq-edge1"><span class="math display">\[
E(u,v)=\sqrt{I_u^2(u,v)+I_v^2(u,v)},
\tag{7.9}\]</span></span></p>
<p>gdzie <span class="math inline">\(I_u\)</span> i <span class="math inline">\(I_v\)</span> powstały przez mnożenie <span class="math inline">\(I*H\)</span> (<span class="math inline">\(H\)</span> jest filtrem Prewitta lub Sobela). Natomiast lokalny kąt orientacji krawędzi jest równy</p>
<p><span id="eq-edge2"><span class="math display">\[
\Phi(u,v)=\tan^{-1}\left(\frac{I_u(u,v)}{I_v(u,v)}\right)
\tag{7.10}\]</span></span></p>
<div id="fig-edge1" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="images/Zrzut ekranu 2023-02-9 o 22.16.59.png" class="img-fluid figure-img" width="400"></p>
<p></p><figcaption class="figure-caption">Rysunek&nbsp;7.5: Ilustracja dla długości wektora gradientu i orientacji krawędzi</figcaption><p></p>
</figure>
</div>
<p>Cały proces ekstrakcji wielkości i orientacji krawędzi jest podsumowany na <a href="#fig-edge2">Rysunek&nbsp;<span>7.6</span></a>. Najpierw oryginalny obraz <span class="math inline">\(I\)</span> jest niezależnie splatany z dwoma filtrami gradientowymi <span class="math inline">\(H_u\)</span> i <span class="math inline">\(H_v\)</span>, a następnie z filtrów obliczana jest długość wektora gradientu krawędzi <span class="math inline">\(E\)</span> i orientacja <span class="math inline">\(\Phi\)</span>.</p>
<div id="fig-edge2" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="images/Zrzut ekranu 2023-02-9 o 22.20.43.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">Rysunek&nbsp;7.6: Przykładowy proces ekstrakcji krawędzi</figcaption><p></p>
</figure>
</div>
</section>
<section id="filtry-robertsa" class="level4" data-number="7.1.1.2">
<h4 data-number="7.1.1.2" class="anchored" data-anchor-id="filtry-robertsa"><span class="header-section-number">7.1.1.2</span> Filtry Roberts’a</h4>
<p>Jako jeden z najprostszych i najstarszych detektorów krawędzi, operator Robertsa <span class="citation" data-cites="OpticalElectroOpticalInformation">(<a href="references.html#ref-OpticalElectroOpticalInformation" role="doc-biblioref"><span>„Optical and <span>Electro-Optical Information Processing</span>”</span>, b.d.</a>)</span> ma dziś głównie znaczenie historyczne. Wykorzystuje on dwa niezwykle małe filtry o rozmiarach 2 × 2 do estymacji gradientu kierunkowego wzdłuż przekątnych obrazu. Zdefiniowane są one za pomocą jądra</p>
<p><span id="eq-roberts"><span class="math display">\[
H^R_1= \begin{bmatrix}
  0&amp;1\\
  -1&amp;0
\end{bmatrix}\quad\text{i}\quad
H^R_2= \begin{bmatrix}
  -1&amp;0\\
  0&amp;1
\end{bmatrix}
\tag{7.11}\]</span></span></p>
<p>Projektowanie liniowych filtrów krawędziowych wiąże się z pewnym kompromisem: im silniej filtr reaguje na struktury podobne do krawędzi, tym bardziej wrażliwy jest na orientację. Innymi słowy, filtry niewrażliwe na orientację mają tendencję do reagowania na struktury nie będące krawędziami, podczas gdy najbardziej dyskryminujące filtry krawędziowe reagują tylko na krawędzie w wąskim zakresie orientacji. Jednym z rozwiązań jest zastosowanie nie tylko pojedynczej pary stosunkowo “szerokich” filtrów dla dwóch kierunków (takich jak Prewitta i Sobela), ale większego zestawu filtrów o ciasno rozłożonych orientacjach.</p>
</section>
<section id="rozszerzony-filtr-sobela" class="level4" data-number="7.1.1.3">
<h4 data-number="7.1.1.3" class="anchored" data-anchor-id="rozszerzony-filtr-sobela"><span class="header-section-number">7.1.1.3</span> Rozszerzony filtr Sobela</h4>
<p>Tym razem zastosujemy 8 filtrów zmieniając orientację o <span class="math inline">\(45\degree\)</span>.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/Zrzut ekranu 2023-02-9 o 22.50.58.png" class="img-fluid figure-img" width="400"></p>
</figure>
</div>
</section>
<section id="filtr-kirscha" class="level4 page-columns page-full" data-number="7.1.1.4">
<h4 data-number="7.1.1.4" class="anchored" data-anchor-id="filtr-kirscha"><span class="header-section-number">7.1.1.4</span> Filtr Kirscha</h4>
<p>Innym klasycznym operatorem kompasu jest operator zaproponowany przez Kirscha <span class="citation" data-cites="kirschComputerDeterminationConstituent1971">(<a href="references.html#ref-kirschComputerDeterminationConstituent1971" role="doc-biblioref">Kirsch 1971</a>)</span>, który również wykorzystuje osiem zorientowanych filtrów o następujących kernelach</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/Zrzut ekranu 2023-02-9 o 22.51.18.png" class="img-fluid figure-img" width="400"></p>
</figure>
</div>
<p>Jednym z problemów z operatorami do wykrywania krawędzi opartymi na pierwszych pochodnych jest to, że każda wynikowa krawędź jest tak szeroka jak przedział zmiany intensywności, a zatem krawędzie mogą być trudne do precyzyjnego zlokalizowania. Alternatywna klasa operatorów krawędzi wykorzystuje drugie pochodne funkcji obrazu.</p>
<div id="fig-edge3" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="images/Zrzut ekranu 2023-02-9 o 23.04.02.png" class="img-fluid figure-img" width="500"></p>
<p></p><figcaption class="figure-caption">Rysunek&nbsp;7.7: Zastosowanie drugiej pochodnej w detekcji krawędzi</figcaption><p></p>
</figure>
</div>
<p>Druga pochodna funkcji mierzy jej lokalną krzywiznę. Idea jest taka, że krawędzie można znaleźć w miejscach zerowych lub - jeszcze lepiej - w miejscach zerowych drugich pochodnych funkcji obrazu, jak pokazano na <a href="#fig-edge3">Rysunek&nbsp;<span>7.7</span></a> dla przypadku 1D. Ponieważ drugie pochodne mają tendencję do wzmacniania szumu obrazu, zwykle stosuje się pewien rodzaj wygładzania wstępnego za pomocą odpowiednich filtrów dolnoprzepustowych.</p>
<p>Popularnym przykładem jest operator “Laplacian-of-Gaussian” (LoG) <span class="citation" data-cites="marrTheoryEdgeDetection1980">(<a href="references.html#ref-marrTheoryEdgeDetection1980" role="doc-biblioref">Marr i Hildreth 1980</a>)</span>, który łączy wygładzanie gussowskie i obliczanie drugich pochodnych w jeden filtr liniowy. Przykład na <a href="#fig-edge4">Rysunek&nbsp;<span>7.8</span></a> pokazuje, że krawędzie uzyskane za pomocą operatora LoG są dokładniej zlokalizowane niż te dostarczone przez operatory Prewitta i Sobela.</p>
<p>Niestety, wyniki działania prostych operatorów krawędziowych, o których mówiliśmy do tej pory, często odbiegają od tego, co my jako ludzie postrzegamy jako ważne krawędzie. Dwie główne przyczyny tego stanu rzeczy to:</p>
<ul>
<li>Po pierwsze, operatory krawędziowe reagują jedynie na lokalne różnice intensywności, podczas gdy nasz system wzrokowy jest w stanie rozpoznać krawędzie na obszarach o minimalnym lub zanikającym kontraście.</li>
<li>Po drugie, krawędzie istnieją nie w jednej stałej rozdzielczości czy w pewnej skali, ale w całym szeregu różnych skal.</li>
</ul>
<p>Typowe małe operatory krawędzi, takie jak operator Sobela, mogą reagować tylko na różnice intensywności, które występują w obrębie ich regionów filtrów 3x3 piksele. Aby rozpoznać wtrącenia podobne do krawędzi w większym zakresie, potrzebowalibyśmy albo większych operatorów krawędzi (z odpowiednio dużymi filtrami), albo użyć oryginalnych (małych) operatorów na zredukowanych (tj. przeskalowanych) obrazach. Jest to główna idea technik “multiresolution” (zwanych również “hierarchicznymi” lub “piramidowymi”), które tradycyjnie są wykorzystywane w wielu zastosowaniach przetwarzania obrazów. W kontekście wykrywania krawędzi, sprowadza się to zazwyczaj do wykrywania najpierw krawędzi na różnych poziomach skali, a następnie decydowania, która krawędź (jeśli w ogóle) na danym poziomie skali jest dominująca w każdej pozycji obrazu.</p>
<p>W wielu sytuacjach, kolejnym krokiem po wzmocnieniu krawędzi (przez jakiś operator krawędziowy) jest wybór punktów krawędziowych, czyli binarna decyzja o tym, czy piksel obrazu jest punktem krawędziowym czy nie. Najprostszą metodą jest zastosowanie operacji progowania do długości wektora gradientu krawędzi dostarczonej przez operator krawędzi, przy użyciu stałej lub adaptacyjnej wartości progowej, co daje binarny obraz krawędzi lub “mapę krawędzi”.</p>
<div class="page-columns page-full"><p>W praktyce mapy krawędzi rzadko zawierają idealne kontury, ale zamiast tego wiele małych, niepołączonych fragmentów konturów, przerwanych w miejscach o niewystarczającej sile krawędzi<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a>. Po progowaniu puste miejsca nie zawierają oczywiście żadnej informacji o krawędziach, która mogłaby zostać wykorzystana w kolejnym kroku, np. do łączenia sąsiadujących segmentów krawędzi. Pomimo tej słabości, globalne progowanie jest często stosowane w tym momencie ze względu na swoją prostotę.</p><div class="no-row-height column-margin column-container"><li id="fn2"><p><sup>2</sup>&nbsp;wyrażonej długością wektora gradientu krawędzi</p></li></div></div>
<p>Idea sekwencyjnego śledzenia konturów wzdłuż odkrytych punktów krawędziowych nie jest rzadkością i wydaje się dość prosta w założeniu. Rozpoczynając od punktu obrazu o dużej sile krawędzi, podąża się iteracyjnie w obu kierunkach, aż do momentu, gdy oba ślady spotkają się i powstanie zamknięty kontur. Niestety, istnieje kilka przeszkód, które sprawiają, że zadanie to jest trudniejsze niż się początkowo wydaje, m.in:</p>
<ul>
<li>krawędzie mogą kończyć się w regionach zanikającego gradientu intensywności,</li>
<li>przecinające się krawędzie prowadzą do niejednoznaczności,</li>
<li>kontury mogą się rozgałęziać w kilku kierunkach.</li>
</ul>
<p>Ze względu na te problemy, śledzenie konturów zazwyczaj nie jest stosowane do obrazów oryginalnych lub obrazów o ciągłej wartości krawędzi, z wyjątkiem bardzo prostych sytuacji, takich jak wyraźne oddzielenie obiektów (pierwszego planu) od tła. Śledzenie konturów w segmentowanych obrazach binarnych jest oczywiście znacznie prostsze.</p>
</section>
<section id="filtry-cannyego" class="level4 page-columns page-full" data-number="7.1.1.5">
<h4 data-number="7.1.1.5" class="anchored" data-anchor-id="filtry-cannyego"><span class="header-section-number">7.1.1.5</span> Filtry Canny’ego</h4>
<div class="page-columns page-full"><p>Operator zaproponowany przez Canny’ego jest szeroko stosowany i nadal uważany za “state of the art”<a href="#fn3" class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a> w detekcji krawędzi. Metoda ta stara się osiągnąć trzy główne cele:</p><div class="no-row-height column-margin column-container"><li id="fn3"><p><sup>3</sup>&nbsp;najwyższe osiągnięcie w danej dziedzinie</p></li></div></div>
<ul>
<li>zminimalizować liczbę fałszywych punktów krawędziowych,</li>
<li>osiągnąć dobrą lokalizację krawędzi</li>
<li>dostarczyć tylko pojedynczy znak na każdej krawędzi.</li>
</ul>
<p>Właściwości te nie są zwykle osiągane przez proste operatory krawędziowe (najczęściej oparte na pierwszych pochodnych i późniejszym progowaniu). W swej istocie filtr Canny’ego jest metodą gradientową (opartą na pierwszych pochodnych), ale do precyzyjnej lokalizacji krawędzi wykorzystuje miejsca zerowe drugich pochodnych. Pod tym względem metoda ta jest podobna do detektorów krawędzi, które bazują na drugich pochodnych funkcji obrazu <span class="citation" data-cites="cannyComputationalApproachEdge1986">(<a href="references.html#ref-cannyComputationalApproachEdge1986" role="doc-biblioref">Canny 1986</a>)</span>.</p>
<div id="fig-edge4" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="images/Zrzut ekranu 2023-02-9 o 23.05.19.png" class="img-fluid figure-img" width="500"></p>
<p></p><figcaption class="figure-caption">Rysunek&nbsp;7.8: Przykłady zastosowania różnych detektorów krawędzi</figcaption><p></p>
</figure>
</div>
<p>W pełni zaimplementowany detektor Canny’ego wykorzystuje zestaw stosunkowo dużych, zorientowanych filtrów przy wielu rozdzielczościach obrazu i łączy poszczególne wyniki we wspólną mapę krawędzi. Często jednak stosuje się tylko jednoskalową implementację algorytmu z regulowanym promieniem filtra (parametr wygładzania <span class="math inline">\(\sigma\)</span>), która jednak przewyższa większość prostych operatorów krawędziowych. Ponadto algorytm ten daje nie tylko binarną mapę krawędzi, ale także połączone łańcuchy pikseli krawędziowych, co znacznie upraszcza kolejne etapy przetwarzania. Dlatego nawet w swojej podstawowej (jednoskalowej) postaci operator Canny’ego jest często preferowany w stosunku do innych metod detekcji krawędzi. W swojej podstawowej (jednoskalowej) postaci operator Canny’ego wykonuje następujące kroki:</p>
<ol type="1">
<li>Obróbka wstępna - Oryginalny obraz intensywności <span class="math inline">\(I\)</span> jest najpierw wygładzany jądrem filtra gaussowskiego <span class="math inline">\(H^{G,\sigma}\)</span>; jego szerokość <span class="math inline">\(\sigma\)</span> określa skalę przestrzenną, w której mają być wykrywane krawędzie. Następnie na wygładzony obraz <span class="math inline">\(\bar{I}\)</span> nakładane są filtry różnicowe pierwszego rzędu w celu obliczenia składowych <span class="math inline">\(\bar{I}_u,\bar{I}_v\)</span> lokalnych wektorów gradientu. Następnie obliczana jest lokalna wielkość <span class="math inline">\(E_{mag}\)</span> jako norma odpowiadającego wektora gradientu. Ze względu na późniejsze progowanie pomocne może być znormalizowanie wartości siły krawędzi do standardowego zakresu (np. do [0, 100]).</li>
<li>Lokalizacja krawędzi - Kandydackie piksele krawędziowe są izolowane poprzez lokalne “non-maximum suppression” siły krawędzi <span class="math inline">\(E_{mag}\)</span>. W tym kroku zachowywane są tylko te piksele, które reprezentują lokalne maksimum wzdłuż profilu 1D w kierunku gradientu, czyli prostopadle do stycznej krawędzi (patrz <a href="#fig-edge5">Rysunek&nbsp;<span>7.9</span></a>). Chociaż gradient może być skierowany w dowolnym kierunku, to dla ułatwienia efektywnego przetwarzania stosuje się zwykle tylko cztery dyskretne kierunki. Piksel w pozycji <span class="math inline">\((u,v)\)</span> jest traktowany jako kandydat na krawędź tylko wtedy, gdy wielkość jego gradientu jest większa niż obu jego bezpośrednich sąsiadów w kierunku określonym przez wektor gradientu <span class="math inline">\((dx,dy)\)</span> w pozycji <span class="math inline">\((u,v)\)</span>. Jeśli piksel nie jest lokalnym maksimum, jego wartość siły krawędzi jest ustawiona na zero (tj. “stłumiona”).</li>
<li>Śledzenie krawędzi i progowanie z histerezą - W ostatnim kroku zbiory połączonych punktów brzegowych są zbierane z wartości, które pozostały nietłumione w poprzedniej operacji. Dokonuje się tego za pomocą techniki zwanej “progowaniem z histerezą” z wykorzystaniem dwóch różnych wartości progowych , <span class="math inline">\(t_{lo}\)</span> (przy czym <span class="math inline">\(t_{hi} &gt; t_{lo}\)</span>). Obraz jest skanowany w poszukiwaniu pikseli o wielkości krawędzi <span class="math inline">\(E_{nms}(u, v) \geq t_{hi}\)</span>. W każdym przypadku znalezienia takiego (wcześniej nie odwiedzanego) miejsca, uruchamiany jest nowy ślad krawędziowy i dodawane są do niego wszystkie połączone piksele krawędziowe <span class="math inline">\((u′,v′)\)</span>, dopóki <span class="math inline">\(E_nms(u′,v′) \geq t_{lo}\)</span>. Pozostają tylko te ślady krawędzi, które zawierają co najmniej jeden piksel o wielkości krawędzi większej niż <span class="math inline">\(t_{hi}\)</span> i żadnych pikseli o wielkości krawędzi mniejszej niż <span class="math inline">\(t_{lo}\)</span>. Typowe wartości progów dla 8-bitowych obrazów w skali szarości to <span class="math inline">\(t_{hi} = 5.0\)</span> i <span class="math inline">\(t_{lo} = 2.5\)</span>.</li>
</ol>
<div id="fig-edge5" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="images/Zrzut ekranu 2023-02-9 o 23.54.54.png" class="img-fluid figure-img" width="500"></p>
<p></p><figcaption class="figure-caption">Rysunek&nbsp;7.9: Zasada działania filtru Canny’ego</figcaption><p></p>
</figure>
</div>
</section>
</section>
</section>
<section id="wyostrzanie-obrazu" class="level2 page-columns page-full" data-number="7.2">
<h2 data-number="7.2" class="anchored" data-anchor-id="wyostrzanie-obrazu"><span class="header-section-number">7.2</span> Wyostrzanie obrazu</h2>
<p>Wyostrzanie obrazów (ang. <em>sharpening</em>) jest częstym zadaniem, np. w celu poprawy ostrości po zeskanowaniu lub przeskalowaniu obrazu lub w celu wstępnej kompensacji późniejszej utraty ostrości w trakcie drukowania lub wyświetlania obrazu. Powszechnym podejściem do wyostrzania obrazu jest wzmacnianie wysokoczęstotliwościowych (ang. <em>hight-frequency amplifying</em>) składowych obrazu, które są głównie odpowiedzialne za postrzeganą ostrość obrazu i dla których najsilniejsze występują przy szybkich zmianach intensywności. W dalszej części opisujemy dwie metody sztucznego wyostrzania obrazu, które opierają się na technikach podobnych do detekcji krawędzi.</p>
<section id="filtr-laplacea" class="level3" data-number="7.2.1">
<h3 data-number="7.2.1" class="anchored" data-anchor-id="filtr-laplacea"><span class="header-section-number">7.2.1</span> Filtr Laplace’a</h3>
<div id="fig-sharp1" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="images/Zrzut ekranu 2023-02-10 o 16.39.04.png" class="img-fluid figure-img" width="400"></p>
<p></p><figcaption class="figure-caption">Rysunek&nbsp;7.10: Wyostrzanie obrazu za pomocą drugich pochodnych</figcaption><p></p>
</figure>
</div>
<p>Popularną metodą lokalizacji szybkich zmian intensywności są filtry oparte na drugich pochodnych funkcji obrazu. <a href="#fig-sharp1">Rysunek&nbsp;<span>7.10</span></a> ilustruje tę ideę dla obrazu 1D i ciągłej funkcji <span class="math inline">\(f(x)\)</span>. Druga pochodna <span class="math inline">\(f''(x)\)</span> funkcji schodkowej pokazuje dodatni impuls na dolnym końcu przejścia i ujemny impuls na górnym końcu. Krawędź wyostrza się przez odjęcie pewnego ułamka w drugiej pochodnej <span class="math inline">\(f''(x)\)</span> od oryginalnej funkcji <span class="math inline">\(f(x)\)</span></p>
<p><span id="eq-sharp1"><span class="math display">\[
\hat{f}(x)=f(x)-w\cdot f''(x).
\tag{7.12}\]</span></span></p>
<p>W zależności od współczynnika wagowego <span class="math inline">\(w\geq0\)</span>, wyrażenie w <a href="#eq-sharp1">Równanie&nbsp;<span>7.12</span></a> powoduje, że funkcja intensywności przeskakuje po obu stronach krawędzi, co powoduje wyolbrzymienie krawędzi i zwiększenie postrzeganej ostrości.</p>
<p>Wyostrzenie funkcji 2D można uzyskać za pomocą drugich pochodnych w kierunku poziomym i pionowym połączonych tzw. operatorem Laplace’a. Operator Laplace’a <span class="math inline">\(\nabla^2\)</span> funkcji 2D <span class="math inline">\(f(x, y)\)</span> jest zdefiniowany jako suma drugich pochodnych cząstkowych wzdłuż kierunków <span class="math inline">\(x\)</span> i <span class="math inline">\(y\)</span>:</p>
<p><span id="eq-sharp2"><span class="math display">\[
(\nabla^2f)(x,y)=\frac{\partial^2 f}{\partial^2 x}(x,y)+\frac{\partial^2 f}{\partial^2 y}(x,y).
\tag{7.13}\]</span></span></p>
<p>Podobnie jak w przypadku pierwszych pochodnych, również drugie pochodne funkcji obrazu dyskretnego mogą być estymowane za pomocą zestawu prostych filtrów liniowych. Również w tym przypadku zaproponowano kilka wersji. Na przykład, dwa filtry 1D:</p>
<p><span id="eq-sharp3"><span class="math display">\[
\frac{\partial^2 f}{\partial^2 x}\approx H_x^L= \begin{bmatrix}
  1 &amp;-2 &amp;1
\end{bmatrix}\quad\text{i}\quad \frac{\partial^2 f}{\partial^2 y}\approx H_y^L=
\begin{bmatrix}
  1\\
  -2\\
  1
\end{bmatrix}.
\tag{7.14}\]</span></span></p>
<p>do szacowania drugich pochodnych odpowiednio wzdłuż kierunku <span class="math inline">\(x\)</span> i <span class="math inline">\(y\)</span>, łączą się w filtr Laplace’a 2D:</p>
<p><span id="eq-sharp4"><span class="math display">\[
H^L= \begin{bmatrix}
  0&amp;1&amp;0\\
  1&amp;-4&amp;1\\
  0&amp;1&amp;0
\end{bmatrix}.
\tag{7.15}\]</span></span></p>
<p>Wyostrzanie odbywa się poprzez odjęcie przekształconego obrazu przez filtr Laplace’a od oryginalnego z odpowiednią wagą <span class="math inline">\(w\)</span></p>
<p><span id="eq-sharp45"><span class="math display">\[
I'\leftarrow I-w\cdot (H^L*I).
\tag{7.16}\]</span></span></p>
<p><a href="#fig-sharp2">Rysunek&nbsp;<span>7.11</span></a> przedstawia przykład zastosowania filtru Laplace’a <span class="math inline">\(H^L\)</span> do obrazu w skali szarości, gdzie wyraźnie widoczne są pary dodatnio i ujemnych szczytów po obu stronach każdej krawędzi. Filtr wydaje się niemal izotropowy pomimo grubego przybliżenia za pomocą małych filtrów.</p>
<div id="fig-sharp2" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="images/Zrzut ekranu 2023-02-10 o 16.56.32.png" class="img-fluid figure-img" width="400"></p>
<p></p><figcaption class="figure-caption">Rysunek&nbsp;7.11: Porównanie filtru Laplace’a z filtrami drugich pochodnych</figcaption><p></p>
</figure>
</div>
</section>
<section id="metoda-nieostrej-maski" class="level3 page-columns page-full" data-number="7.2.2">
<h3 data-number="7.2.2" class="anchored" data-anchor-id="metoda-nieostrej-maski"><span class="header-section-number">7.2.2</span> Metoda nieostrej maski</h3>
<p>Metoda nieostrej maski (ang. <em>unsharp masking)</em> (USM) to technika wyostrzania krawędzi, która jest szczególnie popularna w astronomii, druku cyfrowym i wielu innych dziedzinach przetwarzania obrazów. Termin ten wywodzi się z klasycznej fotografii, gdzie ostrość obrazu była optycznie zwiększana poprzez połączenie go z wygładzoną (“nieostrą”) kopią. Proces ten jest w zasadzie taki sam dla obrazów cyfrowych.</p>
<div class="page-columns page-full"><p>Pierwszym krokiem w filtrze USM jest odjęcie od oryginału wygładzonej wersji obrazu, która uwydatnia krawędzie. Wynik ten nazywany jest “maską”. W fotografii analogowej wymagane wygładzenie uzyskiwano przez zwykłe rozogniskowanie obiektywu<a href="#fn4" class="footnote-ref" id="fnref4" role="doc-noteref"><sup>4</sup></a>. Następnie maska jest ponownie dodawana do oryginału, w taki sposób, że krawędzie w obrazie są wyostrzone. Podsumowując, kroki zaangażowane w filtrowanie USM to:</p><div class="no-row-height column-margin column-container"><li id="fn4"><p><sup>4</sup>&nbsp;utratę ostrości</p></li></div></div>
<ol type="1">
<li>Obraz maski <span class="math inline">\(M\)</span> jest generowany przez odjęcie od obrazu oryginalnego <span class="math inline">\(I\)</span> jego wygładzonej wersji, uzyskanej przez filtrowanie za pomocą filtru <span class="math inline">\(\tilde{H}\)</span></li>
</ol>
<p><span id="eq-sharp5"><span class="math display">\[
M\leftarrow I-(I*\tilde{H})=I-\tilde{I}.
\tag{7.17}\]</span></span></p>
<p>Przyjmuje się, że jądro <span class="math inline">\(\tilde{H}\)</span> filtra wygładzającego jest znormalizowane. 2. Aby uzyskać wyostrzony obraz <span class="math inline">\(\check{I}\)</span>, maska <span class="math inline">\(M\)</span> jest dodawana do oryginalnego obrazu <span class="math inline">\(I\)</span> z odpowiednią wagą <span class="math inline">\(a\)</span>, za pomocą której kontrolujemy stopień wyostrzenia</p>
<p><span id="eq-sharp6"><span class="math display">\[
\check{I}\leftarrow I+a\cdot M,
\tag{7.18}\]</span></span> zatem podstawiając <a href="#eq-sharp5">Równanie&nbsp;<span>7.17</span></a> otrzymujemy</p>
<p><span class="math display">\[
\check{I}\leftarrow I+a\cdot (I-\tilde{I})=(1+a)\cdot I-a\cdot \tilde{I}.
\]</span> Jako filtr wygładzający <span class="math inline">\(\tilde{H}\)</span> można właściwie zastosować dowolny filtr wygładzający, choć najczęściej spotyka się w tym miejscu filtry gassowskie <span class="math inline">\(H^{G,\sigma}\)</span> o <span class="math inline">\(\sigma \in [1,20]\)</span>. Natomiast najczęściej przyjmowane wartości dla <span class="math inline">\(a\)</span> mieszczą się w przedziale [0.2,4].</p>
<div class="cell">
<details>
<summary>Kod</summary>
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a>lena <span class="ot">&lt;-</span> Rvision<span class="sc">::</span><span class="fu">image</span>(<span class="st">"images/lena.png"</span>)</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a><span class="fu">layout</span>(<span class="fu">matrix</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">6</span>, <span class="dv">2</span>, <span class="dv">3</span>, <span class="at">byrow =</span> <span class="cn">TRUE</span>))</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(lena)</span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>lena_blr <span class="ot">&lt;-</span> Rvision<span class="sc">::</span><span class="fu">gaussianBlur</span>(lena, <span class="dv">10</span>, <span class="dv">10</span>, <span class="dv">5</span>, <span class="dv">5</span>)</span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(lena_blr)</span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a>maska <span class="ot">&lt;-</span> lena<span class="sc">-</span>lena_blr</span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(maska)</span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a>lena_sharp <span class="ot">&lt;-</span> lena<span class="sc">+</span>maska</span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(lena_sharp)</span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a>lena_flt <span class="ot">&lt;-</span> Rvision<span class="sc">::</span><span class="fu">filter2D</span>(lena, <span class="fu">matrix</span>(<span class="fu">c</span>(<span class="dv">0</span>,<span class="dv">1</span>,<span class="dv">0</span>,</span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true" tabindex="-1"></a>                                    <span class="dv">1</span>,<span class="sc">-</span><span class="dv">4</span>,<span class="dv">1</span>,</span>
<span id="cb2-15"><a href="#cb2-15" aria-hidden="true" tabindex="-1"></a>                                    <span class="dv">0</span>,<span class="dv">1</span>,<span class="dv">0</span>), <span class="at">byrow =</span> T, <span class="at">ncol =</span> <span class="dv">3</span>))</span>
<span id="cb2-16"><a href="#cb2-16" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(lena_flt)</span>
<span id="cb2-17"><a href="#cb2-17" aria-hidden="true" tabindex="-1"></a>(lena<span class="sc">-</span>lena_flt) <span class="sc">|&gt;</span>  <span class="fu">plot</span>()</span></code><button title="Kopiuj do schowka" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div id="fig-sharp4" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="edge_files/figure-html/fig-sharp4-1.png" class="img-fluid figure-img" width="672"></p>
<p></p><figcaption class="figure-caption">Rysunek&nbsp;7.12: Wyostrzenie obrazu Leny. Pierwszy obraz w górnym rzędzie to oryginał, środkowy w górnym rzędzie to rozmyty obraz Leny filtrem gaussowskim, obraz po prawej w górnym rzędzie to maska. Obraz po lewej stronie w dolnym rzędzie to wyostrzony obraz Leny metodą USM. Środkowy obraz w dolnym rzędzie to filtr Laplace’a nałożony na Lenę, a obraz po prawej w dolnym rzędzie to wyostrzony obraz Leny metodą Laplace’a</figcaption><p></p>
</figure>
</div>
</div>
</div>


<div id="refs" class="references csl-bib-body hanging-indent" role="list" style="display: none">
<div id="ref-cannyComputationalApproachEdge1986" class="csl-entry" role="listitem">
Canny, John. 1986. <span>„A <span>Computational Approach</span> to <span>Edge Detection</span>”</span>. <em>IEEE Transactions on Pattern Analysis and Machine Intelligence</em> PAMI-8 (6): 679–98. <a href="https://doi.org/10.1109/TPAMI.1986.4767851">https://doi.org/10.1109/TPAMI.1986.4767851</a>.
</div>
<div id="ref-davisSurveyEdgeDetection1975" class="csl-entry" role="listitem">
Davis, Larry S. 1975. <span>„A Survey of Edge Detection Techniques”</span>. <em>Computer Graphics and Image Processing</em> 4 (3): 248–70. <a href="https://doi.org/10.1016/0146-664X(75)90012-X">https://doi.org/10.1016/0146-664X(75)90012-X</a>.
</div>
<div id="ref-kirschComputerDeterminationConstituent1971" class="csl-entry" role="listitem">
Kirsch, Russell A. 1971. <span>„Computer Determination of the Constituent Structure of Biological Images”</span>. <em>Computers and Biomedical Research</em> 4 (3): 315–28. <a href="https://doi.org/10.1016/0010-4809(71)90034-6">https://doi.org/10.1016/0010-4809(71)90034-6</a>.
</div>
<div id="ref-marrTheoryEdgeDetection1980" class="csl-entry" role="listitem">
Marr, D., i E. Hildreth. 1980. <span>„Theory of Edge Detection”</span>. <em>Proceedings of the Royal Society of London. Series B, Biological Sciences</em> 207 (1167): 187–217. <a href="https://doi.org/10.1098/rspb.1980.0020">https://doi.org/10.1098/rspb.1980.0020</a>.
</div>
<div id="ref-OpticalElectroOpticalInformation" class="csl-entry" role="listitem">
<span>„Optical and <span>Electro-Optical Information Processing</span>”</span>. b.d. <em>MIT Press</em>.
</div>
<div id="ref-PictureProcessingPsychopictorics" class="csl-entry" role="listitem">
<span>„Picture <span>Processing</span> and <span>Psychopictorics</span> - 1st <span>Edition</span>”</span>. b.d. https://www.elsevier.com/books/picture-processing-and-psychopictorics/lipkin/978-0-12-451550-5.
</div>
</div>
</section>
</section>


</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const disableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'prefetch';
    }
  }
  const enableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'stylesheet';
    }
  }
  const manageTransitions = (selector, allowTransitions) => {
    const els = window.document.querySelectorAll(selector);
    for (let i=0; i < els.length; i++) {
      const el = els[i];
      if (allowTransitions) {
        el.classList.remove('notransition');
      } else {
        el.classList.add('notransition');
      }
    }
  }
  const toggleColorMode = (alternate) => {
    // Switch the stylesheets
    const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
    manageTransitions('#quarto-margin-sidebar .nav-link', false);
    if (alternate) {
      enableStylesheet(alternateStylesheets);
      for (const sheetNode of alternateStylesheets) {
        if (sheetNode.id === "quarto-bootstrap") {
          toggleBodyColorMode(sheetNode);
        }
      }
    } else {
      disableStylesheet(alternateStylesheets);
      toggleBodyColorPrimary();
    }
    manageTransitions('#quarto-margin-sidebar .nav-link', true);
    // Switch the toggles
    const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
    for (let i=0; i < toggles.length; i++) {
      const toggle = toggles[i];
      if (toggle) {
        if (alternate) {
          toggle.classList.add("alternate");     
        } else {
          toggle.classList.remove("alternate");
        }
      }
    }
    // Hack to workaround the fact that safari doesn't
    // properly recolor the scrollbar when toggling (#1455)
    if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
      manageTransitions("body", false);
      window.scrollTo(0, 1);
      setTimeout(() => {
        window.scrollTo(0, 0);
        manageTransitions("body", true);
      }, 40);  
    }
  }
  const isFileUrl = () => { 
    return window.location.protocol === 'file:';
  }
  const hasAlternateSentinel = () => {  
    let styleSentinel = getColorSchemeSentinel();
    if (styleSentinel !== null) {
      return styleSentinel === "alternate";
    } else {
      return false;
    }
  }
  const setStyleSentinel = (alternate) => {
    const value = alternate ? "alternate" : "default";
    if (!isFileUrl()) {
      window.localStorage.setItem("quarto-color-scheme", value);
    } else {
      localAlternateSentinel = value;
    }
  }
  const getColorSchemeSentinel = () => {
    if (!isFileUrl()) {
      const storageValue = window.localStorage.getItem("quarto-color-scheme");
      return storageValue != null ? storageValue : localAlternateSentinel;
    } else {
      return localAlternateSentinel;
    }
  }
  let localAlternateSentinel = 'default';
  // Dark / light mode switch
  window.quartoToggleColorScheme = () => {
    // Read the current dark / light value 
    let toAlternate = !hasAlternateSentinel();
    toggleColorMode(toAlternate);
    setStyleSentinel(toAlternate);
  };
  // Ensure there is a toggle, if there isn't float one in the top right
  if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
    const a = window.document.createElement('a');
    a.classList.add('top-right');
    a.classList.add('quarto-color-scheme-toggle');
    a.href = "";
    a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
    const i = window.document.createElement("i");
    i.classList.add('bi');
    a.appendChild(i);
    window.document.body.appendChild(a);
  }
  // Switch to dark mode if need be
  if (hasAlternateSentinel()) {
    toggleColorMode(true);
  } else {
    toggleColorMode(false);
  }
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Skopiowano!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Skopiowano!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./filters.html" class="pagination-link">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Filtry</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./morpho.html" class="pagination-link">
        <span class="nav-page-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Filtry morfologiczne</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">Automatyczna analiza obrazu, Dariusz Majerek</div>   
    <div class="nav-footer-center">
      &nbsp;
    </div>
    <div class="nav-footer-right">Książka została napisana w <a href="https://quarto.org/">Quarto</a></div>
  </div>
</footer>



</body></html>