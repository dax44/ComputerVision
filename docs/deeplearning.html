<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="pl" xml:lang="pl"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.234">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Automatyczna analiza obrazu - 10&nbsp; Deep learning</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./fundamentals.html" rel="next">
<link href="./fourier.html" rel="prev">
<link href="./cover.png" rel="icon" type="image/png">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-dark.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="site_libs/bootstrap/bootstrap-dark.min.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 20,
  "language": {
    "search-no-results-text": "Brak wynikÃ³w",
    "search-matching-documents-text": "dopasowane dokumenty",
    "search-copy-link-title": "Kopiuj link do wyszukiwania",
    "search-hide-matches-text": "Ukryj dodatkowe dopasowania",
    "search-more-match-text": "wiÄ™cej dopasowaÅ„ w tym dokumencie",
    "search-more-matches-text": "wiÄ™cej dopasowaÅ„ w tym dokumencie",
    "search-clear-button-title": "WyczyÅ›Ä‡",
    "search-detached-cancel-button-title": "Anuluj",
    "search-submit-button-title": "ZatwierdÅº"
  }
}</script>

  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

</head>

<body class="nav-sidebar floating slimcontent">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="PrzeÅ‚Ä…cz pasek boczny" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
      <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./deeplearning.html"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Deep learning</span></a></li></ol></nav>
      <a class="flex-grow-1" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="PrzeÅ‚Ä…cz pasek boczny" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
      </a>
      <button type="button" class="btn quarto-search-button" aria-label="Szukaj" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header sidebar-header-stacked">
      <a href="./index.html" class="sidebar-logo-link">
      <img src="./images/logo.png" alt="" class="sidebar-logo py-0 d-lg-inline d-none">
      </a>
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Automatyczna analiza obrazu</a> 
        <div class="sidebar-tools-main tools-wide">
    <a href="https://twitter.com" title="" class="quarto-navigation-tool px-1" aria-label=""><i class="bi bi-twitter"></i></a>
    <a href="https://github.com/dax44/ComputerVision/" title="Source Code" class="quarto-navigation-tool px-1" aria-label="Source Code"><i class="bi bi-github"></i></a>
    <a href="https://twitter.com/intent/tweet?url=|url|" title="Twitter" class="quarto-navigation-tool px-1" aria-label="Twitter"><i class="bi bi-twitter"></i></a>
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="PrzeÅ‚Ä…cz tryb ciemny"><i class="bi"></i></a>
  <a href="" class="quarto-reader-toggle quarto-navigation-tool px-1" onclick="window.quartoToggleReader(); return false;" title="PrzeÅ‚Ä…cz tryb czytnika">
  <div class="quarto-reader-toggle-btn">
  <i class="bi"></i>
  </div>
</a>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Szukaj"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">WstÄ™p</a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./intro.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Wprowadzenie</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./history.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Historia wizji komputerowej</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./digt_img.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Obrazy cyfrowe</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./transformations.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Transformacje geometryczne</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./point_trans.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Transformacje punktowe</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./filters.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Filtry</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./edge.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Wykrywanie krawÄ™dzi i konturÃ³w</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./morpho.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Filtry morfologiczne</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./fourier.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Transformata Fouriera</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./deeplearning.html" class="sidebar-item-text sidebar-link active"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Deep learning</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./fundamentals.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Fundamenty DNN</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./convolution.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Sieci splotowe</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./references.html" class="sidebar-item-text sidebar-link">Bibliografia</a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Spis treÅ›ci</h2>
   
  <ul>
  <li><a href="#uczenie-siÄ™-reprezentacji-na-podstawie-danych" id="toc-uczenie-siÄ™-reprezentacji-na-podstawie-danych" class="nav-link active" data-scroll-target="#uczenie-siÄ™-reprezentacji-na-podstawie-danych"><span class="header-section-number">10.1</span> Uczenie siÄ™ reprezentacji na podstawie danych</a></li>
  <li><a href="#jak-dziaÅ‚a-deep-learning" id="toc-jak-dziaÅ‚a-deep-learning" class="nav-link" data-scroll-target="#jak-dziaÅ‚a-deep-learning"><span class="header-section-number">10.2</span> Jak dziaÅ‚a deep learning?</a></li>
  <li><a href="#krÃ³tki-rys-historyczny-dl" id="toc-krÃ³tki-rys-historyczny-dl" class="nav-link" data-scroll-target="#krÃ³tki-rys-historyczny-dl"><span class="header-section-number">10.3</span> KrÃ³tki rys historyczny DL</a>
  <ul class="collapse">
  <li><a href="#hardware" id="toc-hardware" class="nav-link" data-scroll-target="#hardware"><span class="header-section-number">10.3.1</span> Hardware</a></li>
  <li><a href="#dane" id="toc-dane" class="nav-link" data-scroll-target="#dane"><span class="header-section-number">10.3.2</span> Dane</a></li>
  <li><a href="#algorytmy" id="toc-algorytmy" class="nav-link" data-scroll-target="#algorytmy"><span class="header-section-number">10.3.3</span> Algorytmy</a></li>
  </ul></li>
  <li><a href="#elementy-deep-learning" id="toc-elementy-deep-learning" class="nav-link" data-scroll-target="#elementy-deep-learning"><span class="header-section-number">10.4</span> Elementy Deep Learning</a>
  <ul class="collapse">
  <li><a href="#operacje-na-danych" id="toc-operacje-na-danych" class="nav-link" data-scroll-target="#operacje-na-danych"><span class="header-section-number">10.4.1</span> Operacje na danych</a></li>
  <li><a href="#optymalizacja-gradientowa" id="toc-optymalizacja-gradientowa" class="nav-link" data-scroll-target="#optymalizacja-gradientowa"><span class="header-section-number">10.4.2</span> Optymalizacja gradientowa</a></li>
  <li><a href="#wsteczna-propagacja-bÅ‚Ä™du" id="toc-wsteczna-propagacja-bÅ‚Ä™du" class="nav-link" data-scroll-target="#wsteczna-propagacja-bÅ‚Ä™du"><span class="header-section-number">10.4.3</span> Wsteczna propagacja bÅ‚Ä™du</a></li>
  <li><a href="#funkcje-straty" id="toc-funkcje-straty" class="nav-link" data-scroll-target="#funkcje-straty"><span class="header-section-number">10.4.4</span> Funkcje straty</a></li>
  </ul></li>
  </ul>
<div class="toc-actions"><div><i class="bi bi-github"></i></div><div class="action-links"><p><a href="https://github.com/dax44/ComputerVision/issues/new" class="toc-action">ZgÅ‚oÅ› problem</a></p></div></div></nav>
    </div>
<!-- main -->
<main class="content page-columns page-full" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Deep learning</span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  

</header>

<p>Jak to zostaÅ‚o wspomniane na poczÄ…tku tej ksiÄ…Å¼ki do automatycznej analizy obrazu wykorzystamy techniki z zakresu uczenia maszynowego, ktÃ³re mieszczÄ… siÄ™ pod pojÄ™ciem gÅ‚Ä™bokiego uczenia (ang. <em>deep learning</em>). Uczenie maszynowe wynika bezpoÅ›rednio z pytania: czy komputer mÃ³gÅ‚by wyjÅ›Ä‡ poza to, co wiemy i samodzielnie nauczyÄ‡ siÄ™, jak wykonaÄ‡ okreÅ›lone zadanie? Czy komputer mÃ³gÅ‚by nas zaskoczyÄ‡? Czy zamiast programistÃ³w rÄ™cznie tworzÄ…cych reguÅ‚y przetwarzania danych, komputer mÃ³gÅ‚by automatycznie nauczyÄ‡ siÄ™ tych reguÅ‚ patrzÄ…c na dane?</p>
<div id="fig-ml1" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="images/Zrzut ekranu 2023-02-23 o 19.01.53.png" class="img-fluid figure-img" width="400"></p>
<p></p><figcaption class="figure-caption">Rysunek&nbsp;10.1: Dwa schematy myÅ›lenia o programowaniu komputerÃ³w</figcaption><p></p>
</figure>
</div>
<p>To pytanie otwiera drzwi do nowego paradygmatu programowania. W klasycznym programowaniu, paradygmacie symbolicznej AI, ludzie wprowadzajÄ… reguÅ‚y (program) i dane, ktÃ³re majÄ… byÄ‡ przetwarzane zgodnie z tymi reguÅ‚ami, a nastÄ™pnie otrzymujÄ… odpowiedzi (patrz <a href="#fig-ml1">Rysunek&nbsp;<span>10.1</span></a>). W przypadku uczenia maszynowego, czÅ‚owiek wprowadza dane oraz odpowiedzi oczekiwane na podstawie tych danych, a nastÄ™pnie otrzymuje reguÅ‚y. ReguÅ‚y te mogÄ… byÄ‡ nastÄ™pnie zastosowane do nowych danych, aby uzyskaÄ‡ oryginalne odpowiedzi.</p>
<p>System uczenia maszynowego jest raczej uczony niÅ¼ programowany. Przedstawia siÄ™ mu wiele przykÅ‚adÃ³w zwiÄ…zanych z zadaniem, a on znajduje w nich strukturÄ™ statystycznÄ…, ktÃ³ra w koÅ„cu pozwala mu wymyÅ›liÄ‡ reguÅ‚y automatyzacji zadania. Na przykÅ‚ad, jeÅ›li chciaÅ‚byÅ› zautomatyzowaÄ‡ zadanie oznaczania zdjÄ™Ä‡ z wakacji, mÃ³gÅ‚byÅ› przedstawiÄ‡ systemowi uczenia maszynowego wiele przykÅ‚adÃ³w zdjÄ™Ä‡ juÅ¼ oznaczonych przez ludzi, a system nauczyÅ‚by siÄ™ statystycznych reguÅ‚ kojarzenia konkretnych zdjÄ™Ä‡ z konkretnymi tagami.</p>

<div class="no-row-height column-margin column-container"><div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/tw1.jpeg" class="img-fluid figure-img" width="400"></p>
</figure>
</div></div><p>ChociaÅ¼ uczenie maszynowe zaczÄ™Å‚o siÄ™ rozwijaÄ‡ dopiero w latach 90-tych, szybko staÅ‚o siÄ™ najpopularniejszÄ… i odnoszÄ…cÄ… najwiÄ™ksze sukcesy dziedzinÄ… AI, a trend ten jest napÄ™dzany przez dostÄ™pnoÅ›Ä‡ szybszego sprzÄ™tu i wiÄ™kszych zbiorÃ³w danych. Uczenie maszynowe jest Å›ciÅ›le zwiÄ…zane ze statystykÄ… matematycznÄ…, ale rÃ³Å¼ni siÄ™ od niej na kilka waÅ¼nych sposobÃ³w. W przeciwieÅ„stwie do statystyki, uczenie maszynowe ma tendencjÄ™ do zajmowania siÄ™ duÅ¼ymi, zÅ‚oÅ¼onymi zbiorami danych (takimi jak zbiÃ³r milionÃ³w obrazÃ³w, z ktÃ³rych kaÅ¼dy skÅ‚ada siÄ™ z dziesiÄ…tek tysiÄ™cy pikseli), dla ktÃ³rych klasyczna analiza statystyczna byÅ‚aby niepraktyczna. W rezultacie, uczenie maszynowe, a zwÅ‚aszcza gÅ‚Ä™bokie uczenie, wykazuje stosunkowo maÅ‚o teorii matematycznej - byÄ‡ moÅ¼e zbyt maÅ‚o - i jest zorientowane na inÅ¼ynieriÄ™. Jest to praktyczna dyscyplina, w ktÃ³rej pomysÅ‚y sÄ… sprawdzane empirycznie znacznie czÄ™Å›ciej niÅ¼ teoretycznie.</p>
<section id="uczenie-siÄ™-reprezentacji-na-podstawie-danych" class="level2" data-number="10.1">
<h2 data-number="10.1" class="anchored" data-anchor-id="uczenie-siÄ™-reprezentacji-na-podstawie-danych"><span class="header-section-number">10.1</span> Uczenie siÄ™ reprezentacji na podstawie danych</h2>
<p>Na to aby zdefiniowaÄ‡ gÅ‚Ä™bokie uczenie i zrozumieÄ‡ rÃ³Å¼nicÄ™ miÄ™dzy gÅ‚Ä™bokim uczeniem a innymi podejÅ›ciami do uczenia maszynowego, najpierw musimy mieÄ‡ pewne pojÄ™cie o tym, co robiÄ… algorytmy uczenia maszynowego. WÅ‚aÅ›nie stwierdziliÅ›my, Å¼e uczenie maszynowe odkrywa reguÅ‚y wykonywania zadania przetwarzania danych, biorÄ…c pod uwagÄ™ przykÅ‚ady tego, co jest oczekiwane na wyjÅ›ciu. Zatem, aby przeprowadziÄ‡ uczenie maszynowe, potrzebujemy trzech rzeczy:</p>
<ul>
<li>Punkty danych wejÅ›ciowych - na przykÅ‚ad, jeÅ›li zadaniem jest rozpoznawanie mowy, tymi punktami danych mogÄ… byÄ‡ pliki dÅºwiÄ™kowe osÃ³b mÃ³wiÄ…cych. JeÅ›li zadanie polega na oznaczaniu obrazÃ³w, mogÄ… to byÄ‡ pliki z obrazami.</li>
<li>PrzykÅ‚ady oczekiwanych wynikÃ³w - w zadaniu rozpoznawania mowy mogÄ… to byÄ‡ generowane przez czÅ‚owieka transkrypcje plikÃ³w dÅºwiÄ™kowych. W zadaniu dotyczÄ…cym obrazÃ³w, oczekiwanymi danymi wyjÅ›ciowymi mogÄ… byÄ‡ tagi takie jak â€œpiesâ€, â€œkotâ€ itd.</li>
<li>SposÃ³b pomiaru, czy algorytm dobrze wykonuje swojÄ… pracÄ™ - jest on niezbÄ™dny do okreÅ›lenia odlegÅ‚oÅ›ci miÄ™dzy aktualnym wyjÅ›ciem algorytmu a jego oczekiwanym wyjÅ›ciem. Pomiar jest uÅ¼ywany jako sygnaÅ‚ zwrotny do dostosowania sposobu dziaÅ‚ania algorytmu. Ten krok dostosowawczy nazywamy uczeniem siÄ™ modelu.</li>
</ul>
<p>Model uczenia maszynowego przeksztaÅ‚ca dane wejÅ›ciowe w sensowne dane wyjÅ›ciowe, a proces ten jest â€œuczonyâ€ przez ekspozycjÄ™ na znane przykÅ‚ady danych wejÅ›ciowych i wyjÅ›ciowych. Dlatego centralnym problemem w uczeniu maszynowym i gÅ‚Ä™bokim uczeniu jest sensowne przeksztaÅ‚canie danych: innymi sÅ‚owy, uczenie siÄ™ uÅ¼ytecznych reprezentacji danych wejÅ›ciowych - reprezentacji, ktÃ³re przybliÅ¼ajÄ… nas do oczekiwanych wynikÃ³w. Zanim przejdziemy dalej: co to jest reprezentacja? W gruncie rzeczy jest to inny sposÃ³b patrzenia na dane - reprezentacja lub kodowanie danych. Na przykÅ‚ad, kolorowy obraz moÅ¼e byÄ‡ zakodowany w formacie RGB lub w formacie HSV (barwa-nasycenie-wartoÅ›Ä‡): sÄ… to dwie rÃ³Å¼ne reprezentacje tych samych danych. NiektÃ³re zadania, ktÃ³re mogÄ… byÄ‡ trudne do rozwiÄ…zania przy jednej reprezentacji, mogÄ… staÄ‡ siÄ™ Å‚atwe przy drugiej. Na przykÅ‚ad zadanie â€œwybierz wszystkie czerwone piksele na obrazieâ€ jest prostsze w formacie RBG, natomiast â€œspraw, by obraz byÅ‚ mniej nasyconyâ€ jest prostsze w formacie HSV. Modele uczenia maszynowego polegajÄ… na znalezieniu odpowiednich reprezentacji dla danych wejÅ›ciowych - przeksztaÅ‚ceÅ„ danych, ktÃ³re czyniÄ… je bardziej przydatnymi do wykonania zadania, np.zadania klasyfikacji.</p>
<p>Wszystkie algorytmy uczenia maszynowego polegajÄ… na automatycznym znajdowaniu takich przeksztaÅ‚ceÅ„, ktÃ³re zmieniajÄ… dane w bardziej uÅ¼yteczne reprezentacje dla danego zadania. Operacje te mogÄ… byÄ‡ zmianami wspÃ³Å‚rzÄ™dnych lub rzutami liniowymi, tÅ‚umaczeniami, operacjami nieliniowymi (takimi jak wybierz wszystkie punkty takie, Å¼e <span class="math inline">\(x &gt;0\)</span>) i tak dalej. Algorytmy uczenia maszynowego zazwyczaj nie sÄ… kreatywne w znajdowaniu tych przeksztaÅ‚ceÅ„; po prostu przeszukujÄ… wczeÅ›niej zdefiniowany zestaw operacji, zwany przestrzeniÄ… hipotez.</p>
<p>Tak wiÄ™c, technicznie rzecz biorÄ…c, uczenie maszynowe polega na poszukiwaniu uÅ¼ytecznych reprezentacji pewnych danych wejÅ›ciowych, w ramach predefiniowanej przestrzeni moÅ¼liwoÅ›ci, przy uÅ¼yciu wskazÃ³wek pochodzÄ…cych z jakiegoÅ› sygnaÅ‚u zwrotnego. Ta prosta idea pozwala na rozwiÄ…zywanie niezwykle szerokiego zakresu zadaÅ„ naturalnych dla czÅ‚owieka, od rozpoznawania mowy po autonomiczne prowadzenie samochodu.</p>
<p>GÅ‚Ä™bokie uczenie jest specyficznÄ… dziedzinÄ… uczenia maszynowego: nowe podejÅ›cie do uczenia siÄ™ reprezentacji z danych, ktÃ³re kÅ‚adzie nacisk na uczenie siÄ™ kolejnych warstw coraz bardziej znaczÄ…cych reprezentacji. GÅ‚Ä™bokie uczenie nie jest odniesieniem do jakiegokolwiek gÅ‚Ä™bszego zrozumienia osiÄ…ganego przez to podejÅ›cie; raczej oznacza ideÄ™ kolejnych warstw reprezentacji. To, ile warstw skÅ‚ada siÄ™ na model danych, nazywane jest gÅ‚Ä™bokoÅ›ciÄ… modelu. Innymi wÅ‚aÅ›ciwymi nazwami dla tej dziedziny mogÅ‚yby byÄ‡ uczenie siÄ™ reprezentacji warstwowych i uczenie siÄ™ reprezentacji hierarchicznych. Nowoczesne uczenie gÅ‚Ä™bokie czÄ™sto obejmuje dziesiÄ…tki, a nawet setki kolejnych warstw - i wszystkie one sÄ… uczone automatycznie na podstawie danych treningowych. Tymczasem inne podejÅ›cia do uczenia maszynowego koncentrujÄ… siÄ™ na uczeniu siÄ™ tylko jednej lub dwÃ³ch warstw reprezentacji danych; stÄ…d czasem nazywa siÄ™ je uczeniem pÅ‚ytkim.</p>
<p>W gÅ‚Ä™bokim uczeniu, te warstwowe reprezentacje sÄ… (prawie zawsze) uczone za pomocÄ… modeli zwanych sieciami neuronowymi, zbudowanymi w dosÅ‚ownych warstwach uÅ‚oÅ¼onych jedna za drugÄ…. Termin sieÄ‡ neuronowa jest odniesieniem do neurobiologii, jednak mimo Å¼e niektÃ³re z gÅ‚Ã³wnych koncepcji gÅ‚Ä™bokiego uczenia zostaÅ‚y opracowane czÄ™Å›ciowo poprzez czerpanie inspiracji z naszego rozumienia mÃ³zgu, modele gÅ‚Ä™bokiego uczenia nie sÄ… modelami mÃ³zgu. Nie ma dowodÃ³w na to, Å¼e mÃ³zg implementuje cokolwiek w rodzaju mechanizmÃ³w uczenia siÄ™ wykorzystywanych w nowoczesnych modelach gÅ‚Ä™bokiego uczenia. MoÅ¼esz natknÄ…Ä‡ siÄ™ na artykuÅ‚y popularno-naukowe gÅ‚oszÄ…ce, Å¼e gÅ‚Ä™bokie uczenie dziaÅ‚a jak mÃ³zg lub byÅ‚o wzorowane na mÃ³zgu, ale to nie jest prawda. ByÅ‚oby to mylÄ…ce, aby myÅ›leÄ‡ o gÅ‚Ä™bokim uczeniu jako w jakikolwiek sposÃ³b zwiÄ…zanym z neurobiologiÄ…. Dla naszych celÃ³w, gÅ‚Ä™bokie uczenie jest matematycznÄ… strukturÄ… do uczenia siÄ™ reprezentacji danych.</p>
<p>Jak wyglÄ…dajÄ… reprezentacje wyuczone przez algorytm gÅ‚Ä™bokiego uczenia? Przyjrzyjmy siÄ™, jak sieÄ‡ o gÅ‚Ä™bokoÅ›ci kilku warstw (patrz <a href="#fig-dl1">Rysunek&nbsp;<span>10.2</span></a>) przeksztaÅ‚ca obraz cyfry w celu rozpoznania, jaka to cyfra.</p>
<div id="fig-dl1" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="images/Zrzut ekranu 2023-02-23 o 19.22.38.png" class="img-fluid figure-img" width="600"></p>
<p></p><figcaption class="figure-caption">Rysunek&nbsp;10.2: Schemat dziaÅ‚ania sieci rozpoznajÄ…cej cyfry</figcaption><p></p>
</figure>
</div>
<p>Jak widaÄ‡ na <a href="#fig-dl2">Rysunek&nbsp;<span>10.3</span></a>, sieÄ‡ przeksztaÅ‚ca obraz cyfry w reprezentacje coraz bardziej rÃ³Å¼niÄ…ce siÄ™ od obrazu oryginalnego i coraz bardziej informujÄ…ce o wyniku koÅ„cowym. MoÅ¼na myÅ›leÄ‡ o sieci gÅ‚Ä™bokiej jak o wielostopniowej operacji destylacji informacji, gdzie informacja przechodzi przez kolejne filtry i wychodzi coraz bardziej oczyszczona (czyli przydatna w odniesieniu do jakiegoÅ› zadania).</p>
<div id="fig-dl2" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="images/Zrzut ekranu 2023-02-23 o 19.24.25.png" class="img-fluid figure-img" width="600"></p>
<p></p><figcaption class="figure-caption">Rysunek&nbsp;10.3: Przedstawienie zasady dziaÅ‚ania poszczegÃ³lnych warstw sieci neuronowej w rozpoznawaniu cyfr</figcaption><p></p>
</figure>
</div>
<p>Tak wÅ‚aÅ›nie wyglÄ…da gÅ‚Ä™bokie uczenie, technicznie rzecz biorÄ…c: jest to wieloetapowy sposÃ³b uczenia siÄ™ reprezentacji danych. To prosty pomysÅ‚ - ale jak siÄ™ okazuje, bardzo proste mechanizmy, odpowiednio skalowane, mogÄ… w koÅ„cu wyglÄ…daÄ‡ jak magia.</p>
</section>
<section id="jak-dziaÅ‚a-deep-learning" class="level2" data-number="10.2">
<h2 data-number="10.2" class="anchored" data-anchor-id="jak-dziaÅ‚a-deep-learning"><span class="header-section-number">10.2</span> Jak dziaÅ‚a deep learning?</h2>
<p>W tym wiemy juÅ¼, Å¼e uczenie maszynowe polega na mapowaniu danych wejÅ›ciowych (takich jak obrazy) na dane docelowe (takie jak etykieta â€œkotâ€), co odbywa siÄ™ poprzez obserwacjÄ™ wielu przykÅ‚adÃ³w danych wejÅ›ciowych i danych docelowych. Wiemy teÅ¼, Å¼e gÅ‚Ä™bokie sieci neuronowe wykonujÄ… odwzorowanie danych wejÅ›ciowych na docelowe poprzez gÅ‚Ä™bokÄ… sekwencjÄ™ prostych transformacji danych (warstwy) i Å¼e te transformacje danych sÄ… uczone przez ekspozycjÄ™ na przykÅ‚ady. Przyjrzyjmy siÄ™ teraz, jak to uczenie przebiega, konkretnie.</p>
<p>Specyfikacja tego, co warstwa robi ze swoimi danymi wejÅ›ciowymi, jest przechowywana w wagach warstwy (zwanych wagami synaptycznymi), ktÃ³re w istocie sÄ… zbiorem liczb. W sensie technicznym moÅ¼na powiedzieÄ‡, Å¼e transformacja wykonywana przez warstwÄ™ jest sparametryzowana przez jej wagi (patrz <a href="#fig-dl3">Rysunek&nbsp;<span>10.4</span></a>). W tym kontekÅ›cie uczenie oznacza znalezienie zestawu wartoÅ›ci dla wag wszystkich warstw w sieci, tak aby sieÄ‡ poprawnie odwzorowywaÅ‚a przykÅ‚adowe wejÅ›cia na przypisane im cele. Rzecz w tym, Å¼e gÅ‚Ä™boka sieÄ‡ neuronowa moÅ¼e zawieraÄ‡ dziesiÄ…tki milionÃ³w parametrÃ³w. Znalezienie poprawnej wartoÅ›ci dla wszystkich z nich moÅ¼e wydawaÄ‡ siÄ™ trudnym zadaniem, szczegÃ³lnie biorÄ…c pod uwagÄ™ fakt, Å¼e zmiana wartoÅ›ci jednego parametru wpÅ‚ynie na zachowanie wszystkich pozostaÅ‚ych!</p>
<div id="fig-dl3" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="images/Zrzut ekranu 2023-02-23 o 19.37.23.png" class="img-fluid figure-img" width="400"></p>
<p></p><figcaption class="figure-caption">Rysunek&nbsp;10.4: SieÄ‡ neuronowa parametryzowana przez wagi</figcaption><p></p>
</figure>
</div>
<p>Aby coÅ› kontrolowaÄ‡, trzeba najpierw mÃ³c to obserwowaÄ‡. Aby kontrolowaÄ‡ wyjÅ›cie sieci neuronowej, musisz byÄ‡ w stanie zmierzyÄ‡, jak daleko to wyjÅ›cie jest od tego, czego siÄ™ spodziewaÅ‚eÅ›. Jest to zadanie funkcji straty sieci, zwanej rÃ³wnieÅ¼ funkcjÄ… celu. Funkcja straty bierze predykcje sieci oraz prawdziwy wynik (to, co chciaÅ‚eÅ›, aby sieÄ‡ â€œwypluÅ‚aâ€) i oblicza wynik odlegÅ‚oÅ›ci, ujmujÄ…c, jak dobrze sieÄ‡ poradziÅ‚a sobie z tym konkretnym przykÅ‚adem (patrz <a href="#fig-dl4">Rysunek&nbsp;<span>10.5</span></a>).</p>
<div id="fig-dl4" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="images/Zrzut ekranu 2023-02-23 o 19.37.35.png" class="img-fluid figure-img" width="400"></p>
<p></p><figcaption class="figure-caption">Rysunek&nbsp;10.5: Funkcja straty mierzÄ…ca jakoÅ›Ä‡ predykcji</figcaption><p></p>
</figure>
</div>
<p>PodstawowÄ… sztuczkÄ… w uczeniu gÅ‚Ä™bokim jest wykorzystanie wyniku jako sygnaÅ‚u zwrotnego do skorygowania wartoÅ›ci wag w kierunku, ktÃ³ry obniÅ¼y wynik straty dla bieÅ¼Ä…cego przykÅ‚adu (patrz <a href="#fig-dl5">Rysunek&nbsp;<span>10.6</span></a>). Ta korekta jest zadaniem optymalizatora, ktÃ³ry implementuje coÅ›, co nazywa siÄ™ algorytmem wstecznej propagacji (ang. <em>backpropagation</em>): gÅ‚Ã³wny algorytm w uczeniu gÅ‚Ä™bokim. W dalszej czÄ™Å›ci wyjaÅ›nimy bardziej szczegÃ³Å‚owo, jak dziaÅ‚a wsteczna propagacja.</p>
<div id="fig-dl5" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="images/Zrzut ekranu 2023-02-23 o 19.37.48.png" class="img-fluid figure-img" width="400"></p>
<p></p><figcaption class="figure-caption">Rysunek&nbsp;10.6: Korekta wag wykorzystujÄ…ca wartoÅ›Ä‡ funkcji straty</figcaption><p></p>
</figure>
</div>
<p>PoczÄ…tkowo wagom sieci przypisane sÄ… losowe wartoÅ›ci, wiÄ™c sieÄ‡ wykonuje jedynie seriÄ™ losowych przeksztaÅ‚ceÅ„. OczywiÅ›cie jej wynik jest daleki od tego, jaki powinien byÄ‡ w idealnej sytuacji, a wynik funkcji straty jest bardzo wysoki. Ale z kaÅ¼dym przykÅ‚adem, ktÃ³ry sieÄ‡ przetwarza, wagi sÄ… dostosowywane w prawidÅ‚owym kierunku, a wynik strat maleje. Jest to pÄ™tla treningowa, ktÃ³ra powtarzana odpowiedniÄ… iloÅ›Ä‡ razy (zwykle dziesiÄ…tki iteracji na tysiÄ…cach przykÅ‚adÃ³w) daje wartoÅ›ci wag, ktÃ³re minimalizujÄ… funkcjÄ™ straty. SieÄ‡ z minimalnÄ… stratÄ… to taka, dla ktÃ³rej wyjÅ›cia sÄ… tak bliskie celom, jak to tylko moÅ¼liwe - sieÄ‡ wytrenowana.</p>
</section>
<section id="krÃ³tki-rys-historyczny-dl" class="level2 page-columns page-full" data-number="10.3">
<h2 data-number="10.3" class="anchored" data-anchor-id="krÃ³tki-rys-historyczny-dl"><span class="header-section-number">10.3</span> KrÃ³tki rys historyczny DL</h2>
<p>OkoÅ‚o 2010 roku, mimo Å¼e sieci neuronowe byÅ‚y niemal caÅ‚kowicie odrzucane przez ogÃ³Å‚ spoÅ‚ecznoÅ›ci naukowej, kilka osÃ³b wciÄ…Å¼ pracujÄ…cych nad sieciami neuronowymi zaczÄ™Å‚o dokonywaÄ‡ waÅ¼nych przeÅ‚omÃ³w: grupy Geoffreya Hintona z Uniwersytetu w Toronto, Yoshua Bengio z Uniwersytetu w Montrealu, Yann LeCun z Uniwersytetu Nowojorskiego oraz IDSIA w Szwajcarii.</p>
<div class="page-columns page-full"><p>W 2011 roku Dan Ciresan z IDSIA zaczÄ…Å‚ wygrywaÄ‡ akademickie konkursy klasyfikacji obrazÃ³w za pomocÄ… trenowanych na GPU gÅ‚Ä™bokich sieci neuronowych - byÅ‚ to pierwszy praktyczny sukces nowoczesnego uczenia gÅ‚Ä™bokiego. Jednak przeÅ‚omowy moment nastÄ…piÅ‚ w 2012 roku, gdy grupa Hintona wziÄ™Å‚a udziaÅ‚ w corocznym wyzwaniu ImageNet dotyczÄ…cym klasyfikacji obrazÃ³w na duÅ¼Ä… skalÄ™. Wyzwanie ImageNet byÅ‚o w tamtym czasie wyjÄ…tkowo trudne, polegaÅ‚o na klasyfikacji kolorowych obrazÃ³w o wysokiej rozdzielczoÅ›ci do 1000 rÃ³Å¼nych kategorii po przeszkoleniu na 1,4 mln obrazÃ³w. W 2011 roku dokÅ‚adnoÅ›Ä‡ zwyciÄ™skiego modelu, opartego na klasycznym podejÅ›ciu do widzenia komputerowego, wyniosÅ‚a zaledwie 74,3%. NastÄ™pnie, w 2012 roku, zespÃ³Å‚ kierowany przez Alexa Krizhevskyâ€™ego i wspierany przez Geoffreya Hintona byÅ‚ w stanie osiÄ…gnÄ…Ä‡ dokÅ‚adnoÅ›Ä‡ w pierwszej piÄ…tce<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a> na poziomie 83,6% - byÅ‚ to znaczÄ…cy przeÅ‚om. Od tego czasu co roku konkurs byÅ‚ zdominowany przez gÅ‚Ä™bokie konwencjonalne sieci neuronowe. W 2015 roku zwyciÄ™zca osiÄ…gnÄ…Å‚ dokÅ‚adnoÅ›Ä‡ 96,4%, a zadanie klasyfikacji na ImageNet uznano za caÅ‚kowicie rozwiÄ…zany problem.</p><div class="no-row-height column-margin column-container"><li id="fn1"><p><sup>1</sup>&nbsp;(ang. <em>top 5 accuracy</em>) <em>-</em> oznacza, Å¼e wÅ›rÃ³d 5 kategorii z najwyÅ¼szym prawdopodobieÅ„stwem jest prawdziwa klasa</p></li></div></div>

<div class="no-row-height column-margin column-container"><div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/tw2.jpeg" class="img-fluid figure-img" width="400"></p>
</figure>
</div></div><p>Od 2012 r. gÅ‚Ä™bokie konwolucyjne sieci neuronowe (CovNets - <em>Convolutional Networks</em>) staÅ‚y siÄ™ algorytmem pierwszego wyboru dla wszystkich zadaÅ„ widzenia komputerowego. Na najwaÅ¼niejszych konferencjach poÅ›wiÄ™conych widzeniu komputerowemu w 2015 i 2016 r. niemal niemoÅ¼liwe byÅ‚o znalezienie prezentacji, ktÃ³re w jakiejÅ› formie nie wiÄ…zaÅ‚yby siÄ™ z CovNets. JednoczeÅ›nie gÅ‚Ä™bokie uczenie znalazÅ‚o zastosowanie w wielu innych typach problemÃ³w, takich jak np. przetwarzanie jÄ™zyka naturalnego. W szerokim zakresie zastosowaÅ„ caÅ‚kowicie zastÄ…piÅ‚o klasyczne modele SVM i drzewa decyzyjne. Na przykÅ‚ad przez kilka lat Europejska Organizacja BadaÅ„ JÄ…drowych (CERN), uÅ¼ywaÅ‚a metod opartych na drzewach decyzyjnych do analizy danych czÄ…stek z detektora ATLAS w Wielkim Zderzaczu HadronÃ³w (LHC); ale CERN ostatecznie przeszedÅ‚ na gÅ‚Ä™bokie sieci neuronowe oparte na Keras ze wzglÄ™du na ich wyÅ¼szÄ… wydajnoÅ›Ä‡ i Å‚atwoÅ›Ä‡ szkolenia na duÅ¼ych zbiorach danych.</p>
<p>Podstawowym powodem, dla ktÃ³rego uczenie gÅ‚Ä™bokie odniosÅ‚o sukces tak szybko, jest to, Å¼e oferowaÅ‚o lepszÄ… wydajnoÅ›Ä‡ w wielu problemach. Ale to nie jest jedyny powÃ³d. GÅ‚Ä™bokie uczenie uÅ‚atwia rÃ³wnieÅ¼ rozwiÄ…zywanie problemÃ³w, poniewaÅ¼ caÅ‚kowicie automatyzuje to, co kiedyÅ› byÅ‚o najbardziej kluczowym krokiem w procesie uczenia maszynowego: inÅ¼ynieriÄ™ cech.</p>
<p>Poprzednie techniki uczenia maszynowego - uczenie gÅ‚Ä™bokie - polegaÅ‚y jedynie na przeksztaÅ‚ceniu danych wejÅ›ciowych w jednÄ… lub dwie kolejne przestrzenie reprezentacji, zwykle poprzez proste przeksztaÅ‚cenia, takie jak wielowymiarowe projekcje nieliniowe (SVM) lub drzewa decyzyjne. Jednak wyrafinowane reprezentacje wymagane przez zÅ‚oÅ¼one problemy zazwyczaj nie mogÄ… byÄ‡ realizowane przez wspomniane techniki. W zwiÄ…zku z tym, ludzie musieli zadaÄ‡ sobie wiele trudu, aby uczyniÄ‡ poczÄ…tkowe dane wejÅ›ciowe bardziej podatnymi na przetwarzanie przez te metody: to znaczy, musieli rÄ™cznie oparcowaÄ‡ dobre warstwy reprezentacji dla swoich danych. Nazywa siÄ™ to inÅ¼ynieriÄ… cech. Uczenie gÅ‚Ä™bokie caÅ‚kowicie automatyzuje ten krok: w przypadku uczenia gÅ‚Ä™bokiego, uczysz siÄ™ wszystkich cech w jednym przejÅ›ciu i nie musisz ich samodzielnie opracowywaÄ‡. To znacznie uproÅ›ciÅ‚o przepÅ‚ywy pracy zwiÄ…zane z uczeniem maszynowym, czÄ™sto zastÄ™pujÄ…c skomplikowane, wieloetapowe potoki jednym, prostym, kompleksowym modelem uczenia gÅ‚Ä™bokiego.</p>
<p>MoÅ¼na zapytaÄ‡, skoro sednem sprawy jest posiadanie wielu kolejnych warstw reprezentacji, to czy pÅ‚ytkie metody mogÄ… byÄ‡ stosowane wielokrotnie, aby emulowaÄ‡ efekty gÅ‚Ä™bokiego uczenia? W praktyce, korzyÅ›Ä‡ z zastosowania kilku metod pÅ‚ytkiego uczenia szybko maleje, poniewaÅ¼ optymalna pierwsza warstwa reprezentacji w modelu trÃ³jwarstwowym nie jest optymalnÄ… pierwszÄ… warstwÄ… w modelu jedno- lub dwuwarstwowym. To, co jest przeÅ‚omowe w uczeniu gÅ‚Ä™bokim, to fakt, Å¼e pozwala ono modelowi uczyÄ‡ siÄ™ wszystkich warstw reprezentacji wspÃ³lnie, w tym samym czasie, a nie po kolei (zachÅ‚annie). DziÄ™ki wspÃ³lnemu uczeniu cech, gdy model dostosowuje jednÄ… ze swoich wewnÄ™trznych cech, wszystkie inne cechy, ktÃ³re od niej zaleÅ¼Ä…, automatycznie dostosowujÄ… siÄ™ do tej zmiany, bez koniecznoÅ›ci interwencji czÅ‚owieka. Wszystko jest nadzorowane przez pojedynczy sygnaÅ‚ zwrotny: kaÅ¼da zmiana w modelu sÅ‚uÅ¼y celowi koÅ„cowemu. Jest to znacznie potÄ™Å¼niejsze niÅ¼ skÅ‚adanie pÅ‚ytkich modeli, poniewaÅ¼ pozwala na uczenie siÄ™ zÅ‚oÅ¼onych, abstrakcyjnych reprezentacji poprzez rozbicie ich na dÅ‚ugie serie poÅ›rednich warstw; kaÅ¼da warstwa jest tylko prostym przeksztaÅ‚ceniem w stosunku do poprzedniej.</p>
<p>SÄ… to dwie zasadnicze cechy tego, jak gÅ‚Ä™bokie uczenie uczy siÄ™ z danych: przyrostowy, warstwa po warstwie sposÃ³b, w jaki korygowane sÄ… coraz bardziej zÅ‚oÅ¼one reprezentacje, oraz fakt, Å¼e te poÅ›rednie, przyrostowe reprezentacje sÄ… uczone wspÃ³lnie, a kaÅ¼da warstwa jest aktualizowana, aby podÄ…Å¼aÄ‡ zarÃ³wno za potrzebami reprezentacyjnymi warstwy powyÅ¼ej, jak i potrzebami warstwy poniÅ¼ej. Razem, te dwie wÅ‚aÅ›ciwoÅ›ci sprawiÅ‚y, Å¼e gÅ‚Ä™bokie uczenie jest znacznie bardziej skuteczne niÅ¼ poprzednie podejÅ›cia do uczenia maszynowego.</p>
<p>Åšwietnym sposobem na poznanie aktualnego krajobrazu algorytmÃ³w i narzÄ™dzi uczenia maszynowego jest przyjrzenie siÄ™ konkursom uczenia maszynowego na Kaggle. DziÄ™ki wysoce konkurencyjnemu Å›rodowisku (niektÃ³re konkursy majÄ… tysiÄ…ce uczestnikÃ³w i milionowe nagrody) i szerokiej gamie problemÃ³w uczenia maszynowego, Kaggle oferuje realistyczny sposÃ³b oceny tego, co dziaÅ‚a, a co nie. Jaki wiÄ™c rodzaj algorytmu niezawodnie wygrywa konkursy? Z jakich narzÄ™dzi korzystajÄ… najlepsi uczestnicy?<br>
</p>
<p>W 2016 roku Kaggle zostaÅ‚ zdominowany przez dwa podejÅ›cia: gradient boosting machines i deep learning. Konkretnie, gradient boosting jest uÅ¼ywany do problemÃ³w, w ktÃ³rych dostÄ™pne sÄ… ustrukturyzowane dane, podczas gdy gÅ‚Ä™bokie uczenie jest uÅ¼ywane do problemÃ³w percepcyjnych, takich jak klasyfikacja obrazÃ³w. Zwolennicy tego pierwszego rozwiÄ…zania prawie zawsze korzystajÄ… ze znakomitej biblioteki <code>XGBoost</code>. Tymczasem wiÄ™kszoÅ›Ä‡ uczestnikÃ³w Kaggle wykorzystujÄ…cych uczenie gÅ‚Ä™bokie uÅ¼ywa biblioteki <code>Keras</code>, ze wzglÄ™du na jej Å‚atwoÅ›Ä‡ uÅ¼ycia i elastycznoÅ›Ä‡. ZarÃ³wno <code>XGBoost</code>, jak i <code>Keras</code> wspierajÄ… dwa najpopularniejsze jÄ™zyki data science: R i Python.</p>
<section id="hardware" class="level3" data-number="10.3.1">
<h3 data-number="10.3.1" class="anchored" data-anchor-id="hardware"><span class="header-section-number">10.3.1</span> Hardware</h3>
<p>W latach 1990-2010 procesory dostÄ™pne na rynku staÅ‚y siÄ™ szybsze o okoÅ‚o 5000 razy. W rezultacie, obecnie moÅ¼liwe jest uruchomienie maÅ‚ych modeli gÅ‚Ä™bokiego uczenia na laptopie, podczas gdy 25 lat temu byÅ‚oby to niewykonalne.</p>
<p>Jednak typowe modele gÅ‚Ä™bokiego uczenia wykorzystywane w wizji komputerowej lub rozpoznawaniu mowy wymagajÄ… mocy obliczeniowej o kilka rzÄ™dÃ³w wielkoÅ›ci wiÄ™kszej niÅ¼ ta, ktÃ³rÄ… moÅ¼e zapewniÄ‡ laptop. Przez caÅ‚Ä… dekadÄ™ XXI wieku firmy takie jak NVIDIA i AMD inwestowaÅ‚y miliardy dolarÃ³w w rozwÃ³j szybkich, rÃ³wnolegÅ‚ych ukÅ‚adÃ³w (procesorÃ³w graficznych [GPU]), ktÃ³re napÄ™dzaÅ‚y grafikÄ™ w coraz bardziej fotorealistycznych grach wideo - tanich, osobistych komputerÃ³w zaprojektowanych do renderowania zÅ‚oÅ¼onych scen 3D na ekranie w czasie rzeczywistym. Inwestycja ta przyniosÅ‚a korzyÅ›ci spoÅ‚ecznoÅ›ci naukowej, gdy w 2007 roku NVIDIA wprowadziÅ‚a CUDA (<a href="https://developer.nvidia.com/about-cuda" class="uri">https://developer.nvidia.com/about-cuda</a>), interfejs programistyczny dla swojej linii ukÅ‚adÃ³w GPU. Niewielka liczba procesorÃ³w graficznych zaczÄ™Å‚a zastÄ™powaÄ‡ klastry CPU w rÃ³Å¼nych zÅ‚oÅ¼onych zadaniach, poczÄ…wszy od modelowania w fizyce. GÅ‚Ä™bokie sieci neuronowe, skÅ‚adajÄ…ce siÄ™ gÅ‚Ã³wnie z wielu mnoÅ¼eÅ„ macierzy, sÄ… rÃ³wnieÅ¼ wysoce paralelizowalne i okoÅ‚o 2011 roku niektÃ³rzy badacze zaczÄ™li pisaÄ‡ implementacje CUDA sieci neuronowych - jednymi z pierwszych byli Dan Ciresan<span class="citation" data-cites="ciresanFlexibleHighPerformance">(<a href="references.html#ref-ciresanFlexibleHighPerformance" role="doc-biblioref">Ciresan i in., b.d.</a>)</span> i Alex Krizhevsky<span class="citation" data-cites="krizhevsky2017">(<a href="references.html#ref-krizhevsky2017" role="doc-biblioref">Krizhevsky, Sutskever, i Hinton 2017</a>)</span>.</p>
<p><br>
StaÅ‚o siÄ™ tak, Å¼e rynek gier dofinansowaÅ‚ superkomputery dla nastÄ™pnej generacji aplikacji sztucznej inteligencji. Czasami wielkie rzeczy zaczynajÄ… siÄ™ do zabawy ğŸ™ˆ. DziÅ› NVIDIA Titan X, procesor graficzny dla graczy, ktÃ³ry kosztowaÅ‚ 1000 dolarÃ³w pod koniec 2015 roku, moÅ¼e zapewniÄ‡ szczytowÄ… wydajnoÅ›Ä‡ 6,6 TLOPS w pojedynczej precyzji: to znaczy 6,6 biliona operacji float32 na sekundÄ™. To okoÅ‚o 350 razy wiÄ™cej niÅ¼ to, co moÅ¼na wyciÄ…gnÄ…Ä‡ z nowoczesnego laptopa. Na Tytanie X trenowanie modelu ImageNet, ktÃ³ry kilka lat temu wygraÅ‚by konkurs ILSVRC, zajmuje zaledwie kilka dni. Tymczasem duÅ¼e firmy trenujÄ… modele gÅ‚Ä™bokiego uczenia na klastrach skÅ‚adajÄ…cych siÄ™ z setek jednostek GPU, takich jak NVIDIA K80, opracowanych specjalnie na potrzeby gÅ‚Ä™bokiego uczenia. Sama moc obliczeniowa takich klastrÃ³w jest czymÅ›, co nigdy nie byÅ‚oby moÅ¼liwe bez nowoczesnych procesorÃ³w graficznych.</p>
<p>Co wiÄ™cej, branÅ¼a gÅ‚Ä™bokiego uczenia zaczyna wychodziÄ‡ poza procesory graficzne i inwestuje w coraz bardziej wyspecjalizowane, wydajne ukÅ‚ady do gÅ‚Ä™bokiego uczenia. W 2016 roku, na corocznej konwencji I/O, Google ujawniÅ‚o swÃ³j projekt procesora tensorowego (TPU): nowy ukÅ‚ad scalony opracowany od podstaw w celu uruchamiania gÅ‚Ä™bokich sieci neuronowych, ktÃ³ry jest podobno 10 razy szybszy i znacznie bardziej energooszczÄ™dny niÅ¼ topowe ukÅ‚ady GPU.</p>
</section>
<section id="dane" class="level3 page-columns page-full" data-number="10.3.2">
<h3 data-number="10.3.2" class="anchored" data-anchor-id="dane"><span class="header-section-number">10.3.2</span> Dane</h3>
<div class="page-columns page-full"><p>AI jest czasem zapowiadana jako nowa rewolucja przemysÅ‚owa. JeÅ›li gÅ‚Ä™bokie uczenie jest maszynÄ… parowÄ… tej rewolucji, to dane sÄ… jej wÄ™glem: surowcem, ktÃ³ry zasila nasze inteligentne maszyny, bez ktÃ³rego nic nie byÅ‚oby moÅ¼liwe. JeÅ›li chodzi o dane, to oprÃ³cz wykÅ‚adniczego postÄ™pu w dziedzinie sprzÄ™tu do przechowywania danych w ciÄ…gu ostatnich 20 lat (zgodnie z prawem Mooreâ€™a<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a>), kluczowym czynnikiem byÅ‚ rozwÃ³j Internetu, dziÄ™ki ktÃ³remu moÅ¼liwe staÅ‚o siÄ™ gromadzenie i rozpowszechnianie bardzo duÅ¼ych zbiorÃ³w danych na potrzeby uczenia maszynowego. Obecnie duÅ¼e firmy pracujÄ… z zestawami danych obrazowych, zestawami danych wideo i zestawami danych w jÄ™zyku naturalnym, ktÃ³re nie mogÅ‚yby zostaÄ‡ zebrane bez Internetu. PrzykÅ‚adowo, generowane przez uÅ¼ytkownikÃ³w tagi do obrazÃ³w w serwisie Flickr sÄ… skarbnicÄ… danych dla wizji komputerowej. Podobnie jest z filmami z YouTube. A Wikipedia jest kluczowym zbiorem danych dla przetwarzania jÄ™zyka naturalnego.</p><div class="no-row-height column-margin column-container"><li id="fn2"><p><sup>2</sup>&nbsp;mÃ³wi o tym, Å¼e liczba tranzystorÃ³w w procesorach roÅ›nie wykÅ‚adniczo</p></li></div></div>
<p>JeÅ›li jest jakiÅ› zbiÃ³r danych, ktÃ³ry staÅ‚ siÄ™ katalizatorem rozwoju gÅ‚Ä™bokiego uczenia, to jest to zbiÃ³r danych ImageNet, skÅ‚adajÄ…cy siÄ™ z 1,4 miliona obrazÃ³w, ktÃ³re zostaÅ‚y rÄ™cznie przypisane do 1000 kategorii obrazÃ³w (1 kategoria na obraz). Jednak to, co czyni ImageNet wyjÄ…tkowym, to nie tylko jego duÅ¼y rozmiar, ale takÅ¼e coroczny konkurs z nim zwiÄ…zany. Jak pokazuje Kaggle od 2010 roku, publiczne konkursy sÄ… doskonaÅ‚ym sposobem motywowania naukowcÃ³w i inÅ¼ynierÃ³w do przekraczania granic. Posiadanie wspÃ³lnych benchmarkÃ³w, ktÃ³re badacze starajÄ… siÄ™ pokonaÄ‡, bardzo pomogÅ‚o w niedawnym rozwoju uczenia gÅ‚Ä™bokiego.</p>
</section>
<section id="algorytmy" class="level3" data-number="10.3.3">
<h3 data-number="10.3.3" class="anchored" data-anchor-id="algorytmy"><span class="header-section-number">10.3.3</span> Algorytmy</h3>
<p>OprÃ³cz sprzÄ™tu i danych, aÅ¼ do pÃ³Åºnych lat 2000 brakowaÅ‚o nam niezawodnego sposobu trenowania bardzo gÅ‚Ä™bokich sieci neuronowych. W rezultacie sieci neuronowe byÅ‚y wciÄ…Å¼ doÅ›Ä‡ pÅ‚ytkie, wykorzystujÄ…c tylko jednÄ… lub dwie warstwy reprezentacji; nie byÅ‚y wiÄ™c w stanie zabÅ‚ysnÄ…Ä‡ w porÃ³wnaniu z bardziej wyrafinowanymi pÅ‚ytkimi metodami, takimi jak SVM czy lasy losowe. Kluczowym problemem byÅ‚a propagacja gradientu przez gÅ‚Ä™bokie stosy warstw. SygnaÅ‚ zwrotny uÅ¼ywany do trenowania sieci neuronowych zanikaÅ‚ wraz ze wzrostem liczby warstw.</p>
<p>ZmieniÅ‚o siÄ™ to okoÅ‚o 2009-2010 roku wraz z pojawieniem siÄ™ kilku prostych, ale waÅ¼nych ulepszeÅ„ algorytmicznych, ktÃ³re pozwoliÅ‚y na lepszÄ… propagacjÄ™ gradientu:</p>
<ul>
<li>lepsze funkcje aktywacji dla warstw neuronowych;</li>
<li>lepsze schematy inicjalizacji wag, poczÄ…wszy od wstÄ™pnego szkolenia z podziaÅ‚em na warstwy, ktÃ³re zostaÅ‚o szybko porzucone;</li>
<li>lepsze schematy optymalizacji, takie jak RMSProp i Adam.</li>
</ul>
<p>Dopiero gdy te ulepszenia zaczÄ™Å‚y umoÅ¼liwiaÄ‡ trenowanie modeli z 10 lub wiÄ™cej warstwami, uczenie gÅ‚Ä™bokie zaczÄ™Å‚o bÅ‚yszczeÄ‡. Wreszcie w latach 2014, 2015 i 2016 odkryto jeszcze bardziej zaawansowane sposoby wspomagania propagacji gradientu, takie jak normalizacja partii (ang. <em>batch normalization</em>), poÅ‚Ä…czenia resztkowe (ang. <em>residual connections</em>) czy konwolucje separowalne w gÅ‚Ä…b (ang. <em>depthwise separable convolutions</em>). DziÅ› moÅ¼emy trenowaÄ‡ od podstaw modele, ktÃ³re majÄ… tysiÄ…ce warstw gÅ‚Ä™bokoÅ›ci.</p>
<p>Czy jest coÅ› szczegÃ³lnego w gÅ‚Ä™bokich sieciach neuronowych, co sprawia, Å¼e sÄ… one â€œwÅ‚aÅ›ciwymâ€ podejÅ›ciem dla firm, w ktÃ³re naleÅ¼y inwestowaÄ‡ i dla naukowcÃ³w, ktÃ³rzy chcÄ… siÄ™ nimi zainteresowaÄ‡? Czy moÅ¼e gÅ‚Ä™bokie uczenie siÄ™ jest tylko modÄ…, ktÃ³ra moÅ¼e nie przetrwaÄ‡? Czy za 20 lat nadal bÄ™dziemy uÅ¼ywaÄ‡ gÅ‚Ä™bokich sieci neuronowych?</p>
<p>KrÃ³tka odpowiedÅº brzmi: tak ğŸ™ - gÅ‚Ä™bokie uczenie ma kilka wÅ‚aÅ›ciwoÅ›ci, ktÃ³re uzasadniajÄ… jego status jako rewolucji AI. ByÄ‡ moÅ¼e za dwie dekady nie bÄ™dziemy uÅ¼ywaÄ‡ sieci neuronowych, ale cokolwiek bÄ™dziemy uÅ¼ywaÄ‡, bÄ™dzie bezpoÅ›rednio dziedziczyÄ‡ po nowoczesnym gÅ‚Ä™bokim uczeniu i jego podstawowych koncepcjach. NajwaÅ¼niejsze wÅ‚aÅ›ciwoÅ›ci moÅ¼na ogÃ³lnie podzieliÄ‡ na trzy kategorie:</p>
<ul>
<li>Prostota - gÅ‚Ä™bokie uczenie eliminuje potrzebÄ™ inÅ¼ynierii cech, zastÄ™pujÄ…c zÅ‚oÅ¼one, wraÅ¼liwe i wymagajÄ…ce inÅ¼ynierii potoki prostymi, kompleksowo wytrenowanymi modelami, ktÃ³re sÄ… zazwyczaj budowane przy uÅ¼yciu tylko piÄ™ciu lub szeÅ›ciu rÃ³Å¼nych operacji na tensorach.</li>
<li>SkalowalnoÅ›Ä‡ - gÅ‚Ä™bokie uczenie jest bardzo podatne na rÃ³wnolegÅ‚e przetwarzanie na ukÅ‚adach GPU lub TPU. Dodatkowo, modele gÅ‚Ä™bokiego uczenia sÄ… trenowane poprzez iteracjÄ™ na maÅ‚ych partiach danych, co pozwala na ich trenowanie na zbiorach danych o dowolnym rozmiarze. (Jedynym wÄ…skim gardÅ‚em jest iloÅ›Ä‡ dostÄ™pnej mocy obliczeniowej).</li>
<li>WszechstronnoÅ›Ä‡ i moÅ¼liwoÅ›Ä‡ ponownego wykorzystania - w przeciwieÅ„stwie do wielu wczeÅ›niejszych podejÅ›Ä‡ do uczenia maszynowego, modele gÅ‚Ä™bokiego uczenia mogÄ… byÄ‡ trenowane na dodatkowych danych bez koniecznoÅ›ci ponownego rozpoczynania od zera, co czyni je realnymi dla ciÄ…gÅ‚ego uczenia siÄ™ na bierzÄ…co - waÅ¼na wÅ‚aÅ›ciwoÅ›Ä‡ dla bardzo duÅ¼ych modeli produkcyjnych. Co wiÄ™cej, wytrenowane modele gÅ‚Ä™bokiego uczenia mogÄ… byÄ‡ ponownie wykorzystane, na przykÅ‚ad, moÅ¼liwe jest wziÄ™cie modelu gÅ‚Ä™bokiego uczenia wytrenowanego do klasyfikacji obrazÃ³w i wrzucenie go do potoku przetwarzania wideo.</li>
</ul>
</section>
</section>
<section id="elementy-deep-learning" class="level2 page-columns page-full" data-number="10.4">
<h2 data-number="10.4" class="anchored" data-anchor-id="elementy-deep-learning"><span class="header-section-number">10.4</span> Elementy Deep Learning</h2>
<p>Zrozumienie gÅ‚Ä™bokiego uczenia wymaga znajomoÅ›ci wielu prostych pojÄ™Ä‡ matematycznych: tensorÃ³w, operacji na tensorach, rÃ³Å¼niczkowania, spadku gradientu itp. Naszym celem w tym rozdziale bÄ™dzie zbudowanie intuicji na temat tych pojÄ™Ä‡ bez nadmiernego zagÅ‚Ä™biania siÄ™ w technikÄ™. W szczegÃ³lnoÅ›ci, bÄ™dziemy unikaÄ‡ notacji matematycznej, ktÃ³ra moÅ¼e byÄ‡ draÅ¼niÄ…ca dla osÃ³b nieposiadajÄ…cych Å¼adnego wyksztaÅ‚cenia matematycznego, a nie jest niezbÄ™dna do dobrego wytÅ‚umaczenia.</p>
<p>Aby dodaÄ‡ trochÄ™ kontekstu dla tensorÃ³w i spadku gradientu, rozpoczniemy podrozdziaÅ‚ od praktycznego przykÅ‚adu sieci neuronowej. NastÄ™pnie przejdziemy przez kaÅ¼de nowe pojÄ™cie, ktÃ³re zostaÅ‚o wprowadzone, punkt po punkcie. PamiÄ™taj, Å¼e pojÄ™cia te bÄ™dÄ… niezbÄ™dne do zrozumienia praktycznych przykÅ‚adÃ³w, ktÃ³re pojawiÄ… siÄ™ w kolejnych rozdziaÅ‚ach!</p>
<p>Przyjrzyjmy siÄ™ konkretnemu przykÅ‚adowi sieci neuronowej, ktÃ³ra wykorzystuje pakiet <code>keras</code> do nauki klasyfikacji rÄ™cznie pisanych cyfr.</p>
<div class="cell">
<details open="">
<summary>Kod</summary>
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(keras)</span></code><button title="Kopiuj do schowka" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>Problemem, ktÃ³ry postaramy siÄ™ rozwiÄ…zaÄ‡ jest klasyfikacja obrazÃ³w pisma rÄ™cznego w skali szaroÅ›ci (28 pikseli na 28 pikseli) do 10 kategorii (od 0 do 9). UÅ¼yjemy zestawu danych MNIST, klasycznego zestawu danych w spoÅ‚ecznoÅ›ci ML, ktÃ³ry istnieje prawie tak dÅ‚ugo jak sama dziedzina i jest intensywnie badany. Jest to zestaw 60 000 obrazÃ³w treningowych oraz 10 000 obrazÃ³w testowych, zebranych przez National Institute of Standards and Technology (NIST w MNIST) w latach 80. MoÅ¼esz myÅ›leÄ‡ o â€œrozwiÄ…zywaniuâ€ MNIST jako o â€œHello Worldâ€ gÅ‚Ä™bokiego uczenia - to jest to, co robisz, aby zweryfikowaÄ‡, Å¼e twoje algorytmy dziaÅ‚ajÄ… zgodnie z oczekiwaniami. Gdy staniesz siÄ™ praktykiem uczenia maszynowego, zobaczysz, Å¼e MNIST pojawia siÄ™ raz za razem, w pracach naukowych, wpisach na blogach i tak dalej. Kilka prÃ³bek MNIST moÅ¼na zobaczyÄ‡ na <a href="#fig-mnist1">Rysunek&nbsp;<span>10.7</span></a>.</p>
<div id="fig-mnist1" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="images/Zrzut ekranu 2023-02-24 o 17.57.00.png" class="img-fluid figure-img" width="600"></p>
<p></p><figcaption class="figure-caption">Rysunek&nbsp;10.7: Kilka przykÅ‚adÃ³w obrazÃ³w ze zbioru MNIST</figcaption><p></p>
</figure>
</div>
<div class="callout callout-style-default callout-caution callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
ZagroÅ¼enie
</div>
</div>
<div class="callout-body-container callout-body">
<p>W uczeniu maszynowym kategoria w problemie klasyfikacyjnym nazywana jest klasÄ…. Punkty danych sÄ… nazywane prÃ³bkami. Klasa zwiÄ…zana z konkretnÄ… prÃ³bkÄ… nazywana jest etykietÄ… (ang. <em>label</em>).</p>
</div>
</div>
<p>ZbiÃ³r danych MNIST jest wstÄ™pnie zaÅ‚adowany do <code>keras</code> w postaci list <code>train</code> i <code>test</code>, z ktÃ³rych kaÅ¼da zawiera zestaw obrazÃ³w (x) i zwiÄ…zanych z nimi etykiet (y):</p>
<div class="cell" data-hash="deeplearning_cache/html/unnamed-chunk-2_fedf61c1f3e72503192f6e2e3613d6e7">
<details open="">
<summary>Kod</summary>
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a>mnist <span class="ot">&lt;-</span> <span class="fu">dataset_mnist</span>()</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>train_images <span class="ot">&lt;-</span> mnist<span class="sc">$</span>train<span class="sc">$</span>x</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>train_labels <span class="ot">&lt;-</span> mnist<span class="sc">$</span>train<span class="sc">$</span>y</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>test_images <span class="ot">&lt;-</span> mnist<span class="sc">$</span>test<span class="sc">$</span>x</span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>test_labels <span class="ot">&lt;-</span> mnist<span class="sc">$</span>test<span class="sc">$</span>y</span></code><button title="Kopiuj do schowka" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p><code>train_images</code> i <code>train_labels</code> tworzÄ… zbiÃ³r treningowy, czyli dane, na podstawie ktÃ³rych model bÄ™dzie siÄ™ uczyÅ‚. Model bÄ™dzie nastÄ™pnie testowany na zbiorze testowym, <code>test_images</code> i <code>test_labels</code> . Obrazy sÄ… zakodowane jako tablice 3D, a etykiety to tablica 1D z cyframi od 0 do 9. PomiÄ™dzy obrazami i etykietami istnieje korespondencja jeden do jednego.</p>
<div class="cell">
<details open="">
<summary>Kod</summary>
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="fu">str</span>(train_images)</span></code><button title="Kopiuj do schowka" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code> int [1:60000, 1:28, 1:28] 0 0 0 0 0 0 0 0 0 0 ...</code></pre>
</div>
<details open="">
<summary>Kod</summary>
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="fu">str</span>(train_labels)</span></code><button title="Kopiuj do schowka" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code> int [1:60000(1d)] 5 0 4 1 9 2 1 3 1 4 ...</code></pre>
</div>
<details open="">
<summary>Kod</summary>
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="fu">str</span>(test_images)</span></code><button title="Kopiuj do schowka" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code> int [1:10000, 1:28, 1:28] 0 0 0 0 0 0 0 0 0 0 ...</code></pre>
</div>
<details open="">
<summary>Kod</summary>
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="fu">str</span>(test_labels)</span></code><button title="Kopiuj do schowka" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code> int [1:10000(1d)] 7 2 1 0 4 1 4 9 5 9 ...</code></pre>
</div>
</div>
<p>PrzepÅ‚yw pracy (ang. <em>workflow</em>) bÄ™dzie nastÄ™pujÄ…cy: najpierw podamy sieci neuronowej dane treningowe, <code>train_images</code> i <code>train_labels</code>. NastÄ™pnie sieÄ‡ nauczy siÄ™ kojarzyÄ‡ obrazy i etykiety. Na koniec poprosimy sieÄ‡ o stworzenie przewidywaÅ„ dla <code>test_images</code> i sprawdzimy, czy te przewidywania pasujÄ… do etykiet z <code>test_labels</code>.</p>
<div class="cell" data-hash="deeplearning_cache/html/unnamed-chunk-4_bfd70e0c37cab0209c01411074e22a1a">
<details open="">
<summary>Kod</summary>
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a>network <span class="ot">&lt;-</span> <span class="fu">keras_model_sequential</span>() <span class="sc">%&gt;%</span></span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dense</span>(<span class="at">units =</span> <span class="dv">512</span>, <span class="at">activation =</span> <span class="st">"relu"</span>, <span class="at">input_shape =</span> <span class="fu">c</span>(<span class="dv">28</span> <span class="sc">*</span> <span class="dv">28</span>)) <span class="sc">%&gt;%</span></span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dense</span>(<span class="at">units =</span> <span class="dv">10</span>, <span class="at">activation =</span> <span class="st">"softmax"</span>)</span></code><button title="Kopiuj do schowka" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>Podstawowym elementem konstrukcyjnym sieci neuronowych jest warstwa, moduÅ‚ przetwarzania danych, o ktÃ³rym moÅ¼na myÅ›leÄ‡ jak o filtrze dla danych. NiektÃ³re dane przychodzÄ… i wychodzÄ… w bardziej uÅ¼ytecznej formie. W szczegÃ³lnoÅ›ci, warstwy wyodrÄ™bniajÄ… reprezentacje z danych, ktÃ³re sÄ… do nich wprowadzane - miejmy nadziejÄ™, Å¼e reprezentacje, ktÃ³re sÄ… bardziej znaczÄ…ce dla danego problemu. WiÄ™kszoÅ›Ä‡ gÅ‚Ä™bokiego uczenia polega na Å‚Ä…czeniu prostych warstw, ktÃ³re implementujÄ… formÄ™ stopniowej destylacji danych. Model gÅ‚Ä™bokiego uczenia jest jak sito do przetwarzania danych, zÅ‚oÅ¼one z szeregu coraz bardziej wyrafinowanych filtrÃ³w danych - warstw.</p>

<div class="no-row-height column-margin column-container"><div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/tw3.jpeg" class="img-fluid figure-img" width="400"></p>
</figure>
</div></div><p>Nasza sieÄ‡ skÅ‚ada siÄ™ z dwÃ³ch warstw, ktÃ³re sÄ… gÄ™sto poÅ‚Ä…czonymi (zwanymi teÅ¼ w peÅ‚ni poÅ‚Ä…czonymi - ang. <em>fully connected</em>) warstwami neuronowymi. Druga (i ostatnia) warstwa jest 10-kierunkowÄ… warstwÄ… softmax, co oznacza, Å¼e zwrÃ³ci tablicÄ™ 10 wynikÃ³w prawdopodobieÅ„stwa (sumujÄ…cych siÄ™ do 1). KaÅ¼dy wynik bÄ™dzie oznaczaÅ‚ prawdopodobieÅ„stwo, Å¼e aktualny obraz cyfry naleÅ¼y do jednej z naszych 10 klas cyfr.</p>
<p>Aby sieÄ‡ byÅ‚a gotowa do treningu, musimy wybraÄ‡ jeszcze trzy rzeczy, w ramach kroku kompilacji:</p>
<ul>
<li>FunkcjÄ™ straty - jak sieÄ‡ bÄ™dzie w stanie zmierzyÄ‡, jak dobrÄ… pracÄ™ wykonuje na danych treningowych, a tym samym czy bÄ™dzie w stanie kierowaÄ‡ siÄ™ we wÅ‚aÅ›ciwym kierunku.</li>
<li>Optymalizator - mechanizm, dziÄ™ki ktÃ³remu sieÄ‡ bÄ™dzie siÄ™ aktualizowaÄ‡ w oparciu o dane, ktÃ³re widzi i swojÄ… funkcjÄ™ straty.</li>
<li>Metryki, ktÃ³re naleÅ¼y monitorowaÄ‡ podczas treningu i testÃ³w - tutaj zajmiemy siÄ™ tylko dokÅ‚adnoÅ›ciÄ… (frakcjÄ… obrazÃ³w, ktÃ³re zostaÅ‚y poprawnie sklasyfikowane - ang. <em>accuracy</em>).</li>
</ul>
<p>DokÅ‚adne przeznaczenie funkcji straty i optymalizatora zostanie wyjaÅ›nione w kolejnych rozdziaÅ‚ach.</p>
<div class="cell" data-hash="deeplearning_cache/html/unnamed-chunk-5_362b131e9423ed281d81da1a2d76781c">
<details open="">
<summary>Kod</summary>
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a>network <span class="sc">%&gt;%</span> <span class="fu">compile</span>(</span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a>  <span class="at">optimizer =</span> <span class="st">"rmsprop"</span>,</span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">loss =</span> <span class="st">"categorical_crossentropy"</span>,</span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">metrics =</span> <span class="fu">c</span>(<span class="st">"accuracy"</span>)</span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Kopiuj do schowka" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>ZauwaÅ¼, Å¼e funkcja <code>compile()</code> modyfikuje sieÄ‡ na bieÅ¼Ä…co (zamiast zwracaÄ‡ nowy obiekt sieci, co jest bardziej typowe dla R). PowÃ³d tego opiszemy, gdy powrÃ³cimy do przykÅ‚adu w dalszej czÄ™Å›ci rozdziaÅ‚u.</p>
<p>Przed treningiem wstÄ™pnie przetworzymy dane, zmieniajÄ…c ich ksztaÅ‚t na taki, jakiego oczekuje sieÄ‡, i skalujÄ…c je tak, by wszystkie wartoÅ›ci mieÅ›ciÅ‚y siÄ™ w przedziale [0, 1]. Poprzednio nasze obrazy treningowe, na przykÅ‚ad, byÅ‚y przechowywane w tablicy o ksztaÅ‚cie <code>(60000, 28, 28)</code> typu <code>integer</code> z wartoÅ›ciami w przedziale [0, 255]. PrzeksztaÅ‚camy go w podwÃ³jnÄ… tablicÄ™ ksztaÅ‚tu <code>(60000, 28 * 28)</code> z wartoÅ›ciami w przedziale [0,1].</p>
<div class="cell" data-hash="deeplearning_cache/html/unnamed-chunk-6_496d486d00834c24faa318baf5f45336">
<details open="">
<summary>Kod</summary>
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a>train_images <span class="ot">&lt;-</span> <span class="fu">array_reshape</span>(train_images, <span class="fu">c</span>(<span class="dv">60000</span>, <span class="dv">28</span> <span class="sc">*</span> <span class="dv">28</span>))</span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a>train_images <span class="ot">&lt;-</span> train_images <span class="sc">/</span> <span class="dv">255</span></span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a>test_images <span class="ot">&lt;-</span> <span class="fu">array_reshape</span>(test_images, <span class="fu">c</span>(<span class="dv">10000</span>, <span class="dv">28</span> <span class="sc">*</span> <span class="dv">28</span>))</span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a>test_images <span class="ot">&lt;-</span> test_images <span class="sc">/</span> <span class="dv">255</span></span></code><button title="Kopiuj do schowka" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>ZauwaÅ¼, Å¼e uÅ¼ywamy funkcji <code>array_reshape()</code> zamiast funkcji <code>dim()</code> do zmiany ksztaÅ‚tu tablicy. PowÃ³d tego omÃ³wimy pÃ³Åºniej, kiedy bÄ™dziemy mÃ³wiÄ‡ o przeksztaÅ‚caniu tensorÃ³w. Musimy rÃ³wnieÅ¼ zakodowaÄ‡ etykiety w sposÃ³b kategoryczny.</p>
<div class="cell" data-hash="deeplearning_cache/html/unnamed-chunk-7_28d63e0e0f078c20e12c43e97b709e5f">
<details open="">
<summary>Kod</summary>
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a>train_labels <span class="ot">&lt;-</span> <span class="fu">to_categorical</span>(train_labels)</span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a>test_labels <span class="ot">&lt;-</span> <span class="fu">to_categorical</span>(test_labels)</span></code><button title="Kopiuj do schowka" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>Teraz jesteÅ›my gotowi do trenowania sieci, co w <code>keras</code> odbywa siÄ™ poprzez wywoÅ‚anie metody <code>fit</code> sieci - dopasowujemy model do danych treningowych:</p>
<div class="cell" data-hash="deeplearning_cache/html/unnamed-chunk-8_879fceaa3973ae3c539ce58814e96936">
<details open="">
<summary>Kod</summary>
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a>network <span class="sc">%&gt;%</span> <span class="fu">fit</span>(train_images, train_labels, <span class="at">epochs =</span> <span class="dv">5</span>, <span class="at">batch_size =</span> <span class="dv">128</span>)</span></code><button title="Kopiuj do schowka" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>Podczas treningu wyÅ›wietlane sÄ… dwie wielkoÅ›ci: strata sieci na danych treningowych oraz dokÅ‚adnoÅ›Ä‡ sieci na danych treningowych. Szybko osiÄ…gamy dokÅ‚adnoÅ›Ä‡ 0,989 (98,9%) na danych treningowych. Teraz sprawdÅºmy, czy model dobrze radzi sobie rÃ³wnieÅ¼ na zbiorze testowym:</p>
<div class="cell" data-hash="deeplearning_cache/html/unnamed-chunk-9_6c7090cd2f5e105fad5466214c75a717">
<details open="">
<summary>Kod</summary>
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a>metrics <span class="ot">&lt;-</span> network <span class="sc">%&gt;%</span> <span class="fu">evaluate</span>(test_images, test_labels)</span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a>metrics</span></code><button title="Kopiuj do schowka" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>      loss   accuracy 
0.07629414 0.97790003 </code></pre>
</div>
</div>
<p>DokÅ‚adnoÅ›Ä‡ zestawu testowego okazuje siÄ™ wynosiÄ‡ 97,8% - to sporo mniej niÅ¼ dokÅ‚adnoÅ›Ä‡ zestawu treningowego. Ta rÃ³Å¼nica miÄ™dzy dokÅ‚adnoÅ›ciÄ… treningu a dokÅ‚adnoÅ›ciÄ… testu jest przykÅ‚adem nadmiernego dopasowania (fakt, Å¼e modele uczenia maszynowego majÄ… tendencjÄ™ do osiÄ…gania gorszych wynikÃ³w na nowych danych niÅ¼ na danych treningowych). Wygenerujmy przewidywania dla pierwszych 10 prÃ³bek zbioru testowego:</p>
<div class="cell" data-hash="deeplearning_cache/html/unnamed-chunk-10_57bddd67053e1e741c2540e3d41b5e23">
<details open="">
<summary>Kod</summary>
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a>network <span class="sc">%&gt;%</span> <span class="fu">predict</span>(test_images[<span class="dv">1</span><span class="sc">:</span><span class="dv">10</span>,]) <span class="sc">|&gt;</span> <span class="fu">k_argmax</span>()</span></code><button title="Kopiuj do schowka" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>tf.Tensor([7 2 1 0 4 1 4 9 5 9], shape=(10), dtype=int64)</code></pre>
</div>
</div>
<p>Na tym koÅ„czymy nasz pierwszy przykÅ‚ad - wÅ‚aÅ›nie zobaczyÅ‚eÅ›, jak moÅ¼na zbudowaÄ‡ i wytrenowaÄ‡ sieÄ‡ neuronowÄ… do klasyfikacji pisma rÄ™cznego w mniej niÅ¼ 20 liniach kodu R. W nastÄ™pnym rozdziale omÃ³wimy szczegÃ³Å‚owo kaÅ¼dy element, ktÃ³ry uÅ¼yliÅ›my i wyjaÅ›nimy, co on robi. Dowiesz siÄ™ o tensorach, obiektach przechowujÄ…cych dane w sieci; o operacjach na tensorach, z ktÃ³rych skÅ‚adajÄ… siÄ™ warstwy; oraz o spadku gradientu, ktÃ³ry pozwala sieci uczyÄ‡ siÄ™ na przykÅ‚adach treningowych.</p>
<section id="operacje-na-danych" class="level3 page-columns page-full" data-number="10.4.1">
<h3 data-number="10.4.1" class="anchored" data-anchor-id="operacje-na-danych"><span class="header-section-number">10.4.1</span> Operacje na danych</h3>
<p>W poprzednim przykÅ‚adzie zaczynaliÅ›my od danych przechowywanych w wielowymiarowych tablicach, zwanych rÃ³wnieÅ¼ tensorami. Wszystkie obecne systemy uczenia maszynowego uÅ¼ywajÄ… tensorÃ³w jako podstawowej struktury danych. Tensory sÄ… fundamentalne dla tej dziedziny - tak fundamentalne, Å¼e Googleâ€™s TensorFlow zostaÅ‚ nazwany na ich czeÅ›Ä‡. Czym wiÄ™c jest tensor?</p>
<p>Tensory sÄ… uogÃ³lnieniem wektorÃ³w i macierzy na dowolnÄ… liczbÄ™ wymiarÃ³w (zauwaÅ¼, Å¼e w kontekÅ›cie tensorÃ³w â€œwymiarâ€ jest czÄ™sto nazywany â€œosiÄ…â€). W R wektory sÄ… uÅ¼ywane do tworzenia i manipulowania tensorami 1D, a matryce sÄ… uÅ¼ywane do tensorÃ³w 2D. Dla wymiarÃ³w wyÅ¼szego rzÄ™du uÅ¼ywane sÄ… obiekty tablicowe (ktÃ³re obsÅ‚ugujÄ… dowolnÄ… liczbÄ™ wymiarÃ³w).</p>
<section id="skalary" class="level4" data-number="10.4.1.1">
<h4 data-number="10.4.1.1" class="anchored" data-anchor-id="skalary"><span class="header-section-number">10.4.1.1</span> Skalary</h4>
<p>Tensor, ktÃ³ry zawiera tylko jednÄ… liczbÄ™ nazywany jest skalarem (lub tensorem skalarnym, lub tensorem 0-wymiarowym, lub tensorem 0D). ChociaÅ¼ R nie ma typu danych do reprezentowania skalarÃ³w (wszystkie obiekty numeryczne sÄ… wektorami, macierzami lub tablicami), wektor R, ktÃ³ry ma zawsze dÅ‚ugoÅ›Ä‡ 1, jest koncepcyjnie podobny do skalara.</p>
</section>
<section id="wektory" class="level4" data-number="10.4.1.2">
<h4 data-number="10.4.1.2" class="anchored" data-anchor-id="wektory"><span class="header-section-number">10.4.1.2</span> Wektory</h4>
<p>Jednowymiarowa tablica liczb nazywana jest wektorem lub tensorem 1D. MÃ³wi siÄ™, Å¼e tensor 1D ma dokÅ‚adnie jednÄ… oÅ›. MoÅ¼emy przekonwertowaÄ‡ wektor R na obiekt tablicowy (<code>array</code>), aby sprawdziÄ‡ jego wymiary:</p>
<div class="cell">
<details open="">
<summary>Kod</summary>
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a>x <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">12</span>, <span class="dv">3</span>, <span class="dv">6</span>, <span class="dv">14</span>, <span class="dv">10</span>)</span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a><span class="fu">str</span>(x)</span></code><button title="Kopiuj do schowka" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code> num [1:5] 12 3 6 14 10</code></pre>
</div>
<details open="">
<summary>Kod</summary>
<div class="sourceCode cell-code" id="cb22"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a><span class="fu">dim</span>(<span class="fu">as.array</span>(x))</span></code><button title="Kopiuj do schowka" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 5</code></pre>
</div>
</div>
<p>Wektor ten ma piÄ™Ä‡ wpisÃ³w i dlatego nazywany jest wektorem 5-wymiarowym. Nie naleÅ¼y myliÄ‡ wektora 5D z tensorem 5D! Wektor 5D ma tylko jednÄ… oÅ› i ma piÄ™Ä‡ wymiarÃ³w wzdÅ‚uÅ¼ swojej osi, podczas gdy tensor 5D ma piÄ™Ä‡ osi (i moÅ¼e mieÄ‡ dowolnÄ… liczbÄ™ wymiarÃ³w wzdÅ‚uÅ¼ kaÅ¼dej osi). WymiarowoÅ›Ä‡ moÅ¼e oznaczaÄ‡ albo liczbÄ™ wpisÃ³w wzdÅ‚uÅ¼ konkretnej osi (jak w przypadku naszego wektora 5D), albo liczbÄ™ osi w tensorze (jak tensor 5D), co moÅ¼e byÄ‡ czasem mylÄ…ce. W tym drugim przypadku technicznie poprawniej jest mÃ³wiÄ‡ o tensorze rzÄ™du 5 (ranga tensora to liczba osi), ale niejednoznaczny zapis tensor 5D jest powszechny niezaleÅ¼nie od tego.</p>
</section>
<section id="macierze" class="level4" data-number="10.4.1.3">
<h4 data-number="10.4.1.3" class="anchored" data-anchor-id="macierze"><span class="header-section-number">10.4.1.3</span> Macierze</h4>
<p>Dwuwymiarowa tablica liczb to macierz, czyli tensor 2D. Macierz ma dwie osie (czÄ™sto nazywane wierszami i kolumnami). MoÅ¼esz wizualnie zinterpretowaÄ‡ macierz jako prostokÄ…tnÄ… siatkÄ™ liczb:</p>
<div class="cell">
<details open="">
<summary>Kod</summary>
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a>x <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="fu">rep</span>(<span class="dv">0</span>, <span class="dv">3</span><span class="sc">*</span><span class="dv">5</span>), <span class="at">nrow =</span> <span class="dv">3</span>, <span class="at">ncol =</span> <span class="dv">5</span>)</span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a>x</span></code><button title="Kopiuj do schowka" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>     [,1] [,2] [,3] [,4] [,5]
[1,]    0    0    0    0    0
[2,]    0    0    0    0    0
[3,]    0    0    0    0    0</code></pre>
</div>
<details open="">
<summary>Kod</summary>
<div class="sourceCode cell-code" id="cb26"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a><span class="fu">dim</span>(x)</span></code><button title="Kopiuj do schowka" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 3 5</code></pre>
</div>
</div>
</section>
<section id="tensory" class="level4" data-number="10.4.1.4">
<h4 data-number="10.4.1.4" class="anchored" data-anchor-id="tensory"><span class="header-section-number">10.4.1.4</span> Tensory</h4>
<p>JeÅ›li spakujemy takie macierze do nowej tablicy, otrzymamy tensor 3D, ktÃ³ry moÅ¼emy wizualnie zinterpretowaÄ‡ jako szeÅ›cian liczb:</p>
<div class="cell">
<details open="">
<summary>Kod</summary>
<div class="sourceCode cell-code" id="cb28"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a>x <span class="ot">&lt;-</span> <span class="fu">array</span>(<span class="fu">rep</span>(<span class="dv">0</span>, <span class="dv">2</span><span class="sc">*</span><span class="dv">3</span><span class="sc">*</span><span class="dv">2</span>), <span class="at">dim =</span> <span class="fu">c</span>(<span class="dv">2</span>,<span class="dv">3</span>,<span class="dv">2</span>))</span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a><span class="fu">str</span>(x)</span></code><button title="Kopiuj do schowka" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code> num [1:2, 1:3, 1:2] 0 0 0 0 0 0 0 0 0 0 ...</code></pre>
</div>
<details open="">
<summary>Kod</summary>
<div class="sourceCode cell-code" id="cb30"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a><span class="fu">dim</span>(x)</span></code><button title="Kopiuj do schowka" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 2 3 2</code></pre>
</div>
</div>
<p>PakujÄ…c tensory 3D w tablicy, moÅ¼esz stworzyÄ‡ tensor 4D i tak dalej. W gÅ‚Ä™bokim uczeniu siÄ™, generalnie bÄ™dziesz manipulowaÄ‡ tensorami, ktÃ³re sÄ… 0D do 4D, a tensory 5D pojawiÄ… siÄ™, jeÅ›li bÄ™dziesz przetwarzaÄ‡ dane wideo.</p>
</section>
<section id="kluczowe-wÅ‚asnoÅ›ci" class="level4 page-columns page-full" data-number="10.4.1.5">
<h4 data-number="10.4.1.5" class="anchored" data-anchor-id="kluczowe-wÅ‚asnoÅ›ci"><span class="header-section-number">10.4.1.5</span> Kluczowe wÅ‚asnoÅ›ci</h4>
<p>Tensor jest okreÅ›lony przez trzy kluczowe atrybuty:</p>
<ul>
<li>Liczba osi - np. tensor 3D ma trzy osie, a macierz dwie osie.</li>
<li>KsztaÅ‚t - to wektor liczb caÅ‚kowitych, ktÃ³ry opisuje, ile wymiarÃ³w ma tensor wzdÅ‚uÅ¼ kaÅ¼dej osi. Na przykÅ‚ad poprzedni przykÅ‚ad macierzy ma ksztaÅ‚t (3, 5), a przykÅ‚ad tensora 3D ma ksztaÅ‚t (3, 3, 5). Wektor ma ksztaÅ‚t z pojedynczym elementem, o wymiarze 5. MoÅ¼esz sprawdziÄ‡ wymiary dowolnej tablicy za pomocÄ… funkcji <code>dim()</code>.</li>
<li>Typ danych - typ danych zawartych w tensorze; na przykÅ‚ad, typem tensora moÅ¼e byÄ‡ liczba caÅ‚kowita lub podwÃ³jna<a href="#fn3" class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a>. W rzadkich przypadkach moÅ¼esz zobaczyÄ‡ tensor znakowy<a href="#fn4" class="footnote-ref" id="fnref4" role="doc-noteref"><sup>4</sup></a>. PoniewaÅ¼ jednak tensory Å¼yjÄ… we wstÄ™pnie przydzielonych segmentach pamiÄ™ci, a Å‚aÅ„cuchy znakÃ³w, bÄ™dÄ…c zmiennej dÅ‚ugoÅ›ci, wykluczyÅ‚yby uÅ¼ycie tej implementacji, sÄ… one rzadziej uÅ¼ywane.</li>
</ul>
<div class="no-row-height column-margin column-container"><li id="fn3"><p><sup>3</sup>&nbsp;float - czyli liczba rzeczywista</p></li><li id="fn4"><p><sup>4</sup>&nbsp;typu <code>character</code></p></li></div><p>Aby to skonkretyzowaÄ‡, spÃ³jrzmy na dane, ktÃ³re przetwarzaliÅ›my w przykÅ‚adzie MNIST. Najpierw Å‚adujemy zbiÃ³r danych MNIST:</p>
<div class="cell" data-hash="deeplearning_cache/html/unnamed-chunk-14_ea3d96b8d181d853268ddaa979c2afdb">
<details open="">
<summary>Kod</summary>
<div class="sourceCode cell-code" id="cb32"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a>train_images <span class="ot">&lt;-</span> mnist<span class="sc">$</span>train<span class="sc">$</span>x</span>
<span id="cb32-2"><a href="#cb32-2" aria-hidden="true" tabindex="-1"></a>train_labels <span class="ot">&lt;-</span> mnist<span class="sc">$</span>train<span class="sc">$</span>y</span>
<span id="cb32-3"><a href="#cb32-3" aria-hidden="true" tabindex="-1"></a>test_images <span class="ot">&lt;-</span> mnist<span class="sc">$</span>test<span class="sc">$</span>x</span>
<span id="cb32-4"><a href="#cb32-4" aria-hidden="true" tabindex="-1"></a>test_labels <span class="ot">&lt;-</span> mnist<span class="sc">$</span>test<span class="sc">$</span>y</span>
<span id="cb32-5"><a href="#cb32-5" aria-hidden="true" tabindex="-1"></a><span class="fu">length</span>(<span class="fu">dim</span>(train_images)) <span class="co"># trzy osie</span></span></code><button title="Kopiuj do schowka" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 3</code></pre>
</div>
<details open="">
<summary>Kod</summary>
<div class="sourceCode cell-code" id="cb34"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a><span class="fu">dim</span>(train_images) <span class="co"># ksztaÅ‚t</span></span></code><button title="Kopiuj do schowka" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 60000    28    28</code></pre>
</div>
<details open="">
<summary>Kod</summary>
<div class="sourceCode cell-code" id="cb36"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb36-1"><a href="#cb36-1" aria-hidden="true" tabindex="-1"></a><span class="fu">typeof</span>(train_images) <span class="co"># typ danych</span></span></code><button title="Kopiuj do schowka" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>[1] "integer"</code></pre>
</div>
</div>
<p>Jak wiÄ™c widaÄ‡ jest to tensor 3D liczb caÅ‚kowitych. DokÅ‚adniej, jest to tablica 60000 macierzy 28 Ã— 28 liczb caÅ‚kowitych. KaÅ¼da taka macierz jest obrazem w skali szaroÅ›ci, o wspÃ³Å‚czynnikach od 0 do 255. WykreÅ›lmy piÄ…tÄ… cyfrÄ™ w tym tensorze 3D:</p>
<div class="cell">
<details open="">
<summary>Kod</summary>
<div class="sourceCode cell-code" id="cb38"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb38-1"><a href="#cb38-1" aria-hidden="true" tabindex="-1"></a>digit <span class="ot">&lt;-</span> train_images[<span class="dv">5</span>,,]</span>
<span id="cb38-2"><a href="#cb38-2" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="fu">as.raster</span>(digit, <span class="at">max =</span> <span class="dv">255</span>))</span></code><button title="Kopiuj do schowka" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<p><img src="deeplearning_files/figure-html/unnamed-chunk-15-1.png" class="img-fluid" width="672"></p>
</div>
</div>
</section>
<section id="operacje-na-tensorach" class="level4" data-number="10.4.1.6">
<h4 data-number="10.4.1.6" class="anchored" data-anchor-id="operacje-na-tensorach"><span class="header-section-number">10.4.1.6</span> Operacje na tensorach</h4>
<p>W poprzednim przykÅ‚adzie wybraliÅ›my konkretnÄ… cyfrÄ™ wzdÅ‚uÅ¼ pierwszej osi za pomocÄ… skÅ‚adni <code>train_images[i,,]</code>. Wybieranie konkretnych elementÃ³w w tensorze nazywa siÄ™ <em>tensor slicing</em>. Przyjrzyjmy siÄ™ operacjom <em>tensor slicing</em>, ktÃ³re moÅ¼na wykonaÄ‡ na tablicach R. PoniÅ¼ej wybrano cyfry od #10 do #99 i umieszczono je w tablicy o ksztaÅ‚cie <code>(90, 28, 28)</code>:</p>
<div class="cell">
<details open="">
<summary>Kod</summary>
<div class="sourceCode cell-code" id="cb39"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a>my_slice <span class="ot">&lt;-</span> train_images[<span class="dv">10</span><span class="sc">:</span><span class="dv">99</span>,,]</span>
<span id="cb39-2"><a href="#cb39-2" aria-hidden="true" tabindex="-1"></a><span class="fu">dim</span>(my_slice)</span></code><button title="Kopiuj do schowka" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 90 28 28</code></pre>
</div>
</div>
<p>Generalnie, moÅ¼esz wybraÄ‡ pomiÄ™dzy dwoma dowolnymi indeksami wzdÅ‚uÅ¼ kaÅ¼dej osi tensora. Na przykÅ‚ad, aby wybraÄ‡ 14 Ã— 14 pikseli w prawym dolnym rogu wszystkich obrazÃ³w, uÅ¼yj:</p>
<div class="cell">
<details open="">
<summary>Kod</summary>
<div class="sourceCode cell-code" id="cb41"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb41-1"><a href="#cb41-1" aria-hidden="true" tabindex="-1"></a>my_slice <span class="ot">&lt;-</span> train_images[, <span class="dv">15</span><span class="sc">:</span><span class="dv">28</span>, <span class="dv">15</span><span class="sc">:</span><span class="dv">28</span>]</span></code><button title="Kopiuj do schowka" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>Generalnie, pierwszÄ… osiÄ… we wszystkich tensorach danych, z ktÃ³rymi zetkniesz siÄ™ w gÅ‚Ä™bokim uczeniu, bÄ™dzie oÅ› prÃ³bek (czasami nazywana wymiarem prÃ³bek). W przykÅ‚adzie MNIST, prÃ³bki to obrazy cyfr. Ponadto, modele gÅ‚Ä™bokiego uczenia nie przetwarzajÄ… caÅ‚ego zbioru danych na raz, ale raczej dzielÄ… dane na maÅ‚e partie (ang. <em>batch</em>). Konkretnie, oto jedna partia naszych cyfr MNIST, o rozmiarze partii 128:</p>
<div class="cell">
<details open="">
<summary>Kod</summary>
<div class="sourceCode cell-code" id="cb42"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb42-1"><a href="#cb42-1" aria-hidden="true" tabindex="-1"></a>batch <span class="ot">&lt;-</span> train_images[<span class="dv">1</span><span class="sc">:</span><span class="dv">128</span>,,]</span></code><button title="Kopiuj do schowka" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>Gdy rozwaÅ¼amy tensor partii, pierwsza oÅ› nazywana jest osiÄ… partii lub wymiarem partii. Jest to termin, ktÃ³ry czÄ™sto spotkasz podczas korzystania z <code>keras</code> i innych bibliotek uczenia gÅ‚Ä™bokiego.</p>
<p>UÅ›ciÅ›lijmy tensory danych za pomocÄ… kilku przykÅ‚adÃ³w podobnych do tego, co napotkasz pÃ³Åºniej. Dane, ktÃ³rymi bÄ™dziesz manipulowaÅ‚, prawie zawsze bÄ™dÄ… naleÅ¼aÅ‚y do jednej z nastÄ™pujÄ…cych kategorii:</p>
<ul>
<li>Dane wektorowe-2D tensory ksztaÅ‚tu (prÃ³bki, cechy);</li>
<li>Dane czasowe lub dane sekwencyjne-3D tensory ksztaÅ‚tu (prÃ³bki, kroki czasowe, cechy);</li>
<li>Obrazy-4D tensory ksztaÅ‚tu (prÃ³bki, wysokoÅ›Ä‡, szerokoÅ›Ä‡, kanaÅ‚y) lub (prÃ³bki, kanaÅ‚y, wysokoÅ›Ä‡, szerokoÅ›Ä‡);</li>
<li>Wideo-5D tensory ksztaÅ‚tu (prÃ³bki, klatki, wysokoÅ›Ä‡, szerokoÅ›Ä‡, kanaÅ‚y) lub (prÃ³bki, klatki, kanaÅ‚y, wysokoÅ›Ä‡, szerokoÅ›Ä‡).</li>
</ul>
<p>Dane wektorowe sÄ… najczÄ™Å›ciej spotykanym przykÅ‚adem formatu danych. W takim zbiorze danych kaÅ¼dy pojedynczy punkt danych moÅ¼e byÄ‡ zakodowany jako wektor, a wiÄ™c partia danych bÄ™dzie zakodowana jako tensor 2D (czyli tablica wektorÃ³w), gdzie pierwsza oÅ› jest osiÄ… prÃ³bek, a druga osiÄ… cech. Przyjrzyjmy siÄ™ dwÃ³m przykÅ‚adom:</p>
<ul>
<li>Aktuarialny zbiÃ³r danych osÃ³b, gdzie rozpatrujemy wiek, kod i dochÃ³d kaÅ¼dej osoby. KaÅ¼da osoba moÅ¼e byÄ‡ scharakteryzowana jako wektor 3 wartoÅ›ci, a zatem caÅ‚y zbiÃ³r danych 100000 osÃ³b moÅ¼e byÄ‡ przechowywany w tensorze 2D o ksztaÅ‚cie <code>(100000, 3)</code>.</li>
<li>ZbiÃ³r dokumentÃ³w tekstowych, gdzie kaÅ¼dy dokument reprezentujemy poprzez zliczanie ile razy pojawia siÄ™ w nim kaÅ¼de sÅ‚owo (ze sÅ‚ownika 20000 sÅ‚Ã³w). KaÅ¼dy dokument moÅ¼na zakodowaÄ‡ jako wektor 20000 wartoÅ›ci (po jednym zliczeniu na sÅ‚owo w sÅ‚owniku), a zatem caÅ‚y zbiÃ³r 500 dokumentÃ³w moÅ¼na zapisaÄ‡ w tensorze ksztaÅ‚tu <code>(500, 20000)</code>.</li>
</ul>
<p>Gdy w danych waÅ¼ny siÄ™ czas (lub kolejnoÅ›Ä‡ sekwencji), sensowne jest przechowywanie ich w tensorze 3D z wyraÅºnÄ… osiÄ… czasu. KaÅ¼da prÃ³bka moÅ¼e byÄ‡ zakodowana jako ciÄ…g wektorÃ³w (tensor 2D), a zatem partia danych bÄ™dzie zakodowana jako tensor 3D (patrz <a href="#fig-tensor1">Rysunek&nbsp;<span>10.8</span></a>).</p>
<div id="fig-tensor1" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="images/Zrzut ekranu 2023-02-24 o 18.59.47.png" class="img-fluid figure-img" width="400"></p>
<p></p><figcaption class="figure-caption">Rysunek&nbsp;10.8: Schemat zapisu danych sekwencyjnych</figcaption><p></p>
</figure>
</div>
<p>OÅ› czasu jest zawsze drugÄ… osiÄ…, zgodnie z konwencjÄ…. Przyjrzyjmy siÄ™ kilku przykÅ‚adom:</p>
<ul>
<li>ZbiÃ³r danych o cenach akcji. Co minutÄ™ zapisujemy aktualnÄ… cenÄ™ akcji, najwyÅ¼szÄ… cenÄ™ w danej minucie oraz najniÅ¼szÄ… cenÄ™ w danej minucie. Tak wiÄ™c kaÅ¼da minuta jest zakodowana jako wektor 3D, caÅ‚y dzieÅ„ handlu jest zakodowany jako tensor 2D o ksztaÅ‚cie <code>(390, 3)</code> (jest 390 minut w dniu handlu), a 250 dni danych moÅ¼e byÄ‡ przechowywanych w tensorze 3D o ksztaÅ‚cie <code>(250, 390, 3)</code>. W tym przypadku kaÅ¼da prÃ³bka to jeden dzieÅ„ danych.</li>
<li>ZbiÃ³r danych tweetÃ³w, gdzie kaÅ¼dy tweet kodujemy jako ciÄ…g 140 znakÃ³w z alfabetu 128 unikalnych znakÃ³w. W tym ustawieniu kaÅ¼dy znak moÅ¼e byÄ‡ zakodowany jako wektor binarny o rozmiarze 128 (wektor wszystkich zer, z wyjÄ…tkiem wpisu 1 w indeksie odpowiadajÄ…cym znakowi). NastÄ™pnie kaÅ¼dy tweet moÅ¼e byÄ‡ zakodowany jako tensor 2D o ksztaÅ‚cie <code>(140, 128)</code>, a zbiÃ³r danych 1 miliona tweetÃ³w moÅ¼e byÄ‡ przechowywany w tensorze o ksztaÅ‚cie <code>(1000000, 140, 128)</code>.</li>
</ul>
<p>Obrazy majÄ… zazwyczaj trzy wymiary: wysokoÅ›Ä‡, szerokoÅ›Ä‡ i gÅ‚Ä™biÄ™ koloru. ChoÄ‡ obrazy w skali szaroÅ›ci (jak nasze cyfry MNIST) majÄ… tylko jeden kanaÅ‚ koloru i mogÅ‚yby byÄ‡ przechowywane w tensorach 2D, to konwencjonalnie tensory obrazÃ³w sÄ… zawsze trÃ³jwymiarowe, z jednowymiarowym kanaÅ‚em koloru dla obrazÃ³w w skali szaroÅ›ci. Partia 128 obrazÃ³w w skali szaroÅ›ci o rozmiarach 256 Ã— 256 mogÅ‚aby wiÄ™c byÄ‡ przechowywana w tensorze o ksztaÅ‚cie <code>(128, 256, 256, 1)</code>, a partia 128 obrazÃ³w kolorowych - w tensorze o ksztaÅ‚cie <code>(128, 256, 256, 3)</code> (patrz <a href="#fig-tensor2">Rysunek&nbsp;<span>10.9</span></a>).</p>
<div id="fig-tensor2" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="images/Zrzut ekranu 2023-02-24 o 19.04.18.png" class="img-fluid figure-img" width="400"></p>
<p></p><figcaption class="figure-caption">Rysunek&nbsp;10.9: Zapis kolorowego obrazu</figcaption><p></p>
</figure>
</div>
<p>IstniejÄ… dwie konwencje dla ksztaÅ‚tÃ³w tensorÃ³w obrazÃ³w: konwencja <em>channels-last</em> (uÅ¼ywana przez TensorFlow) i konwencja <em>channels-firs</em>t (uÅ¼ywana przez Theano). Framework uczenia maszynowego TensorFlow, od Google, umieszcza oÅ› gÅ‚Ä™bokoÅ›ci koloru na koÅ„cu: <code>(sample, height, width, color_depth)</code>. Tymczasem Theano umieszcza oÅ› gÅ‚Ä™bi koloru zaraz po osi wsadowej: <code>(sample, color_depth, height, width)</code>. Keras zapewniajÄ… wsparcie dla obu formatÃ³w.</p>
<p>Dane wideo sÄ… jednym z niewielu typÃ³w danych ze Å›wiata rzeczywistego, dla ktÃ³rych bÄ™dziesz potrzebowaÅ‚ tensorÃ³w 5D. Wideo moÅ¼e byÄ‡ rozumiane jako sekwencja klatek, z ktÃ³rych kaÅ¼da jest obrazem kolorowym. PoniewaÅ¼ kaÅ¼da klatka moÅ¼e byÄ‡ przechowywana w tensorze 3D <code>(wysokoÅ›Ä‡, szerokoÅ›Ä‡, gÅ‚Ä™bokoÅ›Ä‡ koloru)</code>, sekwencja klatek moÅ¼e byÄ‡ przechowywana w tensorze 4D <code>(klatki, wysokoÅ›Ä‡, szerokoÅ›Ä‡, gÅ‚Ä™bokoÅ›Ä‡ koloru)</code>, a zatem partia rÃ³Å¼nych filmÃ³w moÅ¼e byÄ‡ przechowywana w tensorze 5D o ksztaÅ‚cie <code>(prÃ³bki, klatki, wysokoÅ›Ä‡, szerokoÅ›Ä‡, gÅ‚Ä™bokoÅ›Ä‡ koloru)</code>.</p>
<p>Na przykÅ‚ad 60-sekundowy klip wideo YouTube o wymiarach 256 Ã— 144, prÃ³bkowany z prÄ™dkoÅ›ciÄ… 4 klatek na sekundÄ™, miaÅ‚by 240 klatek. Partia czterech takich klipÃ³w wideo byÅ‚aby przechowywana w tensorze o ksztaÅ‚cie <code>(4, 240, 256, 144, 3)</code>. To w sumie 106168320 wartoÅ›ci! JeÅ›li typ danych tensora to <em>double</em>, to kaÅ¼da wartoÅ›Ä‡ jest przechowywana w 64 bitach, wiÄ™c tensor reprezentowaÅ‚by 810 MB. Sporo ğŸ˜±! Filmy, ktÃ³re spotykasz w prawdziwym Å¼yciu sÄ… znacznie lÅ¼ejsze, poniewaÅ¼ nie sÄ… przechowywane w <code>float32</code> i zazwyczaj sÄ… silnie skompresowane (jak w formacie MPEG).</p>
<p>Podobnie jak kaÅ¼dy program komputerowy moÅ¼e byÄ‡ ostatecznie zredukowany do maÅ‚ego zestawu operacji binarnych na wejÅ›ciach binarnych (AND, OR, NOR, i tak dalej), wszystkie transformacje uczone przez gÅ‚Ä™bokie sieci neuronowe mogÄ… byÄ‡ zredukowane do garÅ›ci operacji tensorowych stosowanych do tensorÃ³w danych liczbowych. Na przykÅ‚ad, moÅ¼liwe jest dodawanie tensorÃ³w, mnoÅ¼enie tensorÃ³w i tak dalej. W naszym poczÄ…tkowym przykÅ‚adzie budowaliÅ›my naszÄ… sieÄ‡ poprzez ukÅ‚adanie gÄ™stych warstw jedna na drugiej. Instancja warstwy wyglÄ…da tak:</p>
<div class="cell">
<details open="">
<summary>Kod</summary>
<div class="sourceCode cell-code" id="cb43"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb43-1"><a href="#cb43-1" aria-hidden="true" tabindex="-1"></a><span class="fu">layer_dense</span>(<span class="at">units =</span> <span class="dv">512</span>, <span class="at">activation =</span> <span class="st">"relu"</span>)</span></code><button title="Kopiuj do schowka" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>Warstwa ta moÅ¼e byÄ‡ interpretowana jako funkcja, ktÃ³ra przyjmuje na wejÅ›cie tensor 2D i zwraca inny tensor 2D - nowÄ… reprezentacjÄ™ tensora wejÅ›ciowego. MoÅ¼na jÄ… teÅ¼ przedstawiÄ‡ inaczej (gdzie <code>W</code> jest tensorem 2D, a <code>b</code> jest wektorem):</p>
<div class="cell">
<details open="">
<summary>Kod</summary>
<div class="sourceCode cell-code" id="cb44"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb44-1"><a href="#cb44-1" aria-hidden="true" tabindex="-1"></a><span class="co"># nie wykonuj</span></span>
<span id="cb44-2"><a href="#cb44-2" aria-hidden="true" tabindex="-1"></a>output <span class="ot">=</span> <span class="fu">relu</span>(<span class="fu">dot</span>(W, input) <span class="sc">+</span> b)</span></code><button title="Kopiuj do schowka" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>Mamy tu trzy operacje na tensorach: iloczyn (<code>dot</code>) miÄ™dzy tensorem wejÅ›ciowym a tensorem <code>W</code>, dodawanie (<code>+</code>) miÄ™dzy wynikowym tensorem 2D wektorem <code>b</code> i wreszcie operacjÄ™ <code>relu</code>, gdzie <code>relu(x)</code> to <code>max(x, 0)</code>.</p>
<p>Operacja <code>relu</code> i dodawanie sÄ… operacjami typu <em>element-wise</em>: operacjami, ktÃ³re sÄ… stosowane niezaleÅ¼nie do kaÅ¼dego wpisu w rozwaÅ¼anych tensorach. Oznacza to, Å¼e operacje te sÄ… bardzo podatne na wektoryzacje. W praktyce, gdy mamy do czynienia z tablicami R, operacje te sÄ… dostÄ™pne jako dobrze zoptymalizowane wbudowane funkcje R, ktÃ³re same delegujÄ… ciÄ™Å¼kÄ… pracÄ™ do BLAS (Basic Linear Algebra Subprograms). BLAS to niskopoziomowe, wysoce wektoryzowalne, wydajne procedury manipulacji tensorami, zwykle zaimplementowane w Fortranie lub C.</p>
<p>Operacje na tensorach moÅ¼na wykonywaÄ‡ rÃ³wnieÅ¼ wtedy, gdy sÄ… one innych wymiarÃ³w. PrzykÅ‚adowo:</p>
<div class="cell">
<details open="">
<summary>Kod</summary>
<div class="sourceCode cell-code" id="cb45"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb45-1"><a href="#cb45-1" aria-hidden="true" tabindex="-1"></a><span class="co"># x is a tensor of random values with shape (64, 3, 32, 10)</span></span>
<span id="cb45-2"><a href="#cb45-2" aria-hidden="true" tabindex="-1"></a>x <span class="ot">&lt;-</span> <span class="fu">array</span>(<span class="fu">round</span>(<span class="fu">runif</span>(<span class="dv">1000</span>, <span class="dv">0</span>, <span class="dv">9</span>)), <span class="at">dim =</span> <span class="fu">c</span>(<span class="dv">64</span>, <span class="dv">3</span>, <span class="dv">32</span>, <span class="dv">10</span>))</span>
<span id="cb45-3"><a href="#cb45-3" aria-hidden="true" tabindex="-1"></a><span class="fu">str</span>(x)</span></code><button title="Kopiuj do schowka" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code> num [1:64, 1:3, 1:32, 1:10] 3 7 2 3 5 6 4 8 3 8 ...</code></pre>
</div>
<details open="">
<summary>Kod</summary>
<div class="sourceCode cell-code" id="cb47"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb47-1"><a href="#cb47-1" aria-hidden="true" tabindex="-1"></a><span class="co"># y is a tensor of 5s of shape (32, 10)</span></span>
<span id="cb47-2"><a href="#cb47-2" aria-hidden="true" tabindex="-1"></a>y <span class="ot">&lt;-</span> <span class="fu">array</span>(<span class="dv">5</span>, <span class="at">dim =</span> <span class="fu">c</span>(<span class="dv">32</span>, <span class="dv">10</span>))</span>
<span id="cb47-3"><a href="#cb47-3" aria-hidden="true" tabindex="-1"></a><span class="fu">str</span>(y)</span></code><button title="Kopiuj do schowka" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code> num [1:32, 1:10] 5 5 5 5 5 5 5 5 5 5 ...</code></pre>
</div>
<details open="">
<summary>Kod</summary>
<div class="sourceCode cell-code" id="cb49"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb49-1"><a href="#cb49-1" aria-hidden="true" tabindex="-1"></a><span class="co"># The output z has shape (64, 3, 32, 10) like x</span></span>
<span id="cb49-2"><a href="#cb49-2" aria-hidden="true" tabindex="-1"></a>z <span class="ot">&lt;-</span> <span class="fu">sweep</span>(x, <span class="fu">c</span>(<span class="dv">3</span>, <span class="dv">4</span>), y, pmax)</span>
<span id="cb49-3"><a href="#cb49-3" aria-hidden="true" tabindex="-1"></a><span class="fu">str</span>(z)</span></code><button title="Kopiuj do schowka" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code> num [1:64, 1:3, 1:32, 1:10] 5 7 5 5 5 6 5 8 5 8 ...</code></pre>
</div>
</div>
<p>Operacja <code>dot</code>, zwana rÃ³wnieÅ¼ iloczynem tensorowym jest najczÄ™Å›ciej spotykanÄ…, najbardziej uÅ¼ytecznÄ… operacjÄ… na tensorach. W przeciwieÅ„stwie do operacji <em>element-wise</em>, Å‚Ä…czy ona wpisy w tensorach wejÅ›ciowych. Iloczyny tensorowe wykorzystujÄ… operator <code>%*%</code>. ZauwaÅ¼, Å¼e gdy tylko jeden z dwÃ³ch tensorÃ³w ma wiÄ™cej niÅ¼ jeden wymiar, <code>%*%</code> nie jest symetryczny, czyli Å¼e <code>x %*% y</code> nie jest taki sam jak <code>y %*% x</code>.</p>
<div id="fig-tensor3" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="images/Zrzut ekranu 2023-02-24 o 19.35.48.png" class="img-fluid figure-img" width="400"></p>
<p></p><figcaption class="figure-caption">Rysunek&nbsp;10.10: Iloczyn tensorÃ³w</figcaption><p></p>
</figure>
</div>
<p>Trzecim bardzo waÅ¼nym rodzajem operacji na tensorach jest przeksztaÅ‚canie tensorÃ³w. ChociaÅ¼ nie byÅ‚o ono uÅ¼ywane w gÄ™stych warstwach w naszym pierwszym przykÅ‚adzie sieci neuronowej, uÅ¼ywaliÅ›my go, gdy wstÄ™pnie przetwarzaliÅ›my dane o cyfrach przed wprowadzeniem ich do naszej sieci:</p>
<div class="cell">
<details open="">
<summary>Kod</summary>
<div class="sourceCode cell-code" id="cb51"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb51-1"><a href="#cb51-1" aria-hidden="true" tabindex="-1"></a>train_images <span class="ot">&lt;-</span> mnist<span class="sc">$</span>train<span class="sc">$</span>x</span>
<span id="cb51-2"><a href="#cb51-2" aria-hidden="true" tabindex="-1"></a><span class="fu">str</span>(train_images)</span></code><button title="Kopiuj do schowka" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code> int [1:60000, 1:28, 1:28] 0 0 0 0 0 0 0 0 0 0 ...</code></pre>
</div>
<details open="">
<summary>Kod</summary>
<div class="sourceCode cell-code" id="cb53"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb53-1"><a href="#cb53-1" aria-hidden="true" tabindex="-1"></a>train_images <span class="ot">&lt;-</span> <span class="fu">array_reshape</span>(train_images, <span class="fu">c</span>(<span class="dv">60000</span>, <span class="dv">28</span> <span class="sc">*</span> <span class="dv">28</span>))</span>
<span id="cb53-2"><a href="#cb53-2" aria-hidden="true" tabindex="-1"></a><span class="fu">str</span>(train_images)</span></code><button title="Kopiuj do schowka" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code> int [1:60000, 1:784] 0 0 0 0 0 0 0 0 0 0 ...</code></pre>
</div>
</div>
<p>PrzeksztaÅ‚cenie tensora oznacza zmianÄ™ rozmieszczenia jego wierszy i kolumn tak, by pasowaÅ‚y do docelowego ksztaÅ‚tu. OczywiÅ›cie, przeksztaÅ‚cony tensor ma takÄ… samÄ… caÅ‚kowitÄ… liczbÄ™ wspÃ³Å‚czynnikÃ³w jak tensor poczÄ…tkowy.</p>
<div class="cell">
<details open="">
<summary>Kod</summary>
<div class="sourceCode cell-code" id="cb55"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb55-1"><a href="#cb55-1" aria-hidden="true" tabindex="-1"></a>x <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">1</span>,</span>
<span id="cb55-2"><a href="#cb55-2" aria-hidden="true" tabindex="-1"></a>                <span class="dv">2</span>, <span class="dv">3</span>,</span>
<span id="cb55-3"><a href="#cb55-3" aria-hidden="true" tabindex="-1"></a>                <span class="dv">4</span>, <span class="dv">5</span>),</span>
<span id="cb55-4"><a href="#cb55-4" aria-hidden="true" tabindex="-1"></a>             <span class="at">nrow =</span> <span class="dv">3</span>, <span class="at">ncol =</span> <span class="dv">2</span>, <span class="at">byrow =</span> <span class="cn">TRUE</span>)</span>
<span id="cb55-5"><a href="#cb55-5" aria-hidden="true" tabindex="-1"></a>x</span></code><button title="Kopiuj do schowka" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>     [,1] [,2]
[1,]    0    1
[2,]    2    3
[3,]    4    5</code></pre>
</div>
<details open="">
<summary>Kod</summary>
<div class="sourceCode cell-code" id="cb57"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb57-1"><a href="#cb57-1" aria-hidden="true" tabindex="-1"></a>x <span class="ot">&lt;-</span> <span class="fu">array_reshape</span>(x, <span class="at">dim =</span> <span class="fu">c</span>(<span class="dv">6</span>, <span class="dv">1</span>)) </span>
<span id="cb57-2"><a href="#cb57-2" aria-hidden="true" tabindex="-1"></a>x</span></code><button title="Kopiuj do schowka" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>     [,1]
[1,]    0
[2,]    1
[3,]    2
[4,]    3
[5,]    4
[6,]    5</code></pre>
</div>
<details open="">
<summary>Kod</summary>
<div class="sourceCode cell-code" id="cb59"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb59-1"><a href="#cb59-1" aria-hidden="true" tabindex="-1"></a>x <span class="ot">&lt;-</span> <span class="fu">array_reshape</span>(x, <span class="at">dim =</span> <span class="fu">c</span>(<span class="dv">2</span>, <span class="dv">3</span>))</span>
<span id="cb59-2"><a href="#cb59-2" aria-hidden="true" tabindex="-1"></a>x</span></code><button title="Kopiuj do schowka" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>     [,1] [,2] [,3]
[1,]    0    1    2
[2,]    3    4    5</code></pre>
</div>
</div>
<p>SzczegÃ³lnym przypadkiem przeksztaÅ‚cenia, ktÃ³ry jest powszechnie spotykany, jest transpozycja.</p>
</section>
</section>
<section id="optymalizacja-gradientowa" class="level3" data-number="10.4.2">
<h3 data-number="10.4.2" class="anchored" data-anchor-id="optymalizacja-gradientowa"><span class="header-section-number">10.4.2</span> Optymalizacja gradientowa</h3>
<p>Jak widziaÅ‚eÅ› wyÅ¼ej, kaÅ¼da warstwa neuronowa z naszego pierwszego przykÅ‚adu sieci przeksztaÅ‚ca swoje dane wejÅ›ciowe w nastÄ™pujÄ…cy sposÃ³b:</p>
<div class="cell">
<details open="">
<summary>Kod</summary>
<div class="sourceCode cell-code" id="cb61"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb61-1"><a href="#cb61-1" aria-hidden="true" tabindex="-1"></a>output <span class="ot">=</span> <span class="fu">relu</span>(<span class="fu">dot</span>(input, W)<span class="sc">+</span>b)</span></code><button title="Kopiuj do schowka" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>W tym wyraÅ¼eniu <code>W</code> i <code>b</code> sÄ… tensorami bÄ™dÄ…cymi atrybutami warstwy. Nazywamy je wagami lub parametrami trenowanymi warstwy (odpowiednio atrybuty kernel i bias). Wagi te zawierajÄ… informacje wyuczone przez sieÄ‡ w wyniku ekspozycji na dane treningowe.</p>
<p>PoczÄ…tkowo te macierze wag sÄ… wypeÅ‚nione maÅ‚ymi losowymi wartoÅ›ciami (krok zwany inicjalizacjÄ… losowÄ…). OczywiÅ›cie nie ma powodu, by oczekiwaÄ‡, Å¼e <code>relu(dot(W, input) + b)</code>, gdy <code>W</code> i <code>b</code> sÄ… losowe, da jakÄ…kolwiek uÅ¼ytecznÄ… reprezentacjÄ™. NastÄ™pnym krokiem jest stopniowe dostosowanie tych wag, w oparciu o sygnaÅ‚ zwrotny. To stopniowe dopasowywanie, zwane rÃ³wnieÅ¼ treningiem, jest w zasadzie naukÄ…, o ktÃ³rÄ… chodzi w uczeniu modeli.</p>
<p>Dzieje siÄ™ to w ramach tak zwanej pÄ™tli treningowej, ktÃ³ra schematycznie wyglÄ…da nastÄ™pujÄ…co. Powtarzaj te kroki w pÄ™tli, tak dÅ‚ugo jak to konieczne:</p>
<ol type="1">
<li>Wylosuj partiÄ™ prÃ³bek treningowych <code>x</code> i odpowiadajÄ…ce im cele <code>y</code>.</li>
<li>Uruchom sieÄ‡ na <code>x</code> (nazywane przejÅ›ciem w przÃ³d), aby uzyskaÄ‡ predykcje <code>y_pred</code>.</li>
<li>Oblicz stratÄ™ sieci na partii, czyli miarÄ™ niedopasowania miÄ™dzy <code>y_pred</code> a <code>y</code>.</li>
<li>Zaktualizuj wszystkie wagi sieci w taki sposÃ³b, aby nieznacznie zmniejszyÄ‡ stratÄ™ na tej partii.</li>
</ol>
<p>W koÅ„cu otrzymamy sieÄ‡, ktÃ³ra ma bardzo niskÄ… stratÄ™ na swoich danych treningowych: to znaczy, niskie rozbieÅ¼noÅ›ci miÄ™dzy przewidywaniami <code>y_pred</code> i oczekiwanymi celami <code>y</code>. Ze wszystkich powyÅ¼szych krokÃ³w pierwsze trzy wydajÄ… siÄ™ oczywiste, natomiast 4 jest nieco trudniejszy - aktualizacja wag sieci. BiorÄ…c pod uwagÄ™ indywidualny wspÃ³Å‚czynnik wagowy w sieci, jak moÅ¼na obliczyÄ‡, czy wspÃ³Å‚czynnik ten powinien byÄ‡ zwiÄ™kszony czy zmniejszony i o ile?</p>
<p>PoniewaÅ¼ wszystkie operacje uÅ¼ywane w sieci sÄ… rÃ³Å¼niczkowalne, to moÅ¼na obliczyÄ‡ gradient funkcji straty wzglÄ™dem wspÃ³Å‚czynnikÃ³w sieci. NastÄ™pnie moÅ¼esz skorygowaÄ‡ wspÃ³Å‚czynniki wagowe w kierunku przeciwnym do gradientu, zmniejszajÄ…c w ten sposÃ³b stratÄ™.</p>
<p>BiorÄ…c pod uwagÄ™ funkcjÄ™ rÃ³Å¼niczkowalnÄ…, teoretycznie moÅ¼liwe jest znalezienie jej minimum analitycznie: wiadomo, Å¼e minimum funkcji to punkt, w ktÃ³rym pochodna jest rÃ³wna 0, wiÄ™c wszystko, co musimy zrobiÄ‡, to znaleÅºÄ‡ wszystkie punkty, w ktÃ³rych pochodna zmierza do 0 i sprawdziÄ‡, dla ktÃ³rego z tych punktÃ³w funkcja ma najmniejszÄ… wartoÅ›Ä‡.</p>
<p>W przypadku sieci neuronowej oznacza to analityczne znalezienie kombinacji wartoÅ›ci wag, ktÃ³ra daje najmniejszÄ… moÅ¼liwÄ… funkcjÄ™ straty. MoÅ¼na to zrobiÄ‡ rozwiÄ…zujÄ…c rÃ³wnanie <code>gradient(f)(W) = 0</code> dla <code>W</code>. Jest to rÃ³wnanie wielomianowe o <span class="math inline">\(N\)</span> zmiennych, gdzie <span class="math inline">\(N\)</span> jest liczbÄ… wspÃ³Å‚czynnikÃ³w w sieci. ChociaÅ¼ moÅ¼liwe byÅ‚oby rozwiÄ…zanie takiego rÃ³wnania dla dla <span class="math inline">\(N = 2\)</span> lub <span class="math inline">\(N = 3\)</span>, to zrobienie tego jest niepraktyczne dla rzeczywistych sieci neuronowych, gdzie liczba parametrÃ³w nigdy nie jest mniejsza niÅ¼ kilka tysiÄ™cy, a czÄ™sto moÅ¼e wynosiÄ‡ kilkadziesiÄ…t milionÃ³w.</p>
<p>Zamiast tego moÅ¼esz uÅ¼yÄ‡ czteroetapowego algorytmu przedstawionego na poczÄ…tku tej sekcji: modyfikujesz parametry po trochu w oparciu o bieÅ¼Ä…cÄ… wartoÅ›Ä‡ straty na losowej partii danych. PoniewaÅ¼ mamy do czynienia z funkcjÄ… rÃ³Å¼niczkowalnÄ…, moÅ¼emy obliczyÄ‡ jej gradient, co daje efektywny sposÃ³b implementacji kroku 4. JeÅ›li zaktualizujesz wagi w kierunku przeciwnym do gradientu, strata bÄ™dzie za kaÅ¼dym razem nieco mniejsza:</p>
<ol type="1">
<li>Wylosuj partiÄ™ prÃ³bek treningowych <code>x</code> i odpowiadajÄ…ce im cele <code>y</code>.</li>
<li>Uruchom sieÄ‡ na <code>x</code>, aby uzyskaÄ‡ predykcje <code>y_pred</code>.</li>
<li>Oblicz stratÄ™ sieci na partii, czyli miarÄ™ niedopasowania miÄ™dzy <code>y_pred</code> a <code>y.</code></li>
<li>Oblicz gradient straty wzglÄ™dem parametrÃ³w sieci (przejÅ›cie wsteczne).</li>
<li>Skoryguj (nieznacznie) parametry sieci w kierunku przeciwnym do gradientu - na przykÅ‚ad <code>W = W - (krok * gradient)</code> - tym samym zmniejszajÄ…c nieco stratÄ™ na partii.</li>
</ol>
<p>To, co wÅ‚aÅ›nie opisaliÅ›my, nazywa siÄ™ metodÄ… <em>minibatch stochastic gradient descent</em> (minibatch SGD). Termin stochastyczny odnosi siÄ™ do faktu, Å¼e kaÅ¼da partia danych jest losowana.</p>
<p>Jak widaÄ‡, intuicyjnie waÅ¼ne jest, aby wybraÄ‡ rozsÄ…dnÄ… wartoÅ›Ä‡ wspÃ³Å‚czynnika kroku. JeÅ›li jest on zbyt maÅ‚y, zejÅ›cie w dÃ³Å‚ krzywej zajmie wiele iteracji i moÅ¼e utknÄ…Ä‡ w lokalnym minimum. JeÅ›li krok jest zbyt duÅ¼y, twoje aktualizacje mogÄ… skoÅ„czyÄ‡ siÄ™ zabraniem ciÄ™ do caÅ‚kowicie losowych miejsc na krzywej.</p>
<p>ZauwaÅ¼, Å¼e wariant algorytmu mini-batch SGD polegajÄ…cy na losowaniu pojedynczej prÃ³bki i <code>y</code> w kaÅ¼dej iteracji, zamiast losowania partii danych. WÃ³wczas byÅ‚by to oryginalny algorytm SGD, ktÃ³ry jest mniej wydajny.</p>
<p>OprÃ³cz wspomnianej metody mini-batch SGD istnieje wiele innych, duÅ¼o bardziej skutecznych metod optymalizacji parametrÃ³w wagowych modelu. WÅ›rÃ³d nich naleÅ¼y wymieniÄ‡:</p>
<ul>
<li>RMSprop</li>
<li>Adagrad</li>
<li>Adamax</li>
<li>mini-batch SGD with Momentum</li>
<li>mini-batch SGD with Nesterov Momentum</li>
<li>Adam (chyba najpopularniejsza)</li>
<li>Nadam</li>
</ul>
<p>IstniejÄ… rÃ³wnieÅ¼ odmiany wspominanych wyÅ¼ej metod z planami. Owe plany sÄ… przepisami na to jak wspÃ³Å‚czynnik szybkoÅ›ci uczenia ma siÄ™ zmieniaÄ‡ w kolejnych iteracjach.</p>
<div id="fig-sgd1" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="https://cs231n.github.io/assets/nn3/opt2.gif" class="img-fluid figure-img" width="600"></p>
<p></p><figcaption class="figure-caption">Rysunek&nbsp;10.11: Optymalizacja wag z wykorzystaniem rÃ³Å¼nych technik</figcaption><p></p>
</figure>
</div>
</section>
<section id="wsteczna-propagacja-bÅ‚Ä™du" class="level3" data-number="10.4.3">
<h3 data-number="10.4.3" class="anchored" data-anchor-id="wsteczna-propagacja-bÅ‚Ä™du"><span class="header-section-number">10.4.3</span> Wsteczna propagacja bÅ‚Ä™du</h3>
<p>Wsteczna propagacja bÅ‚Ä™du (ang. <em>backpropagation</em>) jest metodÄ… instruujÄ…cÄ… algorytm jak korygowaÄ‡ wagi sieci. Korzysta ona z prawa znanego w matematyce jako pochodna funkcji zÅ‚oÅ¼onej (ang. <em>chain rule</em>)</p>
<p><span id="eq-chain-rule"><span class="math display">\[
[f(g(x))]'=f'(g(x))\cdot g'(x).
\tag{10.1}\]</span></span></p>
<p><em>Backpropagation</em> rozpoczyna siÄ™ od koÅ„cowej wartoÅ›ci straty i dziaÅ‚a wstecz od gÃ³rnych warstw do dolnych, stosujÄ…c reguÅ‚Ä™ Å‚aÅ„cuchowÄ… do obliczenia wkÅ‚adu, jaki kaÅ¼dy parametr miaÅ‚ w wartoÅ›ci straty.</p>
<div id="fig-backprop1" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="https://developer-blogs.nvidia.com/wp-content/uploads/2022/02/DS-Guide-to-Gradient-Descent_Pic5.gif" class="img-fluid figure-img" width="400"></p>
<p></p><figcaption class="figure-caption">Rysunek&nbsp;10.12: Zasada dziaÅ‚ania wstecznej propagacji bÅ‚Ä™du</figcaption><p></p>
</figure>
</div>
<p>Obecnie korzysta siÄ™ z metod zdolnych do symbolicznego rÃ³Å¼niczkowania, takich jak TensorFlow. Oznacza to, Å¼e biorÄ…c pod uwagÄ™ Å‚aÅ„cuch operacji ze znanÄ… pochodnÄ…, mogÄ… obliczyÄ‡ funkcjÄ™ gradientu dla Å‚aÅ„cucha (stosujÄ…c reguÅ‚Ä™ Å‚aÅ„cucha), ktÃ³ra mapuje wartoÅ›ci parametrÃ³w sieci do wartoÅ›ci gradientu. Kiedy masz dostÄ™p do takiej funkcji, przejÅ›cie wsteczne jest zredukowane do wywoÅ‚ania tej funkcji gradientu. DziÄ™ki symbolicznemu rÃ³Å¼niczkowaniu nigdy nie bÄ™dziesz musiaÅ‚ rÄ™cznie implementowaÄ‡ algorytmu wstecznej propagacji.</p>
</section>
<section id="funkcje-straty" class="level3 page-columns page-full" data-number="10.4.4">
<h3 data-number="10.4.4" class="anchored" data-anchor-id="funkcje-straty"><span class="header-section-number">10.4.4</span> Funkcje straty</h3>
<div class="page-columns page-full"><p>We wczeÅ›niej prezentowanym przykÅ‚adzie w funkcji <code>compile()</code> pojawiÅ‚a siÄ™ funkcja straty <code>loss = 'categorical_crossentropy'</code>, ktÃ³ra jest jednÄ… z moÅ¼liwych do zastosowania funkcji straty<a href="#fn5" class="footnote-ref" id="fnref5" role="doc-noteref"><sup>5</sup></a>. Funkcja straty jest uÅ¼ywana jako sygnaÅ‚ zwrotny do uczenia tensorÃ³w wag i ktÃ³rÄ… w fazie uczenia bÄ™dzie monimalizowana. OdbywaÄ‡ siÄ™ to bÄ™dzie za pomocÄ… mini-batch SGD. DokÅ‚adne zasady rzÄ…dzÄ…ce konkretnÄ… implementacjÄ… SGD sÄ… zdefiniowane przez optymalizator <code>rmsprop</code> przekazany jako pierwszy argument.</p><div class="no-row-height column-margin column-container"><li id="fn5"><p><sup>5</sup>&nbsp;o funkcjach straty bÄ™dziemy jeszcze wspominaÄ‡ przy konkretnych przykÅ‚adach</p></li></div></div>
<p>UruchamiajÄ…c</p>
<div class="cell">
<details open="">
<summary>Kod</summary>
<div class="sourceCode cell-code" id="cb62"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb62-1"><a href="#cb62-1" aria-hidden="true" tabindex="-1"></a>network <span class="sc">|&gt;</span> </span>
<span id="cb62-2"><a href="#cb62-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">fit</span>(train_samples, train_labels, <span class="at">epochs =</span> <span class="dv">5</span>, <span class="at">batch_size =</span> <span class="dv">128</span>)</span></code><button title="Kopiuj do schowka" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>rozpoczynamy iteracyjne uczenie przygotowanej sieci. BÄ™dzie ona realizowana w 5 epokach na partiach danych skÅ‚adajÄ…cych siÄ™ ze 128 obserwacji.</p>

<div class="no-row-height column-margin column-container"><div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/tw4.jpeg" class="img-fluid figure-img" width="400"></p>
</figure>
</div></div><div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Adnotacja
</div>
</div>
<div class="callout-body-container callout-body">
<p>Bardzo pomocne w zrozumieniu zasady dziaÅ‚ania sieci neuronowych na przykÅ‚adzie (bardzo podobnym do naszego) moÅ¼e byÄ‡ obejrzenie cyklu 4 filmÃ³w sieciach neuronowych kanaÅ‚u <a href="https://youtu.be/aircAruvnKk">3Blue1Brown</a></p>
</div>
</div>
<div class="cell">
<details open="">
<summary>Kod</summary>
<div class="sourceCode cell-code" id="cb63"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb63-1"><a href="#cb63-1" aria-hidden="true" tabindex="-1"></a><span class="co"># lista funkcji straty pakietu keras</span></span>
<span id="cb63-2"><a href="#cb63-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb63-3"><a href="#cb63-3" aria-hidden="true" tabindex="-1"></a><span class="fu">ls</span>(<span class="st">"package:keras"</span>) <span class="sc">|&gt;</span> </span>
<span id="cb63-4"><a href="#cb63-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">grep</span>(<span class="at">x =</span> _, <span class="at">pattern =</span> <span class="st">"^loss_"</span>, <span class="at">value =</span> T)</span></code><button title="Kopiuj do schowka" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code> [1] "loss_binary_crossentropy"            
 [2] "loss_categorical_crossentropy"       
 [3] "loss_categorical_hinge"              
 [4] "loss_cosine_proximity"               
 [5] "loss_cosine_similarity"              
 [6] "loss_hinge"                          
 [7] "loss_huber"                          
 [8] "loss_kl_divergence"                  
 [9] "loss_kullback_leibler_divergence"    
[10] "loss_logcosh"                        
[11] "loss_mean_absolute_error"            
[12] "loss_mean_absolute_percentage_error" 
[13] "loss_mean_squared_error"             
[14] "loss_mean_squared_logarithmic_error" 
[15] "loss_poisson"                        
[16] "loss_sparse_categorical_crossentropy"
[17] "loss_squared_hinge"                  </code></pre>
</div>
</div>


<div id="refs" class="references csl-bib-body hanging-indent" role="list" style="display: none">
<div id="ref-ciresanFlexibleHighPerformance" class="csl-entry" role="listitem">
Ciresan, Dan C, Ueli Meier, Jonathan Masci, Luca M Gambardella, i Jurgen Schmidhuber. b.d. <span>â€Flexible, <span>High Performance Convolutional Neural Networks</span> for <span>Image Classification</span>â€</span>.
</div>
<div id="ref-krizhevsky2017" class="csl-entry" role="listitem">
Krizhevsky, Alex, Ilya Sutskever, i Geoffrey E. Hinton. 2017. <span>â€ImageNet Classification with Deep Convolutional Neural Networksâ€</span>. <em>Communications of the ACM</em> 60 (6): 84â€“90. <a href="https://doi.org/10.1145/3065386">https://doi.org/10.1145/3065386</a>.
</div>
</div>
</section>
</section>


</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const disableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'prefetch';
    }
  }
  const enableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'stylesheet';
    }
  }
  const manageTransitions = (selector, allowTransitions) => {
    const els = window.document.querySelectorAll(selector);
    for (let i=0; i < els.length; i++) {
      const el = els[i];
      if (allowTransitions) {
        el.classList.remove('notransition');
      } else {
        el.classList.add('notransition');
      }
    }
  }
  const toggleColorMode = (alternate) => {
    // Switch the stylesheets
    const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
    manageTransitions('#quarto-margin-sidebar .nav-link', false);
    if (alternate) {
      enableStylesheet(alternateStylesheets);
      for (const sheetNode of alternateStylesheets) {
        if (sheetNode.id === "quarto-bootstrap") {
          toggleBodyColorMode(sheetNode);
        }
      }
    } else {
      disableStylesheet(alternateStylesheets);
      toggleBodyColorPrimary();
    }
    manageTransitions('#quarto-margin-sidebar .nav-link', true);
    // Switch the toggles
    const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
    for (let i=0; i < toggles.length; i++) {
      const toggle = toggles[i];
      if (toggle) {
        if (alternate) {
          toggle.classList.add("alternate");     
        } else {
          toggle.classList.remove("alternate");
        }
      }
    }
    // Hack to workaround the fact that safari doesn't
    // properly recolor the scrollbar when toggling (#1455)
    if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
      manageTransitions("body", false);
      window.scrollTo(0, 1);
      setTimeout(() => {
        window.scrollTo(0, 0);
        manageTransitions("body", true);
      }, 40);  
    }
  }
  const isFileUrl = () => { 
    return window.location.protocol === 'file:';
  }
  const hasAlternateSentinel = () => {  
    let styleSentinel = getColorSchemeSentinel();
    if (styleSentinel !== null) {
      return styleSentinel === "alternate";
    } else {
      return false;
    }
  }
  const setStyleSentinel = (alternate) => {
    const value = alternate ? "alternate" : "default";
    if (!isFileUrl()) {
      window.localStorage.setItem("quarto-color-scheme", value);
    } else {
      localAlternateSentinel = value;
    }
  }
  const getColorSchemeSentinel = () => {
    if (!isFileUrl()) {
      const storageValue = window.localStorage.getItem("quarto-color-scheme");
      return storageValue != null ? storageValue : localAlternateSentinel;
    } else {
      return localAlternateSentinel;
    }
  }
  let localAlternateSentinel = 'default';
  // Dark / light mode switch
  window.quartoToggleColorScheme = () => {
    // Read the current dark / light value 
    let toAlternate = !hasAlternateSentinel();
    toggleColorMode(toAlternate);
    setStyleSentinel(toAlternate);
  };
  // Ensure there is a toggle, if there isn't float one in the top right
  if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
    const a = window.document.createElement('a');
    a.classList.add('top-right');
    a.classList.add('quarto-color-scheme-toggle');
    a.href = "";
    a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
    const i = window.document.createElement("i");
    i.classList.add('bi');
    a.appendChild(i);
    window.document.body.appendChild(a);
  }
  // Switch to dark mode if need be
  if (hasAlternateSentinel()) {
    toggleColorMode(true);
  } else {
    toggleColorMode(false);
  }
  const icon = "î§‹";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Skopiowano!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Skopiowano!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./fourier.html" class="pagination-link">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Transformata Fouriera</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./fundamentals.html" class="pagination-link">
        <span class="nav-page-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Fundamenty DNN</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">Automatyczna analiza obrazu, Dariusz Majerek</div>   
    <div class="nav-footer-center">
      &nbsp;
    </div>
    <div class="nav-footer-right">KsiÄ…Å¼ka zostaÅ‚a napisana w <a href="https://quarto.org/">Quarto</a></div>
  </div>
</footer>



</body></html>