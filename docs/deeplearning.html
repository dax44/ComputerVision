<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="pl" xml:lang="pl"><head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="generator" content="quarto-1.4.549">
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">
<title>Automatyczna analiza obrazu - 10&nbsp; Deep learning</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>

<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./fundamentals.html" rel="next">
<link href="./fourier.html" rel="prev">
<link href="./cover.png" rel="icon" type="image/png">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-dark.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="site_libs/bootstrap/bootstrap-dark.min.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark"><script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "Brak wynikÃ³w",
    "search-matching-documents-text": "dopasowane dokumenty",
    "search-copy-link-title": "Kopiuj link do wyszukiwania",
    "search-hide-matches-text": "Ukryj dodatkowe dopasowania",
    "search-more-match-text": "wiÄ™cej dopasowaÅ„ w tym dokumencie",
    "search-more-matches-text": "wiÄ™cej dopasowaÅ„ w tym dokumencie",
    "search-clear-button-title": "WyczyÅ›Ä‡",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Anuluj",
    "search-submit-button-title": "ZatwierdÅº",
    "search-label": "Szukaj"
  }
}</script><script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script><script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script><script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>
</head>
<body class="nav-sidebar floating slimcontent">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top"><nav class="quarto-secondary-nav"><div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="PrzeÅ‚Ä…cz pasek boczny" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./deeplearning.html"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Deep learning</span></a></li></ol></nav>
        <a class="flex-grow-1" role="button" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="PrzeÅ‚Ä…cz pasek boczny" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav></header><!-- content --><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto"><div class="pt-lg-2 mt-2 text-left sidebar-header sidebar-header-stacked">
      <a href="./index.html" class="sidebar-logo-link">
      <img src="./images/logo.jpg" alt="" class="sidebar-logo py-0 d-lg-inline d-none"></a>
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Automatyczna analiza obrazu</a> 
        <div class="sidebar-tools-main tools-wide">
    <a href="https://twitter.com" title="" class="quarto-navigation-tool px-1" aria-label=""><i class="bi bi-twitter"></i></a>
    <a href="https://github.com/dax44/ComputerVision/" title="Source Code" class="quarto-navigation-tool px-1" aria-label="Source Code"><i class="bi bi-github"></i></a>
    <a href="https://twitter.com/intent/tweet?url=%7Curl%7C" title="Twitter" class="quarto-navigation-tool px-1" aria-label="Twitter"><i class="bi bi-twitter"></i></a>
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="PrzeÅ‚Ä…cz tryb ciemny"><i class="bi"></i></a>
  <a href="" class="quarto-reader-toggle quarto-navigation-tool px-1" onclick="window.quartoToggleReader(); return false;" title="PrzeÅ‚Ä…cz tryb czytnika">
  <div class="quarto-reader-toggle-btn">
  <i class="bi"></i>
  </div>
</a>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Szukaj"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">WstÄ™p</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Wprowadzenie</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./history.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Historia wizji komputerowej</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./digt_img.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Obrazy cyfrowe</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./transformations.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Transformacje geometryczne</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./point_trans.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Transformacje punktowe</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./filters.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Filtry</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./edge.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Wykrywanie krawÄ™dzi i konturÃ³w</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./morpho.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Filtry morfologiczne</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./fourier.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Transformata Fouriera</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./deeplearning.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Deep learning</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./fundamentals.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Fundamenty DNN</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./convolution.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Sieci splotowe</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./example.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">PrzykÅ‚ad uczenia sieci splotowej</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./segmentation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Segmentacja obrazÃ³w</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Bibliografia</span></a>
  </div>
</li>
    </ul>
</div>
</nav><div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active"><h2 id="toc-title">Spis treÅ›ci</h2>
   
  <ul>
<li><a href="#uczenie-si%C4%99-reprezentacji-na-podstawie-danych" id="toc-uczenie-siÄ™-reprezentacji-na-podstawie-danych" class="nav-link active" data-scroll-target="#uczenie-si%C4%99-reprezentacji-na-podstawie-danych"><span class="header-section-number">10.1</span> Uczenie siÄ™ reprezentacji na podstawie danych</a></li>
  <li><a href="#jak-dzia%C5%82a-deep-learning" id="toc-jak-dziaÅ‚a-deep-learning" class="nav-link" data-scroll-target="#jak-dzia%C5%82a-deep-learning"><span class="header-section-number">10.2</span> Jak dziaÅ‚a deep learning?</a></li>
  <li>
<a href="#kr%C3%B3tki-rys-historyczny-dl" id="toc-krÃ³tki-rys-historyczny-dl" class="nav-link" data-scroll-target="#kr%C3%B3tki-rys-historyczny-dl"><span class="header-section-number">10.3</span> KrÃ³tki rys historyczny DL</a>
  <ul class="collapse">
<li><a href="#hardware" id="toc-hardware" class="nav-link" data-scroll-target="#hardware"><span class="header-section-number">10.3.1</span> Hardware</a></li>
  <li><a href="#dane" id="toc-dane" class="nav-link" data-scroll-target="#dane"><span class="header-section-number">10.3.2</span> Dane</a></li>
  <li><a href="#algorytmy" id="toc-algorytmy" class="nav-link" data-scroll-target="#algorytmy"><span class="header-section-number">10.3.3</span> Algorytmy</a></li>
  </ul>
</li>
  <li>
<a href="#elementy-deep-learning" id="toc-elementy-deep-learning" class="nav-link" data-scroll-target="#elementy-deep-learning"><span class="header-section-number">10.4</span> Elementy Deep Learning</a>
  <ul class="collapse">
<li><a href="#operacje-na-danych" id="toc-operacje-na-danych" class="nav-link" data-scroll-target="#operacje-na-danych"><span class="header-section-number">10.4.1</span> Operacje na danych</a></li>
  <li><a href="#optymalizacja-gradientowa" id="toc-optymalizacja-gradientowa" class="nav-link" data-scroll-target="#optymalizacja-gradientowa"><span class="header-section-number">10.4.2</span> Optymalizacja gradientowa</a></li>
  <li><a href="#wsteczna-propagacja-b%C5%82%C4%99du" id="toc-wsteczna-propagacja-bÅ‚Ä™du" class="nav-link" data-scroll-target="#wsteczna-propagacja-b%C5%82%C4%99du"><span class="header-section-number">10.4.3</span> Wsteczna propagacja bÅ‚Ä™du</a></li>
  <li><a href="#funkcje-straty" id="toc-funkcje-straty" class="nav-link" data-scroll-target="#funkcje-straty"><span class="header-section-number">10.4.4</span> Funkcje straty</a></li>
  </ul>
</li>
  </ul><div class="toc-actions"><ul><li><a href="https://github.com/dax44/ComputerVision/issues/new" class="toc-action"><i class="bi bi-github"></i>ZgÅ‚oÅ› problem</a></li></ul></div></nav>
    </div>
<!-- main -->
<main class="content page-columns page-full" id="quarto-document-content"><header id="title-block-header" class="quarto-title-block default"><div class="quarto-title">
<h1 class="title">
<span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Deep learning</span>
</h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header><p>Jak to zostaÅ‚o wspomniane na poczÄ…tku tej ksiÄ…Å¼ki do automatycznej analizy obrazu wykorzystamy techniki z zakresu uczenia maszynowego, ktÃ³re mieszczÄ… siÄ™ pod pojÄ™ciem gÅ‚Ä™bokiego uczenia (ang. <em>deep learning</em>). Uczenie maszynowe wynika bezpoÅ›rednio z pytania: czy komputer mÃ³gÅ‚by wyjÅ›Ä‡ poza to, co wiemy i samodzielnie nauczyÄ‡ siÄ™, jak wykonaÄ‡ okreÅ›lone zadanie? Czy komputer mÃ³gÅ‚by nas zaskoczyÄ‡? Czy zamiast programistÃ³w rÄ™cznie tworzÄ…cych reguÅ‚y przetwarzania danych, komputer mÃ³gÅ‚by automatycznie nauczyÄ‡ siÄ™ tych reguÅ‚ patrzÄ…c na dane?</p>
<div id="fig-ml1" class="quarto-figure quarto-figure-center quarto-float anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure"><div aria-describedby="fig-ml1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="images/Zrzut ekranu 2023-02-23 o 19.01.53.png" class="img-fluid quarto-figure quarto-figure-center figure-img" width="400">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-ml1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Rysunek&nbsp;10.1: Dwa schematy myÅ›lenia o programowaniu komputerÃ³w
</figcaption></figure>
</div>
<p>To pytanie otwiera drzwi do nowego paradygmatu programowania. W klasycznym programowaniu, paradygmacie symbolicznej AI, ludzie wprowadzajÄ… reguÅ‚y (program) i dane, ktÃ³re majÄ… byÄ‡ przetwarzane zgodnie z tymi reguÅ‚ami, a nastÄ™pnie otrzymujÄ… odpowiedzi (patrz <a href="#fig-ml1" class="quarto-xref">Rysunek&nbsp;<span>10.1</span></a>). W przypadku uczenia maszynowego, czÅ‚owiek wprowadza dane oraz odpowiedzi oczekiwane na podstawie tych danych, a nastÄ™pnie otrzymuje reguÅ‚y. ReguÅ‚y te mogÄ… byÄ‡ nastÄ™pnie zastosowane do nowych danych, aby uzyskaÄ‡ oryginalne odpowiedzi.</p>
<p>System uczenia maszynowego jest raczej uczony niÅ¼ programowany. Przedstawia siÄ™ mu wiele przykÅ‚adÃ³w zwiÄ…zanych z zadaniem, a on znajduje w nich strukturÄ™ statystycznÄ…, ktÃ³ra w koÅ„cu pozwala mu wymyÅ›liÄ‡ reguÅ‚y automatyzacji zadania. Na przykÅ‚ad, jeÅ›li chciaÅ‚byÅ› zautomatyzowaÄ‡ zadanie oznaczania zdjÄ™Ä‡ z wakacji, mÃ³gÅ‚byÅ› przedstawiÄ‡ systemowi uczenia maszynowego wiele przykÅ‚adÃ³w zdjÄ™Ä‡ juÅ¼ oznaczonych przez ludzi, a system nauczyÅ‚by siÄ™ statystycznych reguÅ‚ kojarzenia konkretnych zdjÄ™Ä‡ z konkretnymi tagami.</p>
<div class="quarto-figure quarto-figure-center page-columns page-full">
<figure class="figure page-columns page-full"><div class="page-columns page-full"><p></p><div class="no-row-height column-margin column-container"><img src="images/tw1.jpeg" class="img-fluid quarto-figure quarto-figure-center figure-img" width="400"></div></div>
</figure>
</div>
<p>ChociaÅ¼ uczenie maszynowe zaczÄ™Å‚o siÄ™ rozwijaÄ‡ dopiero w latach 90-tych, szybko staÅ‚o siÄ™ najpopularniejszÄ… i odnoszÄ…cÄ… najwiÄ™ksze sukcesy dziedzinÄ… AI, a trend ten jest napÄ™dzany przez dostÄ™pnoÅ›Ä‡ szybszego sprzÄ™tu i wiÄ™kszych zbiorÃ³w danych. Uczenie maszynowe jest Å›ciÅ›le zwiÄ…zane ze statystykÄ… matematycznÄ…, ale rÃ³Å¼ni siÄ™ od niej na kilka waÅ¼nych sposobÃ³w. W przeciwieÅ„stwie do statystyki, uczenie maszynowe ma tendencjÄ™ do zajmowania siÄ™ duÅ¼ymi, zÅ‚oÅ¼onymi zbiorami danych (takimi jak zbiÃ³r milionÃ³w obrazÃ³w, z ktÃ³rych kaÅ¼dy skÅ‚ada siÄ™ z dziesiÄ…tek tysiÄ™cy pikseli), dla ktÃ³rych klasyczna analiza statystyczna byÅ‚aby niepraktyczna. W rezultacie, uczenie maszynowe, a zwÅ‚aszcza gÅ‚Ä™bokie uczenie, wykazuje stosunkowo maÅ‚o teorii matematycznej - byÄ‡ moÅ¼e zbyt maÅ‚o - i jest zorientowane na inÅ¼ynieriÄ™. Jest to praktyczna dyscyplina, w ktÃ³rej pomysÅ‚y sÄ… sprawdzane empirycznie znacznie czÄ™Å›ciej niÅ¼ teoretycznie.</p>
<section id="uczenie-siÄ™-reprezentacji-na-podstawie-danych" class="level2" data-number="10.1"><h2 data-number="10.1" class="anchored" data-anchor-id="uczenie-siÄ™-reprezentacji-na-podstawie-danych">
<span class="header-section-number">10.1</span> Uczenie siÄ™ reprezentacji na podstawie danych</h2>
<p>Na to, aby zdefiniowaÄ‡ gÅ‚Ä™bokie uczenie i zrozumieÄ‡ rÃ³Å¼nicÄ™ miÄ™dzy gÅ‚Ä™bokim uczeniem a innymi podejÅ›ciami do uczenia maszynowego, najpierw musimy mieÄ‡ pewne pojÄ™cie o tym, co robiÄ… algorytmy uczenia maszynowego. WÅ‚aÅ›nie stwierdziliÅ›my, Å¼e uczenie maszynowe odkrywa reguÅ‚y wykonywania zadania przetwarzania danych, biorÄ…c pod uwagÄ™ przykÅ‚ady tego, co jest oczekiwane na wyjÅ›ciu. Zatem, aby przeprowadziÄ‡ uczenie maszynowe, potrzebujemy trzech rzeczy:</p>
<ul>
<li>Punkty danych wejÅ›ciowych - na przykÅ‚ad, jeÅ›li zadaniem jest rozpoznawanie mowy, tymi punktami danych mogÄ… byÄ‡ pliki dÅºwiÄ™kowe osÃ³b mÃ³wiÄ…cych. JeÅ›li zadanie polega na oznaczaniu obrazÃ³w, mogÄ… to byÄ‡ pliki z obrazami.</li>
<li>PrzykÅ‚ady oczekiwanych wynikÃ³w - w zadaniu rozpoznawania mowy mogÄ… to byÄ‡ generowane przez czÅ‚owieka transkrypcje plikÃ³w dÅºwiÄ™kowych. W zadaniu dotyczÄ…cym obrazÃ³w, oczekiwanymi danymi wyjÅ›ciowymi mogÄ… byÄ‡ tagi takie jak â€œpiesâ€, â€œkotâ€ itd.</li>
<li>SposÃ³b pomiaru, czy algorytm dobrze wykonuje swojÄ… pracÄ™ - jest on niezbÄ™dny do okreÅ›lenia odlegÅ‚oÅ›ci miÄ™dzy aktualnym wyjÅ›ciem algorytmu a jego oczekiwanym wyjÅ›ciem. Pomiar jest uÅ¼ywany jako sygnaÅ‚ zwrotny do dostosowania sposobu dziaÅ‚ania algorytmu. Ten krok dostosowawczy nazywamy uczeniem siÄ™ modelu.</li>
</ul>
<p>Model uczenia maszynowego przeksztaÅ‚ca dane wejÅ›ciowe w sensowne dane wyjÅ›ciowe, a proces ten jest â€œuczonyâ€ przez ekspozycjÄ™ na znane przykÅ‚ady danych wejÅ›ciowych i wyjÅ›ciowych. Dlatego centralnym problemem w uczeniu maszynowym i gÅ‚Ä™bokim uczeniu jest sensowne przeksztaÅ‚canie danych: innymi sÅ‚owy, uczenie siÄ™ uÅ¼ytecznych reprezentacji danych wejÅ›ciowych - reprezentacji, ktÃ³re przybliÅ¼ajÄ… nas do oczekiwanych wynikÃ³w. Zanim przejdziemy dalej: co to jest reprezentacja? W gruncie rzeczy jest to inny sposÃ³b patrzenia na dane - reprezentacja lub kodowanie danych. Na przykÅ‚ad, kolorowy obraz moÅ¼e byÄ‡ zakodowany w formacie RGB lub w formacie HSV (barwa-nasycenie-wartoÅ›Ä‡): sÄ… to dwie rÃ³Å¼ne reprezentacje tych samych danych. NiektÃ³re zadania, ktÃ³re mogÄ… byÄ‡ trudne do rozwiÄ…zania przy jednej reprezentacji, mogÄ… staÄ‡ siÄ™ Å‚atwe przy drugiej. Na przykÅ‚ad zadanie â€œwybierz wszystkie czerwone piksele na obrazieâ€ jest prostsze w formacie RBG, natomiast â€œspraw, by obraz byÅ‚ mniej nasyconyâ€ jest prostsze w formacie HSV. Modele uczenia maszynowego polegajÄ… na znalezieniu odpowiednich reprezentacji dla danych wejÅ›ciowych - przeksztaÅ‚ceÅ„ danych, ktÃ³re czyniÄ… je bardziej przydatnymi do wykonania zadania, np.zadania klasyfikacji.</p>
<p>Wszystkie algorytmy uczenia maszynowego polegajÄ… na automatycznym znajdowaniu takich przeksztaÅ‚ceÅ„, ktÃ³re zmieniajÄ… dane w bardziej uÅ¼yteczne reprezentacje dla danego zadania. Operacje te mogÄ… byÄ‡ zmianami wspÃ³Å‚rzÄ™dnych lub rzutami liniowymi, tÅ‚umaczeniami, operacjami nieliniowymi (takimi jak wybierz wszystkie punkty takie, Å¼e <span class="math inline">\(x &gt;0\)</span>) i tak dalej. Algorytmy uczenia maszynowego zazwyczaj nie sÄ… kreatywne w znajdowaniu tych przeksztaÅ‚ceÅ„; po prostu przeszukujÄ… wczeÅ›niej zdefiniowany zestaw operacji, zwany przestrzeniÄ… hipotez.</p>
<p>Tak wiÄ™c, technicznie rzecz biorÄ…c, uczenie maszynowe polega na poszukiwaniu uÅ¼ytecznych reprezentacji pewnych danych wejÅ›ciowych, w ramach predefiniowanej przestrzeni moÅ¼liwoÅ›ci, przy uÅ¼yciu wskazÃ³wek pochodzÄ…cych z jakiegoÅ› sygnaÅ‚u zwrotnego. Ta prosta idea pozwala na rozwiÄ…zywanie niezwykle szerokiego zakresu zadaÅ„ naturalnych dla czÅ‚owieka, od rozpoznawania mowy po autonomiczne prowadzenie samochodu.</p>
<p>GÅ‚Ä™bokie uczenie jest specyficznÄ… dziedzinÄ… uczenia maszynowego: nowe podejÅ›cie do uczenia siÄ™ reprezentacji z danych, ktÃ³re kÅ‚adzie nacisk na uczenie siÄ™ kolejnych warstw coraz bardziej znaczÄ…cych reprezentacji. GÅ‚Ä™bokie uczenie nie jest odniesieniem do jakiegokolwiek gÅ‚Ä™bszego zrozumienia osiÄ…ganego przez to podejÅ›cie; raczej oznacza ideÄ™ kolejnych warstw reprezentacji. To, ile warstw skÅ‚ada siÄ™ na model danych, nazywane jest gÅ‚Ä™bokoÅ›ciÄ… modelu. Innymi wÅ‚aÅ›ciwymi nazwami dla tej dziedziny mogÅ‚yby byÄ‡ uczenie siÄ™ reprezentacji warstwowych i uczenie siÄ™ reprezentacji hierarchicznych. Nowoczesne uczenie gÅ‚Ä™bokie czÄ™sto obejmuje dziesiÄ…tki, a nawet setki kolejnych warstw - i wszystkie one sÄ… uczone automatycznie na podstawie danych treningowych. Tymczasem inne podejÅ›cia do uczenia maszynowego koncentrujÄ… siÄ™ na uczeniu siÄ™ tylko jednej lub dwÃ³ch warstw reprezentacji danych; stÄ…d czasem nazywa siÄ™ je uczeniem pÅ‚ytkim.</p>
<p>W gÅ‚Ä™bokim uczeniu, te warstwowe reprezentacje sÄ… (prawie zawsze) uczone za pomocÄ… modeli zwanych sieciami neuronowymi, zbudowanymi w dosÅ‚ownych warstwach uÅ‚oÅ¼onych jedna za drugÄ…. Termin sieÄ‡ neuronowa jest odniesieniem do neurobiologii, jednak mimo Å¼e niektÃ³re z gÅ‚Ã³wnych koncepcji gÅ‚Ä™bokiego uczenia zostaÅ‚y opracowane czÄ™Å›ciowo poprzez czerpanie inspiracji z naszego rozumienia mÃ³zgu, modele gÅ‚Ä™bokiego uczenia nie sÄ… modelami mÃ³zgu. Nie ma dowodÃ³w na to, Å¼e mÃ³zg implementuje cokolwiek w rodzaju mechanizmÃ³w uczenia siÄ™ wykorzystywanych w nowoczesnych modelach gÅ‚Ä™bokiego uczenia. MoÅ¼esz natknÄ…Ä‡ siÄ™ na artykuÅ‚y popularno-naukowe gÅ‚oszÄ…ce, Å¼e gÅ‚Ä™bokie uczenie dziaÅ‚a jak mÃ³zg lub byÅ‚o wzorowane na mÃ³zgu, ale to nie jest prawda. ByÅ‚oby to mylÄ…ce, aby myÅ›leÄ‡ o gÅ‚Ä™bokim uczeniu jako w jakikolwiek sposÃ³b zwiÄ…zanym z neurobiologiÄ…. Dla naszych celÃ³w, gÅ‚Ä™bokie uczenie jest matematycznÄ… strukturÄ… do uczenia siÄ™ reprezentacji danych.</p>
<p>Jak wyglÄ…dajÄ… reprezentacje wyuczone przez algorytm gÅ‚Ä™bokiego uczenia? Przyjrzyjmy siÄ™, jak sieÄ‡ o gÅ‚Ä™bokoÅ›ci kilku warstw (patrz <a href="#fig-dl1" class="quarto-xref">Rysunek&nbsp;<span>10.2</span></a>) przeksztaÅ‚ca obraz cyfry w celu rozpoznania, jaka to cyfra.</p>
<div id="fig-dl1" class="quarto-figure quarto-figure-center quarto-float anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure"><div aria-describedby="fig-dl1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="images/Zrzut ekranu 2023-02-23 o 19.22.38.png" class="img-fluid quarto-figure quarto-figure-center figure-img" width="600">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-dl1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Rysunek&nbsp;10.2: Schemat dziaÅ‚ania sieci rozpoznajÄ…cej cyfry
</figcaption></figure>
</div>
<p>Jak widaÄ‡ na <a href="#fig-dl2" class="quarto-xref">Rysunek&nbsp;<span>10.3</span></a>, sieÄ‡ przeksztaÅ‚ca obraz cyfry w reprezentacje coraz bardziej rÃ³Å¼niÄ…ce siÄ™ od obrazu oryginalnego i coraz bardziej informujÄ…ce o wyniku koÅ„cowym. MoÅ¼na myÅ›leÄ‡ o sieci gÅ‚Ä™bokiej jak o wielostopniowej operacji destylacji informacji, gdzie informacja przechodzi przez kolejne filtry i wychodzi coraz bardziej oczyszczona (czyli przydatna w odniesieniu do jakiegoÅ› zadania).</p>
<div id="fig-dl2" class="quarto-figure quarto-figure-center quarto-float anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure"><div aria-describedby="fig-dl2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="images/Zrzut ekranu 2023-02-23 o 19.24.25.png" class="img-fluid quarto-figure quarto-figure-center figure-img" width="600">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-dl2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Rysunek&nbsp;10.3: Przedstawienie zasady dziaÅ‚ania poszczegÃ³lnych warstw sieci neuronowej w rozpoznawaniu cyfr
</figcaption></figure>
</div>
<p>Tak wÅ‚aÅ›nie wyglÄ…da gÅ‚Ä™bokie uczenie, technicznie rzecz biorÄ…c: jest to wieloetapowy sposÃ³b uczenia siÄ™ reprezentacji danych. To prosty pomysÅ‚ - ale jak siÄ™ okazuje, bardzo proste mechanizmy, odpowiednio skalowane, mogÄ… w koÅ„cu wyglÄ…daÄ‡ jak magia ğŸ™‰.</p>
</section><section id="jak-dziaÅ‚a-deep-learning" class="level2 page-columns page-full" data-number="10.2"><h2 data-number="10.2" class="anchored" data-anchor-id="jak-dziaÅ‚a-deep-learning">
<span class="header-section-number">10.2</span> Jak dziaÅ‚a deep learning?</h2>
<p>Wiemy juÅ¼, Å¼e uczenie maszynowe polega na mapowaniu danych wejÅ›ciowych (takich jak obrazy) na dane docelowe (takie jak etykieta â€œkotâ€), co odbywa siÄ™ poprzez obserwacjÄ™ wielu przykÅ‚adÃ³w danych wejÅ›ciowych i danych docelowych. Wiemy teÅ¼, Å¼e gÅ‚Ä™bokie sieci neuronowe wykonujÄ… odwzorowanie danych wejÅ›ciowych na docelowe poprzez gÅ‚Ä™bokÄ… sekwencjÄ™ prostych transformacji danych (warstwy) i Å¼e te transformacje danych sÄ… uczone przez ekspozycjÄ™ na przykÅ‚ady. Przyjrzyjmy siÄ™ teraz, jak to uczenie przebiega, konkretnie.</p>
<p>Specyfikacja tego, co warstwa robi ze swoimi danymi wejÅ›ciowymi, jest przechowywana w wagach warstwy (zwanych wagami synaptycznymi), ktÃ³re w istocie sÄ… zbiorem liczb. W sensie technicznym moÅ¼na powiedzieÄ‡, Å¼e transformacja wykonywana przez warstwÄ™ jest sparametryzowana przez jej wagi (patrz <a href="#fig-dl3" class="quarto-xref">Rysunek&nbsp;<span>10.4</span></a>). W tym kontekÅ›cie uczenie oznacza znalezienie zestawu wartoÅ›ci dla wag wszystkich warstw w sieci, tak aby sieÄ‡ poprawnie odwzorowywaÅ‚a przykÅ‚adowe wejÅ›cia na przypisane im cele. Rzecz w tym, Å¼e gÅ‚Ä™boka sieÄ‡ neuronowa moÅ¼e zawieraÄ‡ dziesiÄ…tki milionÃ³w parametrÃ³w. Znalezienie poprawnej wartoÅ›ci dla wszystkich z nich moÅ¼e wydawaÄ‡ siÄ™ trudnym zadaniem, szczegÃ³lnie biorÄ…c pod uwagÄ™ fakt, Å¼e zmiana wartoÅ›ci jednego parametru wpÅ‚ynie na zachowanie wszystkich pozostaÅ‚ych!</p>
<div id="fig-dl3" class="quarto-figure quarto-figure-center quarto-float anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure"><div aria-describedby="fig-dl3-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="images/Zrzut ekranu 2023-02-23 o 19.37.23.png" class="img-fluid quarto-figure quarto-figure-center figure-img" width="400">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-dl3-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Rysunek&nbsp;10.4: SieÄ‡ neuronowa parametryzowana przez wagi
</figcaption></figure>
</div>
<p>Aby coÅ› kontrolowaÄ‡, trzeba najpierw mÃ³c to obserwowaÄ‡. Aby kontrolowaÄ‡ wyjÅ›cie sieci neuronowej, musimy byÄ‡ w stanie zmierzyÄ‡, jak daleko to wyjÅ›cie jest od tego, czego siÄ™ spodziewaliÅ›my. Jest to zadanie dla funkcji straty sieci, zwanej rÃ³wnieÅ¼ funkcjÄ… celu. Funkcja straty bierze predykcje sieci oraz prawdziwy wynik i oblicza wynik odlegÅ‚oÅ›ci, ujmujÄ…c, jak dobrze sieÄ‡ poradziÅ‚a sobie z tym konkretnym przykÅ‚adem (patrz <a href="#fig-dl4" class="quarto-xref">Rysunek&nbsp;<span>10.5</span></a>).</p>
<div id="fig-dl4" class="quarto-figure quarto-figure-center quarto-float anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure"><div aria-describedby="fig-dl4-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="images/Zrzut ekranu 2023-02-23 o 19.37.35.png" class="img-fluid quarto-figure quarto-figure-center figure-img" width="400">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-dl4-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Rysunek&nbsp;10.5: Funkcja straty mierzÄ…ca jakoÅ›Ä‡ predykcji
</figcaption></figure>
</div>
<p>PodstawowÄ… sztuczkÄ… w uczeniu gÅ‚Ä™bokim jest wykorzystanie wyniku jako sygnaÅ‚u zwrotnego do skorygowania wartoÅ›ci wag w kierunku, ktÃ³ry obniÅ¼y wynik straty dla bieÅ¼Ä…cego przykÅ‚adu (patrz <a href="#fig-dl5" class="quarto-xref">Rysunek&nbsp;<span>10.6</span></a>). Ta korekta jest zadaniem optymalizatora, ktÃ³ry implementuje coÅ›, co nazywa siÄ™ algorytmem wstecznej propagacji (ang. <em>backpropagation</em>)<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a>. W dalszej czÄ™Å›ci wyjaÅ›nimy bardziej szczegÃ³Å‚owo, jak dziaÅ‚a wsteczna propagacja.</p>
<div class="no-row-height column-margin column-container"><p><sup>1</sup>&nbsp;gÅ‚Ã³wny algorytm w uczeniu gÅ‚Ä™bokim</p></div><div id="fig-dl5" class="quarto-figure quarto-figure-center quarto-float anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure"><div aria-describedby="fig-dl5-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="images/Zrzut ekranu 2023-02-23 o 19.37.48.png" class="img-fluid quarto-figure quarto-figure-center figure-img" width="400">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-dl5-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Rysunek&nbsp;10.6: Korekta wag wykorzystujÄ…ca wartoÅ›Ä‡ funkcji straty
</figcaption></figure>
</div>
<p>PoczÄ…tkowo wagom sieci przypisane sÄ… losowe wartoÅ›ci, wiÄ™c sieÄ‡ wykonuje jedynie seriÄ™ losowych przeksztaÅ‚ceÅ„. OczywiÅ›cie jej wynik jest daleki od tego, jaki powinien byÄ‡ w idealnej sytuacji, a wynik funkcji straty jest bardzo wysoki. Ale z kaÅ¼dym przykÅ‚adem, ktÃ³ry sieÄ‡ przetwarza, wagi sÄ… dostosowywane w prawidÅ‚owym kierunku, a wynik strat maleje. Jest to pÄ™tla treningowa, ktÃ³ra powtarzana odpowiedniÄ… iloÅ›Ä‡ razy (zwykle dziesiÄ…tki iteracji na tysiÄ…cach przykÅ‚adÃ³w) daje wartoÅ›ci wag, ktÃ³re minimalizujÄ… funkcjÄ™ straty. SieÄ‡ z minimalnÄ… stratÄ… to taka, dla ktÃ³rej wyjÅ›cia sÄ… tak bliskie celom, jak to tylko moÅ¼liwe<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a>.</p>
<div class="no-row-height column-margin column-container"><p><sup>2</sup>&nbsp;sieÄ‡ wytrenowana</p></div></section><section id="krÃ³tki-rys-historyczny-dl" class="level2 page-columns page-full" data-number="10.3"><h2 data-number="10.3" class="anchored" data-anchor-id="krÃ³tki-rys-historyczny-dl">
<span class="header-section-number">10.3</span> KrÃ³tki rys historyczny DL</h2>
<p>OkoÅ‚o 2010 roku, mimo Å¼e sieci neuronowe byÅ‚y niemal caÅ‚kowicie odrzucane przez ogÃ³Å‚ spoÅ‚ecznoÅ›ci naukowej, kilka osÃ³b wciÄ…Å¼ pracujÄ…cych nad sieciami neuronowymi zaczÄ™Å‚o dokonywaÄ‡ waÅ¼nych przeÅ‚omÃ³w: grupy Geoffreya Hintona z Uniwersytetu w Toronto, Yoshua Bengio z Uniwersytetu w Montrealu, Yann LeCun z Uniwersytetu Nowojorskiego oraz IDSIA w Szwajcarii.</p>
<p>W 2011 roku Dan Ciresan z IDSIA zaczÄ…Å‚ wygrywaÄ‡ akademickie konkursy klasyfikacji obrazÃ³w za pomocÄ… trenowanych na GPU gÅ‚Ä™bokich sieci neuronowych - byÅ‚ to pierwszy praktyczny sukces nowoczesnego uczenia gÅ‚Ä™bokiego. Jednak przeÅ‚omowy moment nastÄ…piÅ‚ w 2012 roku, gdy grupa Hintona wziÄ™Å‚a udziaÅ‚ w corocznym wyzwaniu ImageNet dotyczÄ…cym klasyfikacji obrazÃ³w na duÅ¼Ä… skalÄ™. Wyzwanie ImageNet byÅ‚o w tamtym czasie wyjÄ…tkowo trudne, polegaÅ‚o na klasyfikacji kolorowych obrazÃ³w o wysokiej rozdzielczoÅ›ci do 1000 rÃ³Å¼nych kategorii po przeszkoleniu na 1,4 mln obrazÃ³w. W 2011 roku dokÅ‚adnoÅ›Ä‡ zwyciÄ™skiego modelu, opartego na klasycznym podejÅ›ciu do widzenia komputerowego, wyniosÅ‚a zaledwie 74,3%. NastÄ™pnie, w 2012 roku, zespÃ³Å‚ kierowany przez Alexa Krizhevskyâ€™ego i wspierany przez Geoffreya Hintona byÅ‚ w stanie osiÄ…gnÄ…Ä‡ dokÅ‚adnoÅ›Ä‡ pierwszej piÄ…tki<a href="#fn3" class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a> na poziomie 83,6% - byÅ‚ to znaczÄ…cy przeÅ‚om. Od tego czasu co roku konkurs byÅ‚ zdominowany przez gÅ‚Ä™bokie konwencjonalne sieci neuronowe. W 2015 roku zwyciÄ™zca osiÄ…gnÄ…Å‚ dokÅ‚adnoÅ›Ä‡ 96,4%, a zadanie klasyfikacji na ImageNet uznano za caÅ‚kowicie rozwiÄ…zany problem.</p>
<div class="no-row-height column-margin column-container"><p><sup>3</sup>&nbsp;(ang. <em>top 5 accuracy</em>) <em>-</em> oznacza, Å¼e wÅ›rÃ³d 5 kategorii z najwyÅ¼szym prawdopodobieÅ„stwem jest prawdziwa klasa</p></div><div class="quarto-figure quarto-figure-center page-columns page-full">
<figure class="figure page-columns page-full"><div class="page-columns page-full"><p></p><div class="no-row-height column-margin column-container"><img src="images/tw2.jpeg" class="img-fluid quarto-figure quarto-figure-center figure-img" width="400"></div></div>
</figure>
</div>
<p>Od 2012 r. gÅ‚Ä™bokie konwolucyjne sieci neuronowe (CovNets - <em>Convolutional Networks</em>) staÅ‚y siÄ™ algorytmem pierwszego wyboru dla wszystkich zadaÅ„ widzenia komputerowego. Na najwaÅ¼niejszych konferencjach poÅ›wiÄ™conych widzeniu komputerowemu w 2015 i 2016 r. niemal niemoÅ¼liwe byÅ‚o znalezienie prezentacji, ktÃ³re w jakiejÅ› formie nie wiÄ…zaÅ‚yby siÄ™ z CovNets. JednoczeÅ›nie gÅ‚Ä™bokie uczenie znalazÅ‚o zastosowanie w wielu innych typach problemÃ³w, takich jak np. przetwarzanie jÄ™zyka naturalnego. W szerokim zakresie zastosowaÅ„ caÅ‚kowicie zastÄ…piÅ‚o klasyczne modele SVM i drzewa decyzyjne. Na przykÅ‚ad przez kilka lat Europejska Organizacja BadaÅ„ JÄ…drowych (CERN), uÅ¼ywaÅ‚a metod opartych na drzewach decyzyjnych do analizy danych czÄ…stek z detektora ATLAS w Wielkim Zderzaczu HadronÃ³w (LHC); ale CERN ostatecznie przeszedÅ‚ na gÅ‚Ä™bokie sieci neuronowe oparte na Keras ze wzglÄ™du na ich wyÅ¼szÄ… wydajnoÅ›Ä‡ i Å‚atwoÅ›Ä‡ szkolenia na duÅ¼ych zbiorach danych.</p>
<p>Podstawowym powodem, dla ktÃ³rego uczenie gÅ‚Ä™bokie odniosÅ‚o sukces tak szybko, jest to, Å¼e oferowaÅ‚o lepszÄ… wydajnoÅ›Ä‡ w wielu problemach. Ale to nie jest jedyny powÃ³d. GÅ‚Ä™bokie uczenie uÅ‚atwia rÃ³wnieÅ¼ rozwiÄ…zywanie problemÃ³w, poniewaÅ¼ caÅ‚kowicie automatyzuje to, co kiedyÅ› byÅ‚o najbardziej kluczowym krokiem w procesie uczenia maszynowego - inÅ¼ynieriÄ™ cech.</p>
<p>Poprzednie techniki uczenia maszynowego - uczenie gÅ‚Ä™bokie - polegaÅ‚y jedynie na przeksztaÅ‚ceniu danych wejÅ›ciowych w jednÄ… lub dwie kolejne przestrzenie reprezentacji, zwykle poprzez proste przeksztaÅ‚cenia, takie jak wielowymiarowe projekcje nieliniowe (SVM) lub drzewa decyzyjne. Jednak wyrafinowane reprezentacje wymagane przez zÅ‚oÅ¼one problemy zazwyczaj nie mogÄ… byÄ‡ realizowane przez wspomniane techniki. W zwiÄ…zku z tym, ludzie musieli zadaÄ‡ sobie wiele trudu, aby uczyniÄ‡ poczÄ…tkowe dane wejÅ›ciowe bardziej podatnymi na przetwarzanie przez te metody: to znaczy, musieli rÄ™cznie opracowaÄ‡ dobre warstwy reprezentacji dla swoich danych. Nazywa siÄ™ to inÅ¼ynieriÄ… cech. Uczenie gÅ‚Ä™bokie caÅ‚kowicie automatyzuje ten krok: w przypadku uczenia gÅ‚Ä™bokiego, uczy siÄ™ wszystkich cech w jednym przejÅ›ciu i nie musimy ich samodzielnie opracowywaÄ‡. To znacznie uproÅ›ciÅ‚o przepÅ‚ywy pracy zwiÄ…zane z uczeniem maszynowym, czÄ™sto zastÄ™pujÄ…c skomplikowane, wieloetapowe potoki jednym, prostym, kompleksowym modelem uczenia gÅ‚Ä™bokiego.</p>
<p>MoÅ¼na zapytaÄ‡, skoro sednem sprawy jest posiadanie wielu kolejnych warstw reprezentacji, to czy pÅ‚ytkie metody mogÄ… byÄ‡ stosowane wielokrotnie, aby emulowaÄ‡ efekty gÅ‚Ä™bokiego uczenia? W praktyce, korzyÅ›Ä‡ z zastosowania kilku metod pÅ‚ytkiego uczenia szybko maleje, poniewaÅ¼ optymalna pierwsza warstwa reprezentacji w modelu trÃ³jwarstwowym nie jest optymalnÄ… pierwszÄ… warstwÄ… w modelu jedno- lub dwuwarstwowym. To, co jest przeÅ‚omowe w uczeniu gÅ‚Ä™bokim, to fakt, Å¼e pozwala ono modelowi uczyÄ‡ siÄ™ wszystkich warstw reprezentacji wspÃ³lnie, w tym samym czasie. DziÄ™ki wspÃ³lnemu uczeniu cech, gdy model dostosowuje jednÄ… ze swoich wewnÄ™trznych cech, wszystkie inne cechy, ktÃ³re od niej zaleÅ¼Ä…, automatycznie dostosowujÄ… siÄ™ do tej zmiany, bez koniecznoÅ›ci interwencji czÅ‚owieka. Wszystko jest nadzorowane przez pojedynczy sygnaÅ‚ zwrotny: kaÅ¼da zmiana w modelu sÅ‚uÅ¼y celowi koÅ„cowemu. Jest to znacznie bardziej efektywne niÅ¼ skÅ‚adanie pÅ‚ytkich modeli, poniewaÅ¼ pozwala na uczenie siÄ™ zÅ‚oÅ¼onych, abstrakcyjnych reprezentacji poprzez rozbicie ich na dÅ‚ugie serie poÅ›rednich warstw; kaÅ¼da warstwa jest tylko prostym przeksztaÅ‚ceniem w stosunku do poprzedniej.</p>
<p>Dwie zasadnicze cechy tego, jak gÅ‚Ä™bokie uczenie uczy siÄ™ z danych, to: przyrostowy, warstwa po warstwie sposÃ³b, w jaki korygowane sÄ… coraz bardziej zÅ‚oÅ¼one reprezentacje, oraz fakt, Å¼e te poÅ›rednie, przyrostowe reprezentacje sÄ… uczone wspÃ³lnie, a kaÅ¼da warstwa jest aktualizowana, aby podÄ…Å¼aÄ‡ zarÃ³wno za potrzebami reprezentacyjnymi warstwy powyÅ¼ej, jak i potrzebami warstwy poniÅ¼ej. Razem, te dwie wÅ‚aÅ›ciwoÅ›ci sprawiÅ‚y, Å¼e gÅ‚Ä™bokie uczenie jest znacznie bardziej skuteczne niÅ¼ poprzednie podejÅ›cia do uczenia maszynowego.</p>
<p>Åšwietnym sposobem na poznanie aktualnego bogactwa algorytmÃ³w i narzÄ™dzi uczenia maszynowego jest przyjrzenie siÄ™ konkursom uczenia maszynowego na Kaggle. DziÄ™ki wysoce konkurencyjnemu Å›rodowisku (niektÃ³re konkursy majÄ… tysiÄ…ce uczestnikÃ³w i milionowe nagrody) i szerokiej gamie problemÃ³w uczenia maszynowego, Kaggle oferuje realistyczny sposÃ³b oceny tego, co dziaÅ‚a, a co nie. Jaki wiÄ™c rodzaj algorytmu niezawodnie wygrywa konkursy? Z jakich narzÄ™dzi korzystajÄ… najlepsi uczestnicy?</p>
<p>W 2016 roku Kaggle zostaÅ‚ zdominowany przez dwa podejÅ›cia: <em>gradient boosting machines</em> i <em>deep learning</em>. NaleÅ¼y nadmieniÄ‡, Å¼e <em>gradient boosting</em> jest uÅ¼ywany gÅ‚Ã³wnie do problemÃ³w, w ktÃ³rych dostÄ™pne sÄ… ustrukturyzowane dane, podczas gdy gÅ‚Ä™bokie uczenie jest uÅ¼ywane do problemÃ³w percepcyjnych, takich jak klasyfikacja obrazÃ³w. Zwolennicy tego pierwszego rozwiÄ…zania prawie zawsze korzystajÄ… ze znakomitej biblioteki <code>XGBoost</code>. Tymczasem wiÄ™kszoÅ›Ä‡ uczestnikÃ³w Kaggle wykorzystujÄ…cych uczenie gÅ‚Ä™bokie uÅ¼ywa biblioteki <code>Keras</code>, ze wzglÄ™du na jej Å‚atwoÅ›Ä‡ uÅ¼ycia i elastycznoÅ›Ä‡. ZarÃ³wno <code>XGBoost</code>, jak i <code>Keras</code> wspierajÄ… dwa najpopularniejsze jÄ™zyki data science: R i Python.</p>
<section id="hardware" class="level3" data-number="10.3.1"><h3 data-number="10.3.1" class="anchored" data-anchor-id="hardware">
<span class="header-section-number">10.3.1</span> Hardware</h3>
<p>W latach 1990-2010 procesory dostÄ™pne na rynku staÅ‚y siÄ™ szybsze o okoÅ‚o 5000 razy. W rezultacie, obecnie moÅ¼liwe jest uruchomienie maÅ‚ych modeli gÅ‚Ä™bokiego uczenia na laptopie, podczas gdy 25 lat temu byÅ‚oby to niewykonalne.</p>
<p>Jednak typowe modele gÅ‚Ä™bokiego uczenia wykorzystywane w wizji komputerowej lub rozpoznawaniu mowy wymagajÄ… mocy obliczeniowej o kilka rzÄ™dÃ³w wielkoÅ›ci wiÄ™kszej niÅ¼ ta, ktÃ³rÄ… moÅ¼e zapewniÄ‡ laptop. Przez caÅ‚Ä… dekadÄ™ XXI wieku firmy takie jak NVIDIA i AMD inwestowaÅ‚y miliardy dolarÃ³w w rozwÃ³j szybkich, rÃ³wnolegÅ‚ych ukÅ‚adÃ³w (procesorÃ³w graficznych [GPU]), ktÃ³re napÄ™dzaÅ‚y grafikÄ™ w coraz bardziej fotorealistycznych grach wideo - tanich, osobistych komputerÃ³w zaprojektowanych do renderowania zÅ‚oÅ¼onych scen 3D na ekranie w czasie rzeczywistym. Inwestycja ta przyniosÅ‚a korzyÅ›ci spoÅ‚ecznoÅ›ci naukowej, gdy w 2007 roku NVIDIA wprowadziÅ‚a CUDA (<a href="https://developer.nvidia.com/about-cuda" class="uri">https://developer.nvidia.com/about-cuda</a>), interfejs programistyczny dla swojej linii ukÅ‚adÃ³w GPU. Niewielka liczba procesorÃ³w graficznych zaczÄ™Å‚a zastÄ™powaÄ‡ klastry CPU w rÃ³Å¼nych zÅ‚oÅ¼onych zadaniach, poczÄ…wszy od modelowania w fizyce. GÅ‚Ä™bokie sieci neuronowe, skÅ‚adajÄ…ce siÄ™ gÅ‚Ã³wnie z wielu mnoÅ¼eÅ„ macierzy, sÄ… rÃ³wnieÅ¼ wysoce paralelizowalne i okoÅ‚o 2011 roku niektÃ³rzy badacze zaczÄ™li pisaÄ‡ implementacje CUDA sieci neuronowych - jednymi z pierwszych byli Dan Ciresan<span class="citation" data-cites="ciresanFlexibleHighPerformance">(<a href="references.html#ref-ciresanFlexibleHighPerformance" role="doc-biblioref">Ciresan i in., b.d.</a>)</span> i Alex Krizhevsky<span class="citation" data-cites="krizhevsky2017">(<a href="references.html#ref-krizhevsky2017" role="doc-biblioref">Krizhevsky, Sutskever, i Hinton 2017</a>)</span>.</p>
<p><br>
StaÅ‚o siÄ™ tak, Å¼e rynek gier dofinansowaÅ‚ superkomputery dla nastÄ™pnej generacji aplikacji sztucznej inteligencji. Czasami wielkie rzeczy zaczynajÄ… siÄ™ do zabawy ğŸ™ˆ. DziÅ› NVIDIA Titan X, procesor graficzny dla graczy, ktÃ³ry kosztowaÅ‚ 1000 dolarÃ³w pod koniec 2015 roku, moÅ¼e zapewniÄ‡ szczytowÄ… wydajnoÅ›Ä‡ 6,6 TLOPS w pojedynczej precyzji: to znaczy 6,6 biliona operacji <code>float32</code> na sekundÄ™. To okoÅ‚o 350 razy wiÄ™cej niÅ¼ to, co moÅ¼na wyciÄ…gnÄ…Ä‡ z nowoczesnego laptopa. Na Tytanie X trenowanie modelu ImageNet, ktÃ³ry kilka lat temu wygraÅ‚by konkurs ILSVRC, zajmuje zaledwie kilka dni. Tymczasem duÅ¼e firmy trenujÄ… modele gÅ‚Ä™bokiego uczenia na klastrach skÅ‚adajÄ…cych siÄ™ z setek jednostek GPU, takich jak NVIDIA K80, opracowanych specjalnie na potrzeby gÅ‚Ä™bokiego uczenia. Sama moc obliczeniowa takich klastrÃ³w jest czymÅ›, co nigdy nie byÅ‚oby moÅ¼liwe bez nowoczesnych procesorÃ³w graficznych.</p>
<p>Co wiÄ™cej, branÅ¼a gÅ‚Ä™bokiego uczenia zaczyna wychodziÄ‡ poza procesory graficzne i inwestuje w coraz bardziej wyspecjalizowane, wydajne ukÅ‚ady do gÅ‚Ä™bokiego uczenia. W 2016 roku, na corocznej konwencji I/O, Google ujawniÅ‚o swÃ³j projekt procesora tensorowego (TPU): nowy ukÅ‚ad scalony opracowany od podstaw w celu uruchamiania gÅ‚Ä™bokich sieci neuronowych, ktÃ³ry jest podobno 10 razy szybszy i znacznie bardziej energooszczÄ™dny niÅ¼ topowe ukÅ‚ady GPU.</p>
</section><section id="dane" class="level3 page-columns page-full" data-number="10.3.2"><h3 data-number="10.3.2" class="anchored" data-anchor-id="dane">
<span class="header-section-number">10.3.2</span> Dane</h3>
<p>AI jest czasem zapowiadana jako nowa rewolucja przemysÅ‚owa. JeÅ›li gÅ‚Ä™bokie uczenie jest maszynÄ… parowÄ… tej rewolucji, to dane sÄ… jej wÄ™glem: surowcem, ktÃ³ry zasila nasze inteligentne maszyny, bez ktÃ³rego nic nie byÅ‚oby moÅ¼liwe. JeÅ›li chodzi o dane, to oprÃ³cz wykÅ‚adniczego postÄ™pu w dziedzinie sprzÄ™tu do przechowywania danych w ciÄ…gu ostatnich 20 lat (zgodnie z prawem Mooreâ€™a<a href="#fn4" class="footnote-ref" id="fnref4" role="doc-noteref"><sup>4</sup></a>), kluczowym czynnikiem byÅ‚ rozwÃ³j Internetu, dziÄ™ki ktÃ³remu moÅ¼liwe staÅ‚o siÄ™ gromadzenie i rozpowszechnianie bardzo duÅ¼ych zbiorÃ³w danych na potrzeby uczenia maszynowego. Obecnie duÅ¼e firmy pracujÄ… z zestawami danych obrazowych, zestawami danych wideo i zestawami danych w jÄ™zyku naturalnym, ktÃ³re nie mogÅ‚yby zostaÄ‡ zebrane bez Internetu. PrzykÅ‚adowo, generowane przez uÅ¼ytkownikÃ³w tagi do obrazÃ³w w serwisie Flickr sÄ… skarbnicÄ… danych dla wizji komputerowej. Podobnie jest z filmami z YouTube. A Wikipedia jest kluczowym zbiorem danych dla przetwarzania jÄ™zyka naturalnego.</p>
<div class="no-row-height column-margin column-container"><p><sup>4</sup>&nbsp;mÃ³wi o tym, Å¼e liczba tranzystorÃ³w w procesorach roÅ›nie wykÅ‚adniczo</p></div><p>JeÅ›li jest jakiÅ› zbiÃ³r danych, ktÃ³ry staÅ‚ siÄ™ katalizatorem rozwoju gÅ‚Ä™bokiego uczenia, to jest to zbiÃ³r danych ImageNet, skÅ‚adajÄ…cy siÄ™ z 1,4 miliona obrazÃ³w, ktÃ³re zostaÅ‚y rÄ™cznie przypisane do 1000 kategorii obrazÃ³w (1 kategoria na obraz). Jednak to, co czyni ImageNet wyjÄ…tkowym, to nie tylko jego duÅ¼y rozmiar, ale takÅ¼e coroczny konkurs z nim zwiÄ…zany. Jak pokazuje Kaggle od 2010 roku, publiczne konkursy sÄ… doskonaÅ‚ym sposobem motywowania naukowcÃ³w i inÅ¼ynierÃ³w do przekraczania granic. Posiadanie wspÃ³lnych benchmarkÃ³w, ktÃ³re badacze starajÄ… siÄ™ pokonaÄ‡, bardzo pomogÅ‚o w niedawnym rozwoju uczenia gÅ‚Ä™bokiego.</p>
</section><section id="algorytmy" class="level3" data-number="10.3.3"><h3 data-number="10.3.3" class="anchored" data-anchor-id="algorytmy">
<span class="header-section-number">10.3.3</span> Algorytmy</h3>
<p>OprÃ³cz sprzÄ™tu i danych, aÅ¼ do pÃ³Åºnych lat 2000 brakowaÅ‚o niezawodnego sposobu trenowania bardzo gÅ‚Ä™bokich sieci neuronowych. W rezultacie sieci neuronowe byÅ‚y wciÄ…Å¼ doÅ›Ä‡ pÅ‚ytkie, wykorzystujÄ…c tylko jednÄ… lub dwie warstwy reprezentacji; nie byÅ‚y wiÄ™c w stanie zabÅ‚ysnÄ…Ä‡ w porÃ³wnaniu z bardziej wyrafinowanymi klasycznymi metodami, takimi jak SVM czy lasy losowe. Kluczowym problemem byÅ‚a propagacja gradientu przez gÅ‚Ä™bokie stosy warstw. SygnaÅ‚ zwrotny uÅ¼ywany do trenowania sieci neuronowych zanikaÅ‚ wraz ze wzrostem liczby warstw.</p>
<p>ZmieniÅ‚o siÄ™ to okoÅ‚o 2009-2010 roku wraz z pojawieniem siÄ™ kilku prostych, ale waÅ¼nych ulepszeÅ„ algorytmicznych, ktÃ³re pozwoliÅ‚y na lepszÄ… propagacjÄ™ gradientu:</p>
<ul>
<li>lepsze funkcje aktywacji dla warstw neuronowych;</li>
<li>lepsze schematy inicjalizacji wag, poczÄ…wszy od wstÄ™pnego szkolenia z podziaÅ‚em na warstwy, ktÃ³re zostaÅ‚o szybko porzucone;</li>
<li>lepsze schematy optymalizacji, takie jak RMSProp i Adam.</li>
</ul>
<p>Dopiero gdy te ulepszenia pozwoliÅ‚y na trenowanie modeli z 10 lub wiÄ™cej warstwami, uczenie gÅ‚Ä™bokie zaczÄ™Å‚o bÅ‚yszczeÄ‡. Wreszcie w latach 2014, 2015 i 2016 odkryto jeszcze bardziej zaawansowane sposoby wspomagania propagacji gradientu, takie jak normalizacja partii (ang. <em>batch normalization</em>), poÅ‚Ä…czenia resztkowe (ang. <em>residual connections</em>) czy konwolucje separowalne w gÅ‚Ä…b (ang. <em>depthwise separable convolutions</em>). DziÅ› moÅ¼emy trenowaÄ‡ od podstaw modele, ktÃ³re majÄ… tysiÄ…ce warstw gÅ‚Ä™bokoÅ›ci.</p>
<p>Czy jest coÅ› szczegÃ³lnego w gÅ‚Ä™bokich sieciach neuronowych, co sprawia, Å¼e sÄ… one â€œwÅ‚aÅ›ciwymâ€ podejÅ›ciem dla firm, w ktÃ³re naleÅ¼y inwestowaÄ‡ i dla naukowcÃ³w, ktÃ³rzy chcÄ… siÄ™ nimi zainteresowaÄ‡? Czy moÅ¼e gÅ‚Ä™bokie uczenie siÄ™ jest tylko modÄ…, ktÃ³ra moÅ¼e nie przetrwaÄ‡? Czy za 20 lat nadal bÄ™dziemy uÅ¼ywaÄ‡ gÅ‚Ä™bokich sieci neuronowych?</p>
<p>KrÃ³tka odpowiedÅº brzmi: tak ğŸ™ - gÅ‚Ä™bokie uczenie ma kilka wÅ‚aÅ›ciwoÅ›ci, ktÃ³re uzasadniajÄ… jego status jako rewolucji AI. ByÄ‡ moÅ¼e za dwie dekady nie bÄ™dziemy uÅ¼ywaÄ‡ sieci neuronowych, ale cokolwiek bÄ™dziemy uÅ¼ywaÄ‡, bÄ™dzie bezpoÅ›rednio dziedziczyÄ‡ po nowoczesnym gÅ‚Ä™bokim uczeniu i jego podstawowych koncepcjach. NajwaÅ¼niejsze wÅ‚aÅ›ciwoÅ›ci moÅ¼na ogÃ³lnie podzieliÄ‡ na trzy kategorie:</p>
<ul>
<li>Prostota - gÅ‚Ä™bokie uczenie eliminuje potrzebÄ™ inÅ¼ynierii cech, zastÄ™pujÄ…c zÅ‚oÅ¼one, wraÅ¼liwe i wymagajÄ…ce inÅ¼ynierii potoki prostymi, kompleksowo wytrenowanymi modelami, ktÃ³re sÄ… zazwyczaj budowane przy uÅ¼yciu tylko piÄ™ciu lub szeÅ›ciu rÃ³Å¼nych operacji na tensorach.</li>
<li>SkalowalnoÅ›Ä‡ - gÅ‚Ä™bokie uczenie jest bardzo podatne na rÃ³wnolegÅ‚e przetwarzanie na ukÅ‚adach GPU lub TPU. Dodatkowo, modele gÅ‚Ä™bokiego uczenia sÄ… trenowane poprzez iteracjÄ™ na maÅ‚ych partiach danych, co pozwala na ich trenowanie na zbiorach danych o dowolnym rozmiarze. (Jedynym wÄ…skim gardÅ‚em jest iloÅ›Ä‡ dostÄ™pnej mocy obliczeniowej).</li>
<li>WszechstronnoÅ›Ä‡ i moÅ¼liwoÅ›Ä‡ ponownego wykorzystania - w przeciwieÅ„stwie do wielu wczeÅ›niejszych podejÅ›Ä‡ do uczenia maszynowego, modele gÅ‚Ä™bokiego uczenia mogÄ… byÄ‡ trenowane na dodatkowych danych bez koniecznoÅ›ci ponownego rozpoczynania od zera, co czyni je realnymi dla ciÄ…gÅ‚ego uczenia siÄ™ na bieÅ¼Ä…co - waÅ¼na wÅ‚aÅ›ciwoÅ›Ä‡ dla bardzo duÅ¼ych modeli produkcyjnych. Co wiÄ™cej, wytrenowane modele gÅ‚Ä™bokiego uczenia mogÄ… byÄ‡ ponownie wykorzystane, na przykÅ‚ad, moÅ¼liwe jest wziÄ™cie modelu gÅ‚Ä™bokiego uczenia wytrenowanego do klasyfikacji obrazÃ³w i wrzucenie go do potoku przetwarzania wideo.</li>
</ul></section></section><section id="elementy-deep-learning" class="level2 page-columns page-full" data-number="10.4"><h2 data-number="10.4" class="anchored" data-anchor-id="elementy-deep-learning">
<span class="header-section-number">10.4</span> Elementy Deep Learning</h2>
<p>Zrozumienie gÅ‚Ä™bokiego uczenia wymaga znajomoÅ›ci wielu prostych pojÄ™Ä‡ matematycznych: tensorÃ³w, operacji na tensorach, rÃ³Å¼niczkowania, spadku gradientu itp. Naszym celem w tym rozdziale bÄ™dzie zbudowanie intuicji na temat tych pojÄ™Ä‡ bez nadmiernego zagÅ‚Ä™biania siÄ™ w technikÄ™. W szczegÃ³lnoÅ›ci, bÄ™dziemy unikaÄ‡ notacji matematycznej, ktÃ³ra moÅ¼e byÄ‡ draÅ¼niÄ…ca dla osÃ³b nieposiadajÄ…cych Å¼adnego wyksztaÅ‚cenia matematycznego, a nie jest niezbÄ™dna do dobrego wytÅ‚umaczenia.</p>
<p>Aby dodaÄ‡ trochÄ™ kontekstu dla tensorÃ³w i spadku gradientu, rozpoczniemy podrozdziaÅ‚ od praktycznego przykÅ‚adu sieci neuronowej. NastÄ™pnie przejdziemy przez kaÅ¼de nowe pojÄ™cie, ktÃ³re zostaÅ‚o wprowadzone, punkt po punkcie. PamiÄ™tajmy, Å¼e pojÄ™cia te bÄ™dÄ… niezbÄ™dne do zrozumienia praktycznych przykÅ‚adÃ³w, ktÃ³re pojawiÄ… siÄ™ w kolejnych rozdziaÅ‚ach!</p>
<p>Przyjrzyjmy siÄ™ konkretnemu przykÅ‚adowi sieci neuronowej, ktÃ³ra wykorzystuje pakiet <code>keras</code> do nauki klasyfikacji rÄ™cznie pisanych cyfr.</p>
<div class="cell">
<details open="" class="code-fold"><summary>Kod</summary><div class="sourceCode" id="cb1"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://tensorflow.rstudio.com/">keras</a></span><span class="op">)</span></span></code><button title="Kopiuj do schowka" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>Problemem, ktÃ³ry postaramy siÄ™ rozwiÄ…zaÄ‡ jest klasyfikacja obrazÃ³w pisma rÄ™cznego w skali szaroÅ›ci (28 pikseli na 28 pikseli) do 10 kategorii (od 0 do 9). UÅ¼yjemy zestawu danych MNIST, klasycznego zestawu danych w spoÅ‚ecznoÅ›ci ML, ktÃ³ry istnieje prawie tak dÅ‚ugo jak sama dziedzina i jest intensywnie badany. Jest to zestaw 60 000 obrazÃ³w treningowych oraz 10 000 obrazÃ³w testowych, zebranych przez National Institute of Standards and Technology (NIST w MNIST) w latach 80. MoÅ¼emy myÅ›leÄ‡ o â€œrozwiÄ…zywaniuâ€ MNIST jako o â€œHello Worldâ€ gÅ‚Ä™bokiego uczenia - to jest to, co robimy, aby zweryfikowaÄ‡, Å¼e nasze algorytmy dziaÅ‚ajÄ… zgodnie z oczekiwaniami. Gdy staniemy siÄ™ praktykami uczenia maszynowego, zobaczymy, Å¼e MNIST pojawia siÄ™ raz za razem, w pracach naukowych, wpisach na blogach i tak dalej. Kilka prÃ³bek MNIST moÅ¼na zobaczyÄ‡ na <a href="#fig-mnist1" class="quarto-xref">Rysunek&nbsp;<span>10.7</span></a>.</p>
<div id="fig-mnist1" class="quarto-figure quarto-figure-center quarto-float anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure"><div aria-describedby="fig-mnist1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="images/Zrzut ekranu 2023-02-24 o 17.57.00.png" class="img-fluid quarto-figure quarto-figure-center figure-img" width="600">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-mnist1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Rysunek&nbsp;10.7: Kilka przykÅ‚adÃ³w obrazÃ³w ze zbioru MNIST
</figcaption></figure>
</div>
<div class="callout callout-style-default callout-caution callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
ZagroÅ¼enie
</div>
</div>
<div class="callout-body-container callout-body">
<p>W uczeniu maszynowym kategoria w problemie klasyfikacyjnym nazywana jest klasÄ…. Punkty danych sÄ… nazywane prÃ³bkami. Klasa zwiÄ…zana z konkretnÄ… prÃ³bkÄ… nazywana jest etykietÄ… (ang. <em>label</em>).</p>
</div>
</div>
<p>ZbiÃ³r danych MNIST jest wstÄ™pnie zaÅ‚adowany do <code>keras</code> w postaci list <code>train</code> i <code>test</code>, z ktÃ³rych kaÅ¼da zawiera zestaw obrazÃ³w (x) i zwiÄ…zanych z nimi etykiet (y):</p>
<div class="cell">
<details open="" class="code-fold"><summary>Kod</summary><div class="sourceCode" id="cb2"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">mnist</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/keras/man/dataset_mnist.html">dataset_mnist</a></span><span class="op">(</span><span class="op">)</span></span>
<span><span class="va">train_images</span> <span class="op">&lt;-</span> <span class="va">mnist</span><span class="op">$</span><span class="va">train</span><span class="op">$</span><span class="va">x</span></span>
<span><span class="va">train_labels</span> <span class="op">&lt;-</span> <span class="va">mnist</span><span class="op">$</span><span class="va">train</span><span class="op">$</span><span class="va">y</span></span>
<span><span class="va">test_images</span> <span class="op">&lt;-</span> <span class="va">mnist</span><span class="op">$</span><span class="va">test</span><span class="op">$</span><span class="va">x</span></span>
<span><span class="va">test_labels</span> <span class="op">&lt;-</span> <span class="va">mnist</span><span class="op">$</span><span class="va">test</span><span class="op">$</span><span class="va">y</span></span></code><button title="Kopiuj do schowka" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p><code>train_images</code> i <code>train_labels</code> tworzÄ… zbiÃ³r treningowy, czyli dane, na podstawie ktÃ³rych model bÄ™dzie siÄ™ uczyÅ‚. Model bÄ™dzie nastÄ™pnie testowany na zbiorze testowym, <code>test_images</code> i <code>test_labels</code> . Obrazy sÄ… zakodowane jako tablice 3D, a etykiety to tablica 1D z cyframi od 0 do 9. PomiÄ™dzy obrazami i etykietami istnieje korespondencja jeden do jednego.</p>
<div class="cell">
<details open="" class="code-fold"><summary>Kod</summary><div class="sourceCode" id="cb3"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/utils/str.html">str</a></span><span class="op">(</span><span class="va">train_images</span><span class="op">)</span></span></code><button title="Kopiuj do schowka" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code> int [1:60000, 1:28, 1:28] 0 0 0 0 0 0 0 0 0 0 ...</code></pre>
</div>
<details open="" class="code-fold"><summary>Kod</summary><div class="sourceCode" id="cb5"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/utils/str.html">str</a></span><span class="op">(</span><span class="va">train_labels</span><span class="op">)</span></span></code><button title="Kopiuj do schowka" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code> int [1:60000(1d)] 5 0 4 1 9 2 1 3 1 4 ...</code></pre>
</div>
<details open="" class="code-fold"><summary>Kod</summary><div class="sourceCode" id="cb7"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/utils/str.html">str</a></span><span class="op">(</span><span class="va">test_images</span><span class="op">)</span></span></code><button title="Kopiuj do schowka" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code> int [1:10000, 1:28, 1:28] 0 0 0 0 0 0 0 0 0 0 ...</code></pre>
</div>
<details open="" class="code-fold"><summary>Kod</summary><div class="sourceCode" id="cb9"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/utils/str.html">str</a></span><span class="op">(</span><span class="va">test_labels</span><span class="op">)</span></span></code><button title="Kopiuj do schowka" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code> int [1:10000(1d)] 7 2 1 0 4 1 4 9 5 9 ...</code></pre>
</div>
</div>
<p>PrzepÅ‚yw pracy (ang. <em>workflow</em>) bÄ™dzie nastÄ™pujÄ…cy: najpierw podamy sieci neuronowej dane treningowe, <code>train_images</code> i <code>train_labels</code>. NastÄ™pnie sieÄ‡ nauczy siÄ™ kojarzyÄ‡ obrazy i etykiety. Na koniec poprosimy sieÄ‡ o stworzenie przewidywaÅ„ dla <code>test_images</code> i sprawdzimy, czy te przewidywania pasujÄ… do etykiet z <code>test_labels</code>.</p>
<div class="cell">
<details open="" class="code-fold"><summary>Kod</summary><div class="sourceCode" id="cb11"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">network</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/keras/man/keras_model_sequential.html">keras_model_sequential</a></span><span class="op">(</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://rdrr.io/pkg/keras/man/layer_dense.html">layer_dense</a></span><span class="op">(</span>units <span class="op">=</span> <span class="fl">512</span>, activation <span class="op">=</span> <span class="st">"relu"</span>, input_shape <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">28</span> <span class="op">*</span> <span class="fl">28</span><span class="op">)</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://rdrr.io/pkg/keras/man/layer_dense.html">layer_dense</a></span><span class="op">(</span>units <span class="op">=</span> <span class="fl">10</span>, activation <span class="op">=</span> <span class="st">"softmax"</span><span class="op">)</span></span></code><button title="Kopiuj do schowka" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>Podstawowym elementem konstrukcyjnym sieci neuronowych jest warstwa, moduÅ‚ przetwarzania danych, o ktÃ³rym moÅ¼na myÅ›leÄ‡ jak o filtrze dla danych. NiektÃ³re dane przychodzÄ… i wychodzÄ… w bardziej uÅ¼ytecznej formie. W szczegÃ³lnoÅ›ci, warstwy wyodrÄ™bniajÄ… reprezentacje z danych, ktÃ³re sÄ… do nich wprowadzane - miejmy nadziejÄ™, Å¼e reprezentacje, ktÃ³re sÄ… bardziej znaczÄ…ce dla danego problemu. WiÄ™kszoÅ›Ä‡ gÅ‚Ä™bokiego uczenia polega na Å‚Ä…czeniu prostych warstw, ktÃ³re implementujÄ… formÄ™ stopniowej destylacji danych. Model gÅ‚Ä™bokiego uczenia jest jak sito do przetwarzania danych, zÅ‚oÅ¼one z szeregu coraz bardziej wyrafinowanych filtrÃ³w danych - warstw.</p>
<div class="quarto-figure quarto-figure-center page-columns page-full">
<figure class="figure page-columns page-full"><div class="page-columns page-full"><p></p><div class="no-row-height column-margin column-container"><img src="images/tw3.jpeg" class="img-fluid quarto-figure quarto-figure-center figure-img" width="400"></div></div>
</figure>
</div>
<p>Nasza sieÄ‡ skÅ‚ada siÄ™ z dwÃ³ch warstw, ktÃ³re sÄ… gÄ™sto poÅ‚Ä…czonymi (zwanymi teÅ¼ w peÅ‚ni poÅ‚Ä…czonymi - ang. <em>fully connected</em>) warstwami neuronowymi. Druga (i ostatnia) warstwa jest 10-kierunkowÄ… warstwÄ… softmax, co oznacza, Å¼e zwrÃ³ci tablicÄ™ 10 wynikÃ³w prawdopodobieÅ„stwa (sumujÄ…cych siÄ™ do 1). KaÅ¼dy wynik bÄ™dzie oznaczaÅ‚ prawdopodobieÅ„stwo, Å¼e aktualny obraz cyfry naleÅ¼y do jednej z naszych 10 klas cyfr.</p>
<p>Aby sieÄ‡ byÅ‚a gotowa do treningu, musimy wybraÄ‡ jeszcze trzy rzeczy, w ramach kroku kompilacji:</p>
<ul>
<li>FunkcjÄ™ straty - jak sieÄ‡ bÄ™dzie w stanie zmierzyÄ‡, jak dobrÄ… pracÄ™ wykonuje na danych treningowych, a tym samym czy bÄ™dzie w stanie kierowaÄ‡ siÄ™ we wÅ‚aÅ›ciwym kierunku.</li>
<li>Optymalizator - mechanizm, dziÄ™ki ktÃ³remu sieÄ‡ bÄ™dzie siÄ™ aktualizowaÄ‡ w oparciu o dane, ktÃ³re widzi i swojÄ… funkcjÄ™ straty.</li>
<li>Metryki, ktÃ³re naleÅ¼y monitorowaÄ‡ podczas treningu i testÃ³w - tutaj zajmiemy siÄ™ tylko dokÅ‚adnoÅ›ciÄ… (frakcjÄ… obrazÃ³w, ktÃ³re zostaÅ‚y poprawnie sklasyfikowane - ang. <em>accuracy</em>).</li>
</ul>
<p>DokÅ‚adne przeznaczenie funkcji straty i optymalizatora zostanie wyjaÅ›nione w kolejnych rozdziaÅ‚ach.</p>
<div class="cell">
<details open="" class="code-fold"><summary>Kod</summary><div class="sourceCode" id="cb12"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">network</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> <span class="fu"><a href="https://generics.r-lib.org/reference/compile.html">compile</a></span><span class="op">(</span></span>
<span>  optimizer <span class="op">=</span> <span class="st">"rmsprop"</span>,</span>
<span>  loss <span class="op">=</span> <span class="st">"categorical_crossentropy"</span>,</span>
<span>  metrics <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"accuracy"</span><span class="op">)</span></span>
<span><span class="op">)</span></span></code><button title="Kopiuj do schowka" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>ZauwaÅ¼my, Å¼e funkcja <code><a href="https://generics.r-lib.org/reference/compile.html">compile()</a></code> modyfikuje sieÄ‡ na bieÅ¼Ä…co (zamiast zwracaÄ‡ nowy obiekt sieci, co jest bardziej typowe dla R). PowÃ³d tego opiszemy, gdy powrÃ³cimy do przykÅ‚adu w dalszej czÄ™Å›ci rozdziaÅ‚u.</p>
<p>Przed treningiem wstÄ™pnie przetworzymy dane, zmieniajÄ…c ich ksztaÅ‚t na taki, jakiego oczekuje sieÄ‡, i skalujÄ…c je tak, by wszystkie wartoÅ›ci mieÅ›ciÅ‚y siÄ™ w przedziale [0, 1]. Poprzednio nasze obrazy treningowe, na przykÅ‚ad, byÅ‚y przechowywane w tablicy o ksztaÅ‚cie <code>(60000, 28, 28)</code> typu <code>integer</code> z wartoÅ›ciami w przedziale [0, 255]. PrzeksztaÅ‚camy go w podwÃ³jnÄ… tablicÄ™ ksztaÅ‚tu <code>(60000, 28 * 28)</code> z wartoÅ›ciami w przedziale [0,1].</p>
<div class="cell">
<details open="" class="code-fold"><summary>Kod</summary><div class="sourceCode" id="cb13"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">train_images</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rstudio.github.io/reticulate/reference/array_reshape.html">array_reshape</a></span><span class="op">(</span><span class="va">train_images</span>, <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">60000</span>, <span class="fl">28</span> <span class="op">*</span> <span class="fl">28</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">train_images</span> <span class="op">&lt;-</span> <span class="va">train_images</span> <span class="op">/</span> <span class="fl">255</span></span>
<span><span class="va">test_images</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rstudio.github.io/reticulate/reference/array_reshape.html">array_reshape</a></span><span class="op">(</span><span class="va">test_images</span>, <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">10000</span>, <span class="fl">28</span> <span class="op">*</span> <span class="fl">28</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">test_images</span> <span class="op">&lt;-</span> <span class="va">test_images</span> <span class="op">/</span> <span class="fl">255</span></span></code><button title="Kopiuj do schowka" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>ZauwaÅ¼my, Å¼e uÅ¼ywamy funkcji <code><a href="https://rstudio.github.io/reticulate/reference/array_reshape.html">array_reshape()</a></code> zamiast funkcji <code><a href="https://rdrr.io/r/base/dim.html">dim()</a></code> do zmiany ksztaÅ‚tu tablicy. PowÃ³d tego omÃ³wimy pÃ³Åºniej, kiedy bÄ™dziemy mÃ³wiÄ‡ o przeksztaÅ‚caniu tensorÃ³w. Musimy rÃ³wnieÅ¼ zakodowaÄ‡ etykiety w sposÃ³b kategoryczny.</p>
<div class="cell">
<details open="" class="code-fold"><summary>Kod</summary><div class="sourceCode" id="cb14"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">train_labels</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/keras/man/to_categorical.html">to_categorical</a></span><span class="op">(</span><span class="va">train_labels</span><span class="op">)</span></span>
<span><span class="va">test_labels</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/keras/man/to_categorical.html">to_categorical</a></span><span class="op">(</span><span class="va">test_labels</span><span class="op">)</span></span></code><button title="Kopiuj do schowka" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>Teraz jesteÅ›my gotowi do trenowania sieci, co w <code>keras</code> odbywa siÄ™ poprzez wywoÅ‚anie metody <code>fit</code> sieci - dopasowujemy model do danych treningowych:</p>
<div class="cell">
<details open="" class="code-fold"><summary>Kod</summary><div class="sourceCode" id="cb15"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">network</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> <span class="fu"><a href="https://generics.r-lib.org/reference/fit.html">fit</a></span><span class="op">(</span><span class="va">train_images</span>, <span class="va">train_labels</span>, epochs <span class="op">=</span> <span class="fl">5</span>, batch_size <span class="op">=</span> <span class="fl">128</span><span class="op">)</span></span></code><button title="Kopiuj do schowka" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>Epoch 1/5
469/469 - 5s - loss: 0.3841 - accuracy: 0.8905 - 5s/epoch - 10ms/step
Epoch 2/5
469/469 - 4s - loss: 0.3199 - accuracy: 0.9111 - 4s/epoch - 9ms/step
Epoch 3/5
469/469 - 4s - loss: 0.3226 - accuracy: 0.9121 - 4s/epoch - 8ms/step
Epoch 4/5
469/469 - 4s - loss: 0.3354 - accuracy: 0.9092 - 4s/epoch - 8ms/step
Epoch 5/5
469/469 - 4s - loss: 0.3483 - accuracy: 0.9089 - 4s/epoch - 8ms/step</code></pre>
</div>
</div>
<p>Podczas treningu wyÅ›wietlane sÄ… dwie wielkoÅ›ci: strata sieci na danych treningowych oraz dokÅ‚adnoÅ›Ä‡ sieci na danych treningowych. Szybko osiÄ…gamy dokÅ‚adnoÅ›Ä‡ 0,989 (98,9%) na danych treningowych. Teraz sprawdÅºmy, czy model dobrze radzi sobie rÃ³wnieÅ¼ na zbiorze testowym:</p>
<div class="cell">
<details open="" class="code-fold"><summary>Kod</summary><div class="sourceCode" id="cb17"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">metrics</span> <span class="op">&lt;-</span> <span class="va">network</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> <span class="fu"><a href="https://rdrr.io/pkg/tensorflow/man/evaluate.html">evaluate</a></span><span class="op">(</span><span class="va">test_images</span>, <span class="va">test_labels</span><span class="op">)</span></span></code><button title="Kopiuj do schowka" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>313/313 - 2s - loss: 0.3424 - accuracy: 0.9104 - 2s/epoch - 6ms/step</code></pre>
</div>
<details open="" class="code-fold"><summary>Kod</summary><div class="sourceCode" id="cb19"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">metrics</span></span></code><button title="Kopiuj do schowka" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>     loss  accuracy 
0.3424286 0.9104000 </code></pre>
</div>
</div>
<p>DokÅ‚adnoÅ›Ä‡ zestawu testowego okazuje siÄ™ wynosiÄ‡ 97,8% - to sporo mniej niÅ¼ dokÅ‚adnoÅ›Ä‡ zestawu treningowego. Ta rÃ³Å¼nica miÄ™dzy dokÅ‚adnoÅ›ciÄ… treningu a dokÅ‚adnoÅ›ciÄ… testu jest przykÅ‚adem nadmiernego dopasowania (fakt, Å¼e modele uczenia maszynowego majÄ… tendencjÄ™ do osiÄ…gania gorszych wynikÃ³w na nowych danych niÅ¼ na danych treningowych). Wygenerujmy przewidywania dla pierwszych 10 prÃ³bek zbioru testowego:</p>
<div class="cell">
<details open="" class="code-fold"><summary>Kod</summary><div class="sourceCode" id="cb21"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">network</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span><span class="op">(</span><span class="va">test_images</span><span class="op">[</span><span class="fl">1</span><span class="op">:</span><span class="fl">10</span>,<span class="op">]</span><span class="op">)</span> <span class="op">|&gt;</span> <span class="fu"><a href="https://rdrr.io/pkg/keras/man/k_argmax.html">k_argmax</a></span><span class="op">(</span><span class="op">)</span></span></code><button title="Kopiuj do schowka" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>1/1 - 0s - 165ms/epoch - 165ms/step</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>tf.Tensor([7 2 1 0 4 1 4 9 6 9], shape=(10), dtype=int64)</code></pre>
</div>
</div>
<p>Na tym koÅ„czymy nasz pierwszy przykÅ‚ad - wÅ‚aÅ›nie zobaczyliÅ›my, jak moÅ¼na zbudowaÄ‡ i wytrenowaÄ‡ sieÄ‡ neuronowÄ… do klasyfikacji pisma rÄ™cznego w mniej niÅ¼ 20 liniach kodu R. W nastÄ™pnym rozdziale omÃ³wimy szczegÃ³Å‚owo kaÅ¼dy element, ktÃ³ry uÅ¼yliÅ›my i wyjaÅ›nimy, co on robi. Dowiemy siÄ™ o tensorach, obiektach przechowujÄ…cych dane w sieci; o operacjach na tensorach, z ktÃ³rych skÅ‚adajÄ… siÄ™ warstwy oraz o spadku gradientu, ktÃ³ry pozwala sieci uczyÄ‡ siÄ™ na przykÅ‚adach treningowych.</p>
<section id="operacje-na-danych" class="level3 page-columns page-full" data-number="10.4.1"><h3 data-number="10.4.1" class="anchored" data-anchor-id="operacje-na-danych">
<span class="header-section-number">10.4.1</span> Operacje na danych</h3>
<p>W poprzednim przykÅ‚adzie zaczynaliÅ›my od danych przechowywanych w wielowymiarowych tablicach, zwanych rÃ³wnieÅ¼ tensorami. Wszystkie obecne systemy uczenia maszynowego uÅ¼ywajÄ… tensorÃ³w jako podstawowej struktury danych. Tensory sÄ… fundamentalne dla tej dziedziny - tak fundamentalne, Å¼e Googleâ€™s TensorFlow zostaÅ‚ nazwany na ich czeÅ›Ä‡. Czym wiÄ™c jest tensor?</p>
<p>Tensory sÄ… uogÃ³lnieniem wektorÃ³w i macierzy na dowolnÄ… liczbÄ™ wymiarÃ³w (zauwaÅ¼my, Å¼e w kontekÅ›cie tensorÃ³w â€œwymiarâ€ jest czÄ™sto nazywany â€œosiÄ…â€). W R wektory sÄ… uÅ¼ywane do tworzenia i manipulowania tensorami 1D, a macierze sÄ… uÅ¼ywane do tensorÃ³w 2D. Dla wymiarÃ³w wyÅ¼szego rzÄ™du uÅ¼ywane sÄ… obiekty tablicowe<a href="#fn5" class="footnote-ref" id="fnref5" role="doc-noteref"><sup>5</sup></a> (ktÃ³re obsÅ‚ugujÄ… dowolnÄ… liczbÄ™ wymiarÃ³w).</p>
<div class="no-row-height column-margin column-container"><p><sup>5</sup>&nbsp;ang. <em>array</em></p></div><section id="skalary" class="level4" data-number="10.4.1.1"><h4 data-number="10.4.1.1" class="anchored" data-anchor-id="skalary">
<span class="header-section-number">10.4.1.1</span> Skalary</h4>
<p>Tensor, ktÃ³ry zawiera tylko jednÄ… liczbÄ™ nazywany jest skalarem (lub tensorem skalarnym, lub tensorem 0-wymiarowym, lub tensorem 0D). ChociaÅ¼ R nie ma typu danych do reprezentowania skalarÃ³w (wszystkie obiekty numeryczne sÄ… wektorami, macierzami lub tablicami), wektor R, ktÃ³ry ma zawsze dÅ‚ugoÅ›Ä‡ 1, jest koncepcyjnie podobny do skalara.</p>
</section><section id="wektory" class="level4" data-number="10.4.1.2"><h4 data-number="10.4.1.2" class="anchored" data-anchor-id="wektory">
<span class="header-section-number">10.4.1.2</span> Wektory</h4>
<p>Jednowymiarowa tablica liczb nazywana jest wektorem lub tensorem 1D. MÃ³wi siÄ™, Å¼e tensor 1D ma dokÅ‚adnie jednÄ… oÅ›. MoÅ¼emy przekonwertowaÄ‡ wektor R na obiekt tablicowy (<code>array</code>), aby sprawdziÄ‡ jego wymiary:</p>
<div class="cell">
<details open="" class="code-fold"><summary>Kod</summary><div class="sourceCode" id="cb24"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">x</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">12</span>, <span class="fl">3</span>, <span class="fl">6</span>, <span class="fl">14</span>, <span class="fl">10</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/str.html">str</a></span><span class="op">(</span><span class="va">x</span><span class="op">)</span></span></code><button title="Kopiuj do schowka" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code> num [1:5] 12 3 6 14 10</code></pre>
</div>
<details open="" class="code-fold"><summary>Kod</summary><div class="sourceCode" id="cb26"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/dim.html">dim</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/array.html">as.array</a></span><span class="op">(</span><span class="va">x</span><span class="op">)</span><span class="op">)</span></span></code><button title="Kopiuj do schowka" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>[1] 5</code></pre>
</div>
</div>
<p>Wektor ten ma piÄ™Ä‡ wpisÃ³w i dlatego nazywany jest wektorem 5-wymiarowym. Nie naleÅ¼y myliÄ‡ wektora 5D z tensorem 5D! Wektor 5D ma tylko jednÄ… oÅ› i ma piÄ™Ä‡ wymiarÃ³w wzdÅ‚uÅ¼ swojej osi, podczas gdy tensor 5D ma piÄ™Ä‡ osi (i moÅ¼e mieÄ‡ dowolnÄ… liczbÄ™ wymiarÃ³w wzdÅ‚uÅ¼ kaÅ¼dej osi). WymiarowoÅ›Ä‡ moÅ¼e oznaczaÄ‡ albo liczbÄ™ wpisÃ³w wzdÅ‚uÅ¼ konkretnej osi (jak w przypadku naszego wektora 5D), albo liczbÄ™ osi w tensorze (jak tensor 5D), co moÅ¼e byÄ‡ czasem mylÄ…ce. W tym drugim przypadku technicznie poprawniej jest mÃ³wiÄ‡ o tensorze rzÄ™du 5 (ranga tensora to liczba osi), ale niejednoznaczny zapis tensor 5D jest powszechny niezaleÅ¼nie od tego.</p>
</section><section id="macierze" class="level4" data-number="10.4.1.3"><h4 data-number="10.4.1.3" class="anchored" data-anchor-id="macierze">
<span class="header-section-number">10.4.1.3</span> Macierze</h4>
<p>Dwuwymiarowa tablica liczb to macierz, czyli tensor 2D. Macierz ma dwie osie (czÄ™sto nazywane wierszami i kolumnami). MoÅ¼esz wizualnie zinterpretowaÄ‡ macierz jako prostokÄ…tnÄ… siatkÄ™ liczb:</p>
<div class="cell">
<details open="" class="code-fold"><summary>Kod</summary><div class="sourceCode" id="cb28"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">x</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html">matrix</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">3</span><span class="op">*</span><span class="fl">5</span><span class="op">)</span>, nrow <span class="op">=</span> <span class="fl">3</span>, ncol <span class="op">=</span> <span class="fl">5</span><span class="op">)</span></span>
<span><span class="va">x</span></span></code><button title="Kopiuj do schowka" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>     [,1] [,2] [,3] [,4] [,5]
[1,]    0    0    0    0    0
[2,]    0    0    0    0    0
[3,]    0    0    0    0    0</code></pre>
</div>
<details open="" class="code-fold"><summary>Kod</summary><div class="sourceCode" id="cb30"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/dim.html">dim</a></span><span class="op">(</span><span class="va">x</span><span class="op">)</span></span></code><button title="Kopiuj do schowka" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>[1] 3 5</code></pre>
</div>
</div>
</section><section id="tensory" class="level4" data-number="10.4.1.4"><h4 data-number="10.4.1.4" class="anchored" data-anchor-id="tensory">
<span class="header-section-number">10.4.1.4</span> Tensory</h4>
<p>JeÅ›li spakujemy takie macierze do nowej tablicy, otrzymamy tensor 3D, ktÃ³ry moÅ¼emy wizualnie zinterpretowaÄ‡ jako szeÅ›cian liczb:</p>
<div class="cell">
<details open="" class="code-fold"><summary>Kod</summary><div class="sourceCode" id="cb32"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">x</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/array.html">array</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">2</span><span class="op">*</span><span class="fl">3</span><span class="op">*</span><span class="fl">2</span><span class="op">)</span>, dim <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">2</span>,<span class="fl">3</span>,<span class="fl">2</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/str.html">str</a></span><span class="op">(</span><span class="va">x</span><span class="op">)</span></span></code><button title="Kopiuj do schowka" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code> num [1:2, 1:3, 1:2] 0 0 0 0 0 0 0 0 0 0 ...</code></pre>
</div>
<details open="" class="code-fold"><summary>Kod</summary><div class="sourceCode" id="cb34"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/dim.html">dim</a></span><span class="op">(</span><span class="va">x</span><span class="op">)</span></span></code><button title="Kopiuj do schowka" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>[1] 2 3 2</code></pre>
</div>
</div>
<p>PakujÄ…c tensory 3D w tablicy, moÅ¼esz stworzyÄ‡ tensor 4D i tak dalej. W gÅ‚Ä™bokim uczeniu siÄ™, generalnie bÄ™dziesz manipulowaÄ‡ tensorami, ktÃ³re sÄ… 0D do 4D, a tensory 5D pojawiÄ… siÄ™, jeÅ›li bÄ™dziesz przetwarzaÄ‡ dane wideo.</p>
</section><section id="kluczowe-wÅ‚asnoÅ›ci" class="level4 page-columns page-full" data-number="10.4.1.5"><h4 data-number="10.4.1.5" class="anchored" data-anchor-id="kluczowe-wÅ‚asnoÅ›ci">
<span class="header-section-number">10.4.1.5</span> Kluczowe wÅ‚asnoÅ›ci</h4>
<p>Tensor jest okreÅ›lony przez trzy kluczowe atrybuty:</p>
<ul>
<li>Liczba osi - np. tensor 3D ma trzy osie, a macierz dwie osie.</li>
<li>KsztaÅ‚t - to wektor liczb caÅ‚kowitych, ktÃ³ry opisuje, ile wymiarÃ³w ma tensor wzdÅ‚uÅ¼ kaÅ¼dej osi. Na przykÅ‚ad poprzedni przykÅ‚ad macierzy ma ksztaÅ‚t (3, 5), a przykÅ‚ad tensora 3D ma ksztaÅ‚t (3, 3, 5). Wektor ma ksztaÅ‚t z pojedynczym elementem, o wymiarze 5. MoÅ¼esz sprawdziÄ‡ wymiary dowolnej tablicy za pomocÄ… funkcji <code><a href="https://rdrr.io/r/base/dim.html">dim()</a></code>.</li>
<li>Typ danych - typ danych zawartych w tensorze; na przykÅ‚ad, typem tensora moÅ¼e byÄ‡ liczba caÅ‚kowita lub rzeczywista<a href="#fn6" class="footnote-ref" id="fnref6" role="doc-noteref"><sup>6</sup></a>. W rzadkich przypadkach moÅ¼esz zobaczyÄ‡ tensor znakowy<a href="#fn7" class="footnote-ref" id="fnref7" role="doc-noteref"><sup>7</sup></a>. PoniewaÅ¼ jednak tensory Å¼yjÄ… we wstÄ™pnie przydzielonych segmentach pamiÄ™ci, a Å‚aÅ„cuchy znakÃ³w, bÄ™dÄ…c zmiennej dÅ‚ugoÅ›ci, wykluczyÅ‚yby uÅ¼ycie tej implementacji, sÄ… one rzadziej uÅ¼ywane.</li>
</ul>
<div class="no-row-height column-margin column-container"><p><sup>6</sup>&nbsp;float - czyli liczba rzeczywista</p><p><sup>7</sup>&nbsp;typu <code>character</code></p></div><p>Aby to skonkretyzowaÄ‡, spÃ³jrzmy na dane, ktÃ³re przetwarzaliÅ›my w przykÅ‚adzie MNIST. Najpierw Å‚adujemy zbiÃ³r danych MNIST:</p>
<div class="cell">
<details open="" class="code-fold"><summary>Kod</summary><div class="sourceCode" id="cb36"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">train_images</span> <span class="op">&lt;-</span> <span class="va">mnist</span><span class="op">$</span><span class="va">train</span><span class="op">$</span><span class="va">x</span></span>
<span><span class="va">train_labels</span> <span class="op">&lt;-</span> <span class="va">mnist</span><span class="op">$</span><span class="va">train</span><span class="op">$</span><span class="va">y</span></span>
<span><span class="va">test_images</span> <span class="op">&lt;-</span> <span class="va">mnist</span><span class="op">$</span><span class="va">test</span><span class="op">$</span><span class="va">x</span></span>
<span><span class="va">test_labels</span> <span class="op">&lt;-</span> <span class="va">mnist</span><span class="op">$</span><span class="va">test</span><span class="op">$</span><span class="va">y</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/length.html">length</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/dim.html">dim</a></span><span class="op">(</span><span class="va">train_images</span><span class="op">)</span><span class="op">)</span> <span class="co"># osie</span></span></code><button title="Kopiuj do schowka" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>[1] 3</code></pre>
</div>
<details open="" class="code-fold"><summary>Kod</summary><div class="sourceCode" id="cb38"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/dim.html">dim</a></span><span class="op">(</span><span class="va">train_images</span><span class="op">)</span> <span class="co"># ksztaÅ‚t</span></span></code><button title="Kopiuj do schowka" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>[1] 60000    28    28</code></pre>
</div>
<details open="" class="code-fold"><summary>Kod</summary><div class="sourceCode" id="cb40"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/typeof.html">typeof</a></span><span class="op">(</span><span class="va">train_images</span><span class="op">)</span> <span class="co"># typ danych</span></span></code><button title="Kopiuj do schowka" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>[1] "integer"</code></pre>
</div>
</div>
<p>Jak wiÄ™c widaÄ‡ jest to tensor 3D liczb caÅ‚kowitych. DokÅ‚adniej, jest to tablica 60000 macierzy 28 Ã— 28 liczb caÅ‚kowitych. KaÅ¼da taka macierz jest obrazem w skali szaroÅ›ci o wspÃ³Å‚czynnikach od 0 do 255. WykreÅ›lmy piÄ…tÄ… cyfrÄ™ w tym tensorze 3D:</p>
<div class="cell">
<details open="" class="code-fold"><summary>Kod</summary><div class="sourceCode" id="cb42"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">digit</span> <span class="op">&lt;-</span> <span class="va">train_images</span><span class="op">[</span><span class="fl">5</span>,,<span class="op">]</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/grDevices/as.raster.html">as.raster</a></span><span class="op">(</span><span class="va">digit</span>, max <span class="op">=</span> <span class="fl">255</span><span class="op">)</span><span class="op">)</span></span></code><button title="Kopiuj do schowka" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output-display">
<div>
<figure class="figure"><p><img src="deeplearning_files/figure-html/unnamed-chunk-15-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
</section><section id="operacje-na-tensorach" class="level4 page-columns page-full" data-number="10.4.1.6"><h4 data-number="10.4.1.6" class="anchored" data-anchor-id="operacje-na-tensorach">
<span class="header-section-number">10.4.1.6</span> Operacje na tensorach</h4>
<p>W poprzednim przykÅ‚adzie wybraliÅ›my konkretnÄ… cyfrÄ™ wzdÅ‚uÅ¼ pierwszej osi za pomocÄ… skÅ‚adni <code>train_images[i,,]</code>. Wybieranie konkretnych elementÃ³w w tensorze nazywa siÄ™ <em>tensor slicing</em>. Przyjrzyjmy siÄ™ operacjom <em>tensor slicing</em>, ktÃ³re moÅ¼na wykonaÄ‡ na tablicach R. PoniÅ¼ej wybrano cyfry od #10 do #99 i umieszczono je w tablicy o ksztaÅ‚cie <code>(90, 28, 28)</code>:</p>
<div class="cell">
<details open="" class="code-fold"><summary>Kod</summary><div class="sourceCode" id="cb43"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">my_slice</span> <span class="op">&lt;-</span> <span class="va">train_images</span><span class="op">[</span><span class="fl">10</span><span class="op">:</span><span class="fl">99</span>,,<span class="op">]</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/dim.html">dim</a></span><span class="op">(</span><span class="va">my_slice</span><span class="op">)</span></span></code><button title="Kopiuj do schowka" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>[1] 90 28 28</code></pre>
</div>
</div>
<p>Generalnie, moÅ¼emy wybraÄ‡ pomiÄ™dzy dwoma dowolnymi indeksami wzdÅ‚uÅ¼ kaÅ¼dej osi tensora. Na przykÅ‚ad, aby wybraÄ‡ 14 Ã— 14 pikseli w prawym dolnym rogu wszystkich obrazÃ³w, uÅ¼yjemy:</p>
<div class="cell">
<details open="" class="code-fold"><summary>Kod</summary><div class="sourceCode" id="cb45"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">my_slice</span> <span class="op">&lt;-</span> <span class="va">train_images</span><span class="op">[</span>, <span class="fl">15</span><span class="op">:</span><span class="fl">28</span>, <span class="fl">15</span><span class="op">:</span><span class="fl">28</span><span class="op">]</span></span></code><button title="Kopiuj do schowka" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>Generalnie, pierwszÄ… osiÄ… we wszystkich tensorach danych, z ktÃ³rymi zetkniemy siÄ™ w gÅ‚Ä™bokim uczeniu, bÄ™dzie oÅ› prÃ³bek (czasami nazywana wymiarem prÃ³bek). W przykÅ‚adzie MNIST, prÃ³bki to obrazy cyfr. Ponadto, modele gÅ‚Ä™bokiego uczenia nie przetwarzajÄ… caÅ‚ego zbioru danych na raz, ale raczej dzielÄ… dane na maÅ‚e partie (ang. <em>batch</em>). Konkretnie, oto jedna partia naszych cyfr MNIST, o rozmiarze partii 128:</p>
<div class="cell">
<details open="" class="code-fold"><summary>Kod</summary><div class="sourceCode" id="cb46"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">batch</span> <span class="op">&lt;-</span> <span class="va">train_images</span><span class="op">[</span><span class="fl">1</span><span class="op">:</span><span class="fl">128</span>,,<span class="op">]</span></span></code><button title="Kopiuj do schowka" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>Gdy rozwaÅ¼amy tensor partii, pierwsza oÅ› nazywana jest osiÄ… partii lub wymiarem partii. Jest to termin, ktÃ³ry czÄ™sto spotkamy podczas korzystania z <code>keras</code> i innych bibliotek uczenia gÅ‚Ä™bokiego.</p>
<p>UÅ›ciÅ›lijmy tensory danych za pomocÄ… kilku przykÅ‚adÃ³w podobnych do tego, co napotkamy pÃ³Åºniej. Dane, ktÃ³rymi bÄ™dziemy manipulowaÄ‡, prawie zawsze bÄ™dÄ… naleÅ¼aÅ‚y do jednej z nastÄ™pujÄ…cych kategorii:</p>
<ul>
<li>Dane wektorowe-2D tensory ksztaÅ‚tu (prÃ³bki, cechy);</li>
<li>Dane czasowe lub dane sekwencyjne-3D tensory ksztaÅ‚tu (prÃ³bki, kroki czasowe, cechy);</li>
<li>Obrazy-4D tensory ksztaÅ‚tu (prÃ³bki, wysokoÅ›Ä‡, szerokoÅ›Ä‡, kanaÅ‚y) lub (prÃ³bki, kanaÅ‚y, wysokoÅ›Ä‡, szerokoÅ›Ä‡);</li>
<li>Wideo-5D tensory ksztaÅ‚tu (prÃ³bki, klatki, wysokoÅ›Ä‡, szerokoÅ›Ä‡, kanaÅ‚y) lub (prÃ³bki, klatki, kanaÅ‚y, wysokoÅ›Ä‡, szerokoÅ›Ä‡).</li>
</ul>
<p>Dane wektorowe sÄ… najczÄ™Å›ciej spotykanym przykÅ‚adem formatu danych. W takim zbiorze danych kaÅ¼dy pojedynczy punkt danych moÅ¼e byÄ‡ zakodowany jako wektor, a wiÄ™c partia danych bÄ™dzie zakodowana jako tensor 2D (czyli tablica wektorÃ³w), gdzie pierwsza oÅ› jest osiÄ… prÃ³bek, a druga osiÄ… cech. Przyjrzyjmy siÄ™ dwÃ³m przykÅ‚adom:</p>
<ul>
<li>Aktuarialny zbiÃ³r danych osÃ³b, gdzie rozpatrujemy wiek, kod i dochÃ³d kaÅ¼dej osoby. KaÅ¼da osoba moÅ¼e byÄ‡ scharakteryzowana jako wektor 3 wartoÅ›ci, a zatem caÅ‚y zbiÃ³r danych 100000 osÃ³b moÅ¼e byÄ‡ przechowywany w tensorze 2D o ksztaÅ‚cie <code>(100000, 3)</code>.</li>
<li>ZbiÃ³r dokumentÃ³w tekstowych, gdzie kaÅ¼dy dokument reprezentujemy poprzez zliczanie ile razy pojawia siÄ™ w nim kaÅ¼de sÅ‚owo (ze sÅ‚ownika 20000 sÅ‚Ã³w). KaÅ¼dy dokument moÅ¼na zakodowaÄ‡ jako wektor 20000 wartoÅ›ci (po jednym zliczeniu na sÅ‚owo w sÅ‚owniku), a zatem caÅ‚y zbiÃ³r 500 dokumentÃ³w moÅ¼na zapisaÄ‡ w tensorze ksztaÅ‚tu <code>(500, 20000)</code>.</li>
</ul>
<p>Gdy w danych waÅ¼ny staje siÄ™ czas (lub kolejnoÅ›Ä‡ sekwencji), sensowne jest przechowywanie ich w tensorze 3D z wyraÅºnÄ… osiÄ… czasu. KaÅ¼da prÃ³bka moÅ¼e byÄ‡ zakodowana jako ciÄ…g wektorÃ³w (tensor 2D), a zatem partia danych bÄ™dzie zakodowana jako tensor 3D (patrz <a href="#fig-tensor1" class="quarto-xref">Rysunek&nbsp;<span>10.8</span></a>).</p>
<div id="fig-tensor1" class="quarto-figure quarto-figure-center quarto-float anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure"><div aria-describedby="fig-tensor1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="images/Zrzut ekranu 2023-02-24 o 18.59.47.png" class="img-fluid quarto-figure quarto-figure-center figure-img" width="400">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-tensor1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Rysunek&nbsp;10.8: Schemat zapisu danych sekwencyjnych
</figcaption></figure>
</div>
<p>OÅ› czasu jest zawsze drugÄ… osiÄ…, zgodnie z konwencjÄ…. Przyjrzyjmy siÄ™ kilku przykÅ‚adom:</p>
<ul>
<li>ZbiÃ³r danych o cenach akcji. Co minutÄ™ zapisujemy aktualnÄ… cenÄ™ akcji, najwyÅ¼szÄ… cenÄ™ w danej minucie oraz najniÅ¼szÄ… cenÄ™ w danej minucie. Tak wiÄ™c kaÅ¼da minuta jest zakodowana jako wektor 3D, caÅ‚y dzieÅ„ handlu jest zakodowany jako tensor 2D o ksztaÅ‚cie <code>(390, 3)</code> (jest 390 minut w dniu handlu), a 250 dni danych moÅ¼e byÄ‡ przechowywanych w tensorze 3D o ksztaÅ‚cie <code>(250, 390, 3)</code>. W tym przypadku kaÅ¼da prÃ³bka to jeden dzieÅ„ danych.</li>
<li>ZbiÃ³r danych tweetÃ³w, gdzie kaÅ¼dy tweet kodujemy jako ciÄ…g 140 znakÃ³w z alfabetu 128 unikalnych znakÃ³w. W tym ustawieniu kaÅ¼dy znak moÅ¼e byÄ‡ zakodowany jako wektor binarny o rozmiarze 128 (wektor wszystkich zer, z wyjÄ…tkiem wpisu 1 w indeksie odpowiadajÄ…cym znakowi). NastÄ™pnie kaÅ¼dy tweet moÅ¼e byÄ‡ zakodowany jako tensor 2D o ksztaÅ‚cie <code>(140, 128)</code>, a zbiÃ³r danych 1 miliona tweetÃ³w moÅ¼e byÄ‡ przechowywany w tensorze o ksztaÅ‚cie <code>(1000000, 140, 128)</code>.</li>
</ul>
<p>Obrazy majÄ… zazwyczaj trzy wymiary: wysokoÅ›Ä‡, szerokoÅ›Ä‡ i gÅ‚Ä™biÄ™ koloru. ChoÄ‡ obrazy w skali szaroÅ›ci (jak nasze cyfry MNIST) majÄ… tylko jeden kanaÅ‚ koloru i mogÅ‚yby byÄ‡ przechowywane w tensorach 2D, to konwencjonalnie tensory obrazÃ³w sÄ… zawsze trÃ³jwymiarowe, z jednowymiarowym kanaÅ‚em koloru dla obrazÃ³w w skali szaroÅ›ci. Partia 128 obrazÃ³w w skali szaroÅ›ci o rozmiarach 256 Ã— 256 mogÅ‚aby wiÄ™c byÄ‡ przechowywana w tensorze o ksztaÅ‚cie <code>(128, 256, 256, 1)</code>, a partia 128 obrazÃ³w kolorowych - w tensorze o ksztaÅ‚cie <code>(128, 256, 256, 3)</code> (patrz <a href="#fig-tensor2" class="quarto-xref">Rysunek&nbsp;<span>10.9</span></a>).</p>
<div id="fig-tensor2" class="quarto-figure quarto-figure-center quarto-float anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure"><div aria-describedby="fig-tensor2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="images/Zrzut ekranu 2023-02-24 o 19.04.18.png" class="img-fluid quarto-figure quarto-figure-center figure-img" width="400">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-tensor2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Rysunek&nbsp;10.9: Zapis kolorowego obrazu
</figcaption></figure>
</div>
<p>IstniejÄ… dwie konwencje dla ksztaÅ‚tÃ³w tensorÃ³w obrazÃ³w: konwencja <em>channels-last</em> (uÅ¼ywana przez TensorFlow) i konwencja <em>channels-firs</em>t (uÅ¼ywana przez Theano). Framework uczenia maszynowego TensorFlow, od Google, umieszcza oÅ› gÅ‚Ä™bokoÅ›ci koloru na koÅ„cu: <code>(sample, height, width, color_depth)</code>. Tymczasem Theano umieszcza oÅ› gÅ‚Ä™bi koloru zaraz po osi partii: <code>(sample, color_depth, height, width)</code>. Keras zapewniajÄ… wsparcie dla obu formatÃ³w.</p>
<p>Dane wideo sÄ… jednym z niewielu typÃ³w danych ze Å›wiata rzeczywistego, dla ktÃ³rych bÄ™dziemy potrzebowaÄ‡ tensorÃ³w 5D. Wideo moÅ¼e byÄ‡ rozumiane jako sekwencja klatek, z ktÃ³rych kaÅ¼da jest obrazem kolorowym. PoniewaÅ¼ kaÅ¼da klatka moÅ¼e byÄ‡ przechowywana w tensorze 3D <code>(wysokoÅ›Ä‡, szerokoÅ›Ä‡, gÅ‚Ä™bokoÅ›Ä‡ koloru)</code>, sekwencja klatek moÅ¼e byÄ‡ przechowywana w tensorze 4D <code>(klatki, wysokoÅ›Ä‡, szerokoÅ›Ä‡, gÅ‚Ä™bokoÅ›Ä‡ koloru)</code>, a zatem partia rÃ³Å¼nych filmÃ³w moÅ¼e byÄ‡ przechowywana w tensorze 5D o ksztaÅ‚cie <code>(prÃ³bki, klatki, wysokoÅ›Ä‡, szerokoÅ›Ä‡, gÅ‚Ä™bokoÅ›Ä‡ koloru)</code>.</p>
<div class="quarto-figure quarto-figure-center page-columns page-full">
<figure class="figure page-columns page-full"><div class="page-columns page-full"><p></p><div class="no-row-height column-margin column-container"><img src="images/reshape.jpg" class="img-fluid quarto-figure quarto-figure-center figure-img" width="400"></div></div>
</figure>
</div>
<p>Na przykÅ‚ad 60-sekundowy klip wideo YouTube o wymiarach 256 Ã— 144, prÃ³bkowany z prÄ™dkoÅ›ciÄ… 4 klatek na sekundÄ™, miaÅ‚by 240 klatek. Partia czterech takich klipÃ³w wideo byÅ‚aby przechowywana w tensorze o ksztaÅ‚cie <code>(4, 240, 256, 144, 3)</code>. To w sumie 106168320 liczb! JeÅ›li typ danych tensora to <em>double</em>, to kaÅ¼da wartoÅ›Ä‡ jest przechowywana w 64 bitach, wiÄ™c tensor reprezentowaÅ‚by 810 MB. Sporo ğŸ˜±! Filmy, ktÃ³re spotykamy w prawdziwym Å¼yciu sÄ… znacznie lÅ¼ejsze, poniewaÅ¼ nie sÄ… przechowywane w <code>float32</code> i zazwyczaj sÄ… silnie skompresowane (jak w formacie MPEG).</p>
<p>Podobnie jak kaÅ¼dy program komputerowy moÅ¼e byÄ‡ ostatecznie zredukowany do maÅ‚ego zestawu operacji binarnych na wejÅ›ciach binarnych (AND, OR, NOR, i tak dalej), wszystkie transformacje uczone przez gÅ‚Ä™bokie sieci neuronowe mogÄ… byÄ‡ zredukowane do garÅ›ci operacji tensorowych stosowanych do tensorÃ³w danych liczbowych. Na przykÅ‚ad, moÅ¼liwe jest dodawanie tensorÃ³w, mnoÅ¼enie tensorÃ³w i tak dalej. W naszym poczÄ…tkowym przykÅ‚adzie budowaliÅ›my naszÄ… sieÄ‡ poprzez ukÅ‚adanie gÄ™stych warstw jedna na drugiej. Instancja warstwy wyglÄ…da tak:</p>
<div class="cell">
<details open="" class="code-fold"><summary>Kod</summary><div class="sourceCode" id="cb47"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/pkg/keras/man/layer_dense.html">layer_dense</a></span><span class="op">(</span>units <span class="op">=</span> <span class="fl">512</span>, activation <span class="op">=</span> <span class="st">"relu"</span><span class="op">)</span></span></code><button title="Kopiuj do schowka" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>Warstwa ta moÅ¼e byÄ‡ interpretowana jako funkcja, ktÃ³ra przyjmuje na wejÅ›cie tensor 2D i zwraca inny tensor 2D - nowÄ… reprezentacjÄ™ tensora wejÅ›ciowego. MoÅ¼na jÄ… teÅ¼ przedstawiÄ‡ inaczej (gdzie <code>W</code> jest tensorem 2D, a <code>b</code> jest wektorem):</p>
<div class="cell">
<details open="" class="code-fold"><summary>Kod</summary><div class="sourceCode" id="cb48"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># nie wykonuj</span></span>
<span><span class="va">output</span> <span class="op">=</span> <span class="fu">relu</span><span class="op">(</span><span class="fu">dot</span><span class="op">(</span><span class="va">W</span>, <span class="va">input</span><span class="op">)</span> <span class="op">+</span> <span class="va">b</span><span class="op">)</span></span></code><button title="Kopiuj do schowka" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>Mamy tu trzy operacje na tensorach: iloczyn (<code>dot</code>) miÄ™dzy tensorem wejÅ›ciowym a tensorem <code>W</code>, dodawanie (<code>+</code>) miÄ™dzy wynikowym tensorem 2D wektorem <code>b</code> i wreszcie operacjÄ™ <code>relu</code>, gdzie <code>relu(x)</code> to <code>max(x, 0)</code>.</p>
<p>Operacja <code>relu</code> i dodawanie sÄ… operacjami typu <em>element-wise</em>: operacjami, ktÃ³re sÄ… stosowane niezaleÅ¼nie do kaÅ¼dego wpisu w rozwaÅ¼anych tensorach. Oznacza to, Å¼e operacje te sÄ… bardzo podatne na wektoryzacje. W praktyce, gdy mamy do czynienia z tablicami R, operacje te sÄ… dostÄ™pne jako dobrze zoptymalizowane wbudowane funkcje R, ktÃ³re same delegujÄ… ciÄ™Å¼kÄ… pracÄ™ do BLAS (<em>Basic Linear Algebra Subprograms</em>). BLAS to niskopoziomowe, wysoce wektoryzowalne, wydajne procedury manipulacji tensorami, zwykle zaimplementowane w Fortranie lub C.</p>
<p>Operacje na tensorach moÅ¼na wykonywaÄ‡ rÃ³wnieÅ¼ wtedy, gdy sÄ… one innych wymiarÃ³w. PrzykÅ‚adowo:</p>
<div class="cell">
<details open="" class="code-fold"><summary>Kod</summary><div class="sourceCode" id="cb49"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># x is a tensor of random values with shape (64, 3, 32, 10)</span></span>
<span><span class="va">x</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/array.html">array</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/Round.html">round</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/Uniform.html">runif</a></span><span class="op">(</span><span class="fl">1000</span>, <span class="fl">0</span>, <span class="fl">9</span><span class="op">)</span><span class="op">)</span>, dim <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">64</span>, <span class="fl">3</span>, <span class="fl">32</span>, <span class="fl">10</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/str.html">str</a></span><span class="op">(</span><span class="va">x</span><span class="op">)</span></span></code><button title="Kopiuj do schowka" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code> num [1:64, 1:3, 1:32, 1:10] 8 6 2 2 0 3 7 4 5 8 ...</code></pre>
</div>
<details open="" class="code-fold"><summary>Kod</summary><div class="sourceCode" id="cb51"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># y is a tensor of 5s of shape (32, 10)</span></span>
<span><span class="va">y</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/array.html">array</a></span><span class="op">(</span><span class="fl">5</span>, dim <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">32</span>, <span class="fl">10</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/str.html">str</a></span><span class="op">(</span><span class="va">y</span><span class="op">)</span></span></code><button title="Kopiuj do schowka" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code> num [1:32, 1:10] 5 5 5 5 5 5 5 5 5 5 ...</code></pre>
</div>
<details open="" class="code-fold"><summary>Kod</summary><div class="sourceCode" id="cb53"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># The output z has shape (64, 3, 32, 10) like x</span></span>
<span><span class="va">z</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/sweep.html">sweep</a></span><span class="op">(</span><span class="va">x</span>, <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">3</span>, <span class="fl">4</span><span class="op">)</span>, <span class="va">y</span>, <span class="va">pmax</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/str.html">str</a></span><span class="op">(</span><span class="va">z</span><span class="op">)</span></span></code><button title="Kopiuj do schowka" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code> num [1:64, 1:3, 1:32, 1:10] 8 6 5 5 5 5 7 5 5 8 ...</code></pre>
</div>
</div>
<p>Operacja <code>dot</code>, zwana rÃ³wnieÅ¼ iloczynem tensorowym jest najczÄ™Å›ciej spotykanÄ…, najbardziej uÅ¼ytecznÄ… operacjÄ… na tensorach. W przeciwieÅ„stwie do operacji <em>element-wise</em>, Å‚Ä…czy ona wpisy w tensorach wejÅ›ciowych. Iloczyny tensorowe wykorzystujÄ… operator <code>%*%</code>. ZauwaÅ¼, Å¼e gdy tylko jeden z dwÃ³ch tensorÃ³w ma wiÄ™cej niÅ¼ jeden wymiar, <code>%*%</code> nie jest symetryczny, czyli Å¼e <code>x %*% y</code> nie jest taki sam jak <code>y %*% x</code>.</p>
<div id="fig-tensor3" class="quarto-figure quarto-figure-center quarto-float anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure"><div aria-describedby="fig-tensor3-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="images/Zrzut ekranu 2023-02-24 o 19.35.48.png" class="img-fluid quarto-figure quarto-figure-center figure-img" width="400">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-tensor3-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Rysunek&nbsp;10.10: Iloczyn tensorÃ³w
</figcaption></figure>
</div>
<p>Trzecim bardzo waÅ¼nym rodzajem operacji na tensorach jest przeksztaÅ‚canie tensorÃ³w. ChociaÅ¼ nie byÅ‚o ono uÅ¼ywane w gÄ™stych warstwach w naszym pierwszym przykÅ‚adzie sieci neuronowej, uÅ¼ywaliÅ›my go, gdy wstÄ™pnie przetwarzaliÅ›my dane o cyfrach przed wprowadzeniem ich do naszej sieci:</p>
<div class="cell">
<details open="" class="code-fold"><summary>Kod</summary><div class="sourceCode" id="cb55"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">train_images</span> <span class="op">&lt;-</span> <span class="va">mnist</span><span class="op">$</span><span class="va">train</span><span class="op">$</span><span class="va">x</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/str.html">str</a></span><span class="op">(</span><span class="va">train_images</span><span class="op">)</span></span></code><button title="Kopiuj do schowka" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code> int [1:60000, 1:28, 1:28] 0 0 0 0 0 0 0 0 0 0 ...</code></pre>
</div>
<details open="" class="code-fold"><summary>Kod</summary><div class="sourceCode" id="cb57"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">train_images</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rstudio.github.io/reticulate/reference/array_reshape.html">array_reshape</a></span><span class="op">(</span><span class="va">train_images</span>, <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">60000</span>, <span class="fl">28</span> <span class="op">*</span> <span class="fl">28</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/str.html">str</a></span><span class="op">(</span><span class="va">train_images</span><span class="op">)</span></span></code><button title="Kopiuj do schowka" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code> int [1:60000, 1:784] 0 0 0 0 0 0 0 0 0 0 ...</code></pre>
</div>
</div>
<p>PrzeksztaÅ‚cenie tensora oznacza zmianÄ™ rozmieszczenia jego wierszy i kolumn tak, by pasowaÅ‚y do docelowego ksztaÅ‚tu. OczywiÅ›cie, przeksztaÅ‚cony tensor ma takÄ… samÄ… caÅ‚kowitÄ… liczbÄ™ wspÃ³Å‚czynnikÃ³w jak tensor poczÄ…tkowy.</p>
<div class="cell">
<details open="" class="code-fold"><summary>Kod</summary><div class="sourceCode" id="cb59"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">x</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html">matrix</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">1</span>,</span>
<span>                <span class="fl">2</span>, <span class="fl">3</span>,</span>
<span>                <span class="fl">4</span>, <span class="fl">5</span><span class="op">)</span>,</span>
<span>             nrow <span class="op">=</span> <span class="fl">3</span>, ncol <span class="op">=</span> <span class="fl">2</span>, byrow <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span>
<span><span class="va">x</span></span></code><button title="Kopiuj do schowka" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>     [,1] [,2]
[1,]    0    1
[2,]    2    3
[3,]    4    5</code></pre>
</div>
<details open="" class="code-fold"><summary>Kod</summary><div class="sourceCode" id="cb61"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">x</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rstudio.github.io/reticulate/reference/array_reshape.html">array_reshape</a></span><span class="op">(</span><span class="va">x</span>, dim <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">6</span>, <span class="fl">1</span><span class="op">)</span><span class="op">)</span> </span>
<span><span class="va">x</span></span></code><button title="Kopiuj do schowka" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>     [,1]
[1,]    0
[2,]    1
[3,]    2
[4,]    3
[5,]    4
[6,]    5</code></pre>
</div>
<details open="" class="code-fold"><summary>Kod</summary><div class="sourceCode" id="cb63"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">x</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rstudio.github.io/reticulate/reference/array_reshape.html">array_reshape</a></span><span class="op">(</span><span class="va">x</span>, dim <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">2</span>, <span class="fl">3</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">x</span></span></code><button title="Kopiuj do schowka" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>     [,1] [,2] [,3]
[1,]    0    1    2
[2,]    3    4    5</code></pre>
</div>
</div>
<p>SzczegÃ³lnym przypadkiem przeksztaÅ‚cenia, ktÃ³ry jest powszechnie spotykany, jest transpozycja.</p>
</section></section><section id="optymalizacja-gradientowa" class="level3" data-number="10.4.2"><h3 data-number="10.4.2" class="anchored" data-anchor-id="optymalizacja-gradientowa">
<span class="header-section-number">10.4.2</span> Optymalizacja gradientowa</h3>
<p>Jak widzieliÅ›my wczeÅ›niej, kaÅ¼da warstwa neuronowa z naszego pierwszego przykÅ‚adu sieci przeksztaÅ‚ca swoje dane wejÅ›ciowe w nastÄ™pujÄ…cy sposÃ³b:</p>
<div class="cell">
<details open="" class="code-fold"><summary>Kod</summary><div class="sourceCode" id="cb65"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">output</span> <span class="op">=</span> <span class="fu">relu</span><span class="op">(</span><span class="fu">dot</span><span class="op">(</span><span class="va">input</span>, <span class="va">W</span><span class="op">)</span><span class="op">+</span><span class="va">b</span><span class="op">)</span></span></code><button title="Kopiuj do schowka" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>W tym wyraÅ¼eniu <code>W</code> i <code>b</code> sÄ… tensorami bÄ™dÄ…cymi atrybutami warstwy. Nazywamy je wagami lub parametrami trenowanymi warstwy (odpowiednio atrybuty kernel i bias). Wagi te zawierajÄ… informacje wyuczone przez sieÄ‡ w wyniku ekspozycji na dane treningowe.</p>
<p>PoczÄ…tkowo te macierze wag sÄ… wypeÅ‚nione maÅ‚ymi losowymi wartoÅ›ciami (krok zwany inicjalizacjÄ… losowÄ…). OczywiÅ›cie nie ma powodu, by oczekiwaÄ‡, Å¼e <code>relu(dot(W, input) + b)</code>, gdy <code>W</code> i <code>b</code> sÄ… losowe, da jakÄ…kolwiek uÅ¼ytecznÄ… reprezentacjÄ™. NastÄ™pnym krokiem jest stopniowe dostosowanie tych wag, w oparciu o sygnaÅ‚ zwrotny. To stopniowe dopasowywanie, zwane rÃ³wnieÅ¼ treningiem, jest w zasadzie naukÄ…, o ktÃ³rÄ… chodzi w uczeniu modeli.</p>
<p>Dzieje siÄ™ to w ramach tak zwanej pÄ™tli treningowej, ktÃ³ra schematycznie wyglÄ…da nastÄ™pujÄ…co. Powtarzaj te kroki w pÄ™tli, tak dÅ‚ugo jak to konieczne:</p>
<ol type="1">
<li>Wylosuj partiÄ™ prÃ³bek treningowych <code>x</code> i odpowiadajÄ…ce im odpowiedzi <code>y</code>.</li>
<li>Uruchom sieÄ‡ na <code>x</code> (nazywane przejÅ›ciem w przÃ³d), aby uzyskaÄ‡ predykcje <code>y_pred</code>.</li>
<li>Oblicz stratÄ™ sieci na partii, czyli miarÄ™ niedopasowania miÄ™dzy <code>y_pred</code> a <code>y</code>.</li>
<li>Zaktualizuj wszystkie wagi sieci w taki sposÃ³b, aby nieznacznie zmniejszyÄ‡ stratÄ™ na tej partii.</li>
</ol>
<p>W koÅ„cu otrzymamy sieÄ‡, ktÃ³ra ma bardzo niskÄ… stratÄ™ na swoich danych treningowych: to znaczy, niskie rozbieÅ¼noÅ›ci miÄ™dzy przewidywaniami <code>y_pred</code> i oczekiwanymi celami <code>y</code>. Ze wszystkich powyÅ¼szych krokÃ³w pierwsze trzy wydajÄ… siÄ™ oczywiste, natomiast 4 jest nieco trudniejszy - aktualizacja wag sieci. BiorÄ…c pod uwagÄ™ indywidualny wspÃ³Å‚czynnik wagowy w sieci, jak moÅ¼na obliczyÄ‡, czy wspÃ³Å‚czynnik ten powinien byÄ‡ zwiÄ™kszony czy zmniejszony i o ile?</p>
<p>PoniewaÅ¼ wszystkie operacje uÅ¼ywane w sieci sÄ… rÃ³Å¼niczkowalne, to moÅ¼na obliczyÄ‡ gradient funkcji straty wzglÄ™dem wspÃ³Å‚czynnikÃ³w sieci. NastÄ™pnie moÅ¼esz skorygowaÄ‡ wspÃ³Å‚czynniki wagowe w kierunku przeciwnym do gradientu, zmniejszajÄ…c w ten sposÃ³b stratÄ™.</p>
<p>BiorÄ…c pod uwagÄ™ funkcjÄ™ rÃ³Å¼niczkowalnÄ…, teoretycznie moÅ¼liwe jest znalezienie jej minimum analitycznie: wiadomo, Å¼e minimum funkcji to punkt, w ktÃ³rym pochodna jest rÃ³wna 0, wiÄ™c wszystko, co musimy zrobiÄ‡, to znaleÅºÄ‡ wszystkie punkty, w ktÃ³rych pochodna zmierza do 0 i sprawdziÄ‡, dla ktÃ³rego z tych punktÃ³w funkcja ma najmniejszÄ… wartoÅ›Ä‡.</p>
<p>W przypadku sieci neuronowej oznacza to analityczne znalezienie kombinacji wartoÅ›ci wag, ktÃ³ra daje najmniejszÄ… moÅ¼liwÄ… funkcjÄ™ straty. MoÅ¼na to zrobiÄ‡ rozwiÄ…zujÄ…c rÃ³wnanie <code>gradient(f)(W) = 0</code> dla <code>W</code>. Jest to rÃ³wnanie wielomianowe o <span class="math inline">\(N\)</span> zmiennych, gdzie <span class="math inline">\(N\)</span> jest liczbÄ… wspÃ³Å‚czynnikÃ³w w sieci. ChociaÅ¼ moÅ¼liwe byÅ‚oby rozwiÄ…zanie takiego rÃ³wnania dla <span class="math inline">\(N = 2\)</span> lub <span class="math inline">\(N = 3\)</span>, to zrobienie tego jest niepraktyczne dla rzeczywistych sieci neuronowych, gdzie liczba parametrÃ³w nigdy nie jest mniejsza niÅ¼ kilka tysiÄ™cy, a czÄ™sto moÅ¼e wynosiÄ‡ kilkadziesiÄ…t milionÃ³w.</p>
<p>Zamiast tego moÅ¼esz uÅ¼yÄ‡ czteroetapowego algorytmu przedstawionego na poczÄ…tku tej sekcji: modyfikujesz parametry po trochu w oparciu o bieÅ¼Ä…cÄ… wartoÅ›Ä‡ straty na losowej partii danych. PoniewaÅ¼ mamy do czynienia z funkcjÄ… rÃ³Å¼niczkowalnÄ…, moÅ¼emy obliczyÄ‡ jej gradient, co daje efektywny sposÃ³b implementacji kroku 4. JeÅ›li zaktualizujesz wagi w kierunku przeciwnym do gradientu, strata bÄ™dzie za kaÅ¼dym razem nieco mniejsza:</p>
<ol type="1">
<li>Wylosuj partiÄ™ prÃ³bek treningowych <code>x</code> i odpowiadajÄ…ce im cele <code>y</code>.</li>
<li>Uruchom sieÄ‡ na <code>x</code>, aby uzyskaÄ‡ predykcje <code>y_pred</code>.</li>
<li>Oblicz stratÄ™ sieci na partii, czyli miarÄ™ niedopasowania miÄ™dzy <code>y_pred</code> a <code>y.</code>
</li>
<li>Oblicz gradient straty wzglÄ™dem parametrÃ³w sieci (przejÅ›cie wsteczne).</li>
<li>Skoryguj (nieznacznie) parametry sieci w kierunku przeciwnym do gradientu - na przykÅ‚ad <code>W = W - (krok * gradient)</code> - tym samym zmniejszajÄ…c nieco stratÄ™ na partii.</li>
</ol>
<p>To, co wÅ‚aÅ›nie opisaliÅ›my, nazywa siÄ™ metodÄ… <em>minibatch stochastic gradient descent</em> (minibatch SGD). Termin stochastyczny odnosi siÄ™ do faktu, Å¼e kaÅ¼da partia danych jest losowana.</p>
<p>Jak widaÄ‡, intuicyjnie waÅ¼ne jest, aby wybraÄ‡ rozsÄ…dnÄ… wartoÅ›Ä‡ wspÃ³Å‚czynnika kroku. JeÅ›li jest on zbyt maÅ‚y, zejÅ›cie w dÃ³Å‚ krzywej zajmie wiele iteracji i moÅ¼e utknÄ…Ä‡ w lokalnym minimum. JeÅ›li krok jest zbyt duÅ¼y, twoje aktualizacje mogÄ… skoÅ„czyÄ‡ siÄ™ zabraniem ciÄ™ do caÅ‚kowicie losowych miejsc na krzywej.</p>
<p>ZauwaÅ¼my, Å¼e istnieje wariant algorytmu mini-batch SGD polegajÄ…cy na losowaniu pojedynczej prÃ³bki i <code>y</code> w kaÅ¼dej iteracji, zamiast losowania partii danych. Jest on oryginalnym algorytmem SGD, ktÃ³ry jest mniej wydajny.</p>
<p>OprÃ³cz wspomnianej metody mini-batch SGD istnieje wiele innych, duÅ¼o bardziej skutecznych metod optymalizacji parametrÃ³w wagowych modelu. WÅ›rÃ³d nich naleÅ¼y wymieniÄ‡:</p>
<ul>
<li>RMSprop</li>
<li>Adagrad</li>
<li>Adamax</li>
<li>mini-batch SGD with Momentum</li>
<li>mini-batch SGD with Nesterov Momentum</li>
<li>Adam (chyba najpopularniejsza)</li>
<li>Nadam</li>
</ul>
<p>IstniejÄ… rÃ³wnieÅ¼ odmiany wspominanych wyÅ¼ej metod z planami. Owe plany sÄ… przepisami na to jak wspÃ³Å‚czynnik szybkoÅ›ci uczenia ma siÄ™ zmieniaÄ‡ w kolejnych iteracjach.</p>
<div id="fig-sgd1" class="quarto-figure quarto-figure-center quarto-float anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure"><div aria-describedby="fig-sgd1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="https://cs231n.github.io/assets/nn3/opt2.gif" class="img-fluid quarto-figure quarto-figure-center figure-img" width="600">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-sgd1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Rysunek&nbsp;10.11: Optymalizacja wag z wykorzystaniem rÃ³Å¼nych technik
</figcaption></figure>
</div>
</section><section id="wsteczna-propagacja-bÅ‚Ä™du" class="level3" data-number="10.4.3"><h3 data-number="10.4.3" class="anchored" data-anchor-id="wsteczna-propagacja-bÅ‚Ä™du">
<span class="header-section-number">10.4.3</span> Wsteczna propagacja bÅ‚Ä™du</h3>
<p>Wsteczna propagacja bÅ‚Ä™du (ang. <em>backpropagation</em>) jest metodÄ… instruujÄ…cÄ… algorytm jak korygowaÄ‡ wagi sieci. Korzysta ona z prawa znanego w matematyce jako pochodna funkcji zÅ‚oÅ¼onej (ang. <em>chain rule</em>)</p>
<p><span id="eq-chain-rule"><span class="math display">\[
[f(g(x))]'=f'(g(x))\cdot g'(x).
\tag{10.1}\]</span></span></p>
<p><em>Backpropagation</em> rozpoczyna siÄ™ od koÅ„cowej wartoÅ›ci straty i dziaÅ‚a wstecz od gÃ³rnych warstw do dolnych, stosujÄ…c reguÅ‚Ä™ Å‚aÅ„cuchowÄ… do obliczenia wkÅ‚adu, jaki kaÅ¼dy parametr miaÅ‚ w wartoÅ›ci straty.</p>
<div id="fig-backprop1" class="quarto-figure quarto-figure-center quarto-float anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure"><div aria-describedby="fig-backprop1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="https://developer-blogs.nvidia.com/wp-content/uploads/2022/02/DS-Guide-to-Gradient-Descent_Pic5.gif" class="img-fluid quarto-figure quarto-figure-center figure-img" width="400">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-backprop1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Rysunek&nbsp;10.12: Zasada dziaÅ‚ania wstecznej propagacji bÅ‚Ä™du
</figcaption></figure>
</div>
<p>Obecnie korzysta siÄ™ z metod zdolnych do symbolicznego rÃ³Å¼niczkowania, takich jak TensorFlow. Oznacza to, Å¼e biorÄ…c pod uwagÄ™ Å‚aÅ„cuch operacji ze znanÄ… funkcjÄ… straty, mogÄ… obliczyÄ‡ funkcjÄ™ gradientu dla Å‚aÅ„cucha za pomocÄ… pochodnej funkcji zÅ‚oÅ¼onej, ktÃ³ra mapuje wartoÅ›ci parametrÃ³w sieci do wartoÅ›ci gradientu. Kiedy mamy dostÄ™p do takiej funkcji, przejÅ›cie wsteczne jest zredukowane do wywoÅ‚ania tej funkcji gradientu. DziÄ™ki symbolicznemu rÃ³Å¼niczkowaniu nigdy nie bÄ™dziemy musieli rÄ™cznie implementowaÄ‡ algorytmu wstecznej propagacji.</p>
</section><section id="funkcje-straty" class="level3 page-columns page-full" data-number="10.4.4"><h3 data-number="10.4.4" class="anchored" data-anchor-id="funkcje-straty">
<span class="header-section-number">10.4.4</span> Funkcje straty</h3>
<p>We wczeÅ›niej prezentowanym przykÅ‚adzie w funkcji <code><a href="https://generics.r-lib.org/reference/compile.html">compile()</a></code> pojawiÅ‚a siÄ™ funkcja straty <code>loss = 'categorical_crossentropy'</code>, ktÃ³ra jest jednÄ… z moÅ¼liwych do zastosowania funkcji straty<a href="#fn8" class="footnote-ref" id="fnref8" role="doc-noteref"><sup>8</sup></a>. Funkcja straty jest uÅ¼ywana jako sygnaÅ‚ zwrotny do uczenia tensorÃ³w wag i ktÃ³rÄ… w fazie uczenia bÄ™dzie minimalizowana. OdbywaÄ‡ siÄ™ to bÄ™dzie za pomocÄ… mini-batch SGD. DokÅ‚adne zasady rzÄ…dzÄ…ce konkretnÄ… implementacjÄ… SGD sÄ… zdefiniowane przez optymalizator <code>rmsprop</code> przekazany jako pierwszy argument.</p>
<div class="no-row-height column-margin column-container"><p><sup>8</sup>&nbsp;o funkcjach straty bÄ™dziemy jeszcze wspominaÄ‡ przy konkretnych przykÅ‚adach</p></div><p>UruchamiajÄ…c</p>
<div class="cell">
<details open="" class="code-fold"><summary>Kod</summary><div class="sourceCode" id="cb66"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">network</span> <span class="op">|&gt;</span> </span>
<span>  <span class="fu"><a href="https://generics.r-lib.org/reference/fit.html">fit</a></span><span class="op">(</span><span class="va">train_samples</span>, <span class="va">train_labels</span>, epochs <span class="op">=</span> <span class="fl">5</span>, batch_size <span class="op">=</span> <span class="fl">128</span><span class="op">)</span></span></code><button title="Kopiuj do schowka" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>rozpoczynamy iteracyjne uczenie przygotowanej sieci. BÄ™dzie ona realizowana w 5 epokach na partiach danych skÅ‚adajÄ…cych siÄ™ ze 128 obserwacji.</p>
<div class="quarto-figure quarto-figure-center page-columns page-full">
<figure class="figure page-columns page-full"><div class="page-columns page-full"><p></p><div class="no-row-height column-margin column-container"><img src="images/tw4.jpeg" class="img-fluid quarto-figure quarto-figure-center figure-img" width="400"></div></div>
</figure>
</div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Adnotacja
</div>
</div>
<div class="callout-body-container callout-body">
<p>Bardzo pomocne w zrozumieniu zasady dziaÅ‚ania sieci neuronowych na przykÅ‚adzie (bardzo podobnym do naszego) moÅ¼e byÄ‡ obejrzenie cyklu 4 filmÃ³w sieciach neuronowych kanaÅ‚u <a href="https://youtu.be/aircAruvnKk">3Blue1Brown</a></p>
</div>
</div>
<div class="cell">
<details open="" class="code-fold"><summary>Kod</summary><div class="sourceCode" id="cb67"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># lista funkcji straty pakietu keras</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/ls.html">ls</a></span><span class="op">(</span><span class="st">"package:keras"</span><span class="op">)</span> <span class="op">|&gt;</span> </span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/grep.html">grep</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">_</span>, pattern <span class="op">=</span> <span class="st">"^loss_"</span>, value <span class="op">=</span> <span class="cn">T</span><span class="op">)</span></span></code><button title="Kopiuj do schowka" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code> [1] "loss_binary_crossentropy"            
 [2] "loss_categorical_crossentropy"       
 [3] "loss_categorical_hinge"              
 [4] "loss_cosine_proximity"               
 [5] "loss_cosine_similarity"              
 [6] "loss_hinge"                          
 [7] "loss_huber"                          
 [8] "loss_kl_divergence"                  
 [9] "loss_kullback_leibler_divergence"    
[10] "loss_logcosh"                        
[11] "loss_mean_absolute_error"            
[12] "loss_mean_absolute_percentage_error" 
[13] "loss_mean_squared_error"             
[14] "loss_mean_squared_logarithmic_error" 
[15] "loss_poisson"                        
[16] "loss_sparse_categorical_crossentropy"
[17] "loss_squared_hinge"                  </code></pre>
</div>
</div>


<div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list" style="display: none">
<div id="ref-ciresanFlexibleHighPerformance" class="csl-entry" role="listitem">
Ciresan, Dan C, Ueli Meier, Jonathan Masci, Luca M Gambardella, i Jurgen Schmidhuber. b.d. <span>â€Flexible, <span>High Performance Convolutional Neural Networks</span> for <span>Image Classification</span>â€</span>.
</div>
<div id="ref-krizhevsky2017" class="csl-entry" role="listitem">
Krizhevsky, Alex, Ilya Sutskever, i Geoffrey E. Hinton. 2017. <span>â€ImageNet Classification with Deep Convolutional Neural Networksâ€</span>. <em>Communications of the ACM</em> 60 (6): 84â€“90. <a href="https://doi.org/10.1145/3065386">https://doi.org/10.1145/3065386</a>.
</div>
</div>
</section></section></main><!-- /main --><script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const disableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'prefetch';
    }
  }
  const enableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'stylesheet';
    }
  }
  const manageTransitions = (selector, allowTransitions) => {
    const els = window.document.querySelectorAll(selector);
    for (let i=0; i < els.length; i++) {
      const el = els[i];
      if (allowTransitions) {
        el.classList.remove('notransition');
      } else {
        el.classList.add('notransition');
      }
    }
  }
  const toggleGiscusIfUsed = (isAlternate, darkModeDefault) => {
    const baseTheme = document.querySelector('#giscus-base-theme')?.value ?? 'light';
    const alternateTheme = document.querySelector('#giscus-alt-theme')?.value ?? 'dark';
    let newTheme = '';
    if(darkModeDefault) {
      newTheme = isAlternate ? baseTheme : alternateTheme;
    } else {
      newTheme = isAlternate ? alternateTheme : baseTheme;
    }
    const changeGiscusTheme = () => {
      // From: https://github.com/giscus/giscus/issues/336
      const sendMessage = (message) => {
        const iframe = document.querySelector('iframe.giscus-frame');
        if (!iframe) return;
        iframe.contentWindow.postMessage({ giscus: message }, 'https://giscus.app');
      }
      sendMessage({
        setConfig: {
          theme: newTheme
        }
      });
    }
    const isGiscussLoaded = window.document.querySelector('iframe.giscus-frame') !== null;
    if (isGiscussLoaded) {
      changeGiscusTheme();
    }
  }
  const toggleColorMode = (alternate) => {
    // Switch the stylesheets
    const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
    manageTransitions('#quarto-margin-sidebar .nav-link', false);
    if (alternate) {
      enableStylesheet(alternateStylesheets);
      for (const sheetNode of alternateStylesheets) {
        if (sheetNode.id === "quarto-bootstrap") {
          toggleBodyColorMode(sheetNode);
        }
      }
    } else {
      disableStylesheet(alternateStylesheets);
      toggleBodyColorPrimary();
    }
    manageTransitions('#quarto-margin-sidebar .nav-link', true);
    // Switch the toggles
    const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
    for (let i=0; i < toggles.length; i++) {
      const toggle = toggles[i];
      if (toggle) {
        if (alternate) {
          toggle.classList.add("alternate");     
        } else {
          toggle.classList.remove("alternate");
        }
      }
    }
    // Hack to workaround the fact that safari doesn't
    // properly recolor the scrollbar when toggling (#1455)
    if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
      manageTransitions("body", false);
      window.scrollTo(0, 1);
      setTimeout(() => {
        window.scrollTo(0, 0);
        manageTransitions("body", true);
      }, 40);  
    }
  }
  const isFileUrl = () => { 
    return window.location.protocol === 'file:';
  }
  const hasAlternateSentinel = () => {  
    let styleSentinel = getColorSchemeSentinel();
    if (styleSentinel !== null) {
      return styleSentinel === "alternate";
    } else {
      return false;
    }
  }
  const setStyleSentinel = (alternate) => {
    const value = alternate ? "alternate" : "default";
    if (!isFileUrl()) {
      window.localStorage.setItem("quarto-color-scheme", value);
    } else {
      localAlternateSentinel = value;
    }
  }
  const getColorSchemeSentinel = () => {
    if (!isFileUrl()) {
      const storageValue = window.localStorage.getItem("quarto-color-scheme");
      return storageValue != null ? storageValue : localAlternateSentinel;
    } else {
      return localAlternateSentinel;
    }
  }
  const darkModeDefault = false;
  let localAlternateSentinel = darkModeDefault ? 'alternate' : 'default';
  // Dark / light mode switch
  window.quartoToggleColorScheme = () => {
    // Read the current dark / light value 
    let toAlternate = !hasAlternateSentinel();
    toggleColorMode(toAlternate);
    setStyleSentinel(toAlternate);
    toggleGiscusIfUsed(toAlternate, darkModeDefault);
  };
  // Ensure there is a toggle, if there isn't float one in the top right
  if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
    const a = window.document.createElement('a');
    a.classList.add('top-right');
    a.classList.add('quarto-color-scheme-toggle');
    a.href = "";
    a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
    const i = window.document.createElement("i");
    i.classList.add('bi');
    a.appendChild(i);
    window.document.body.appendChild(a);
  }
  // Switch to dark mode if need be
  if (hasAlternateSentinel()) {
    toggleColorMode(true);
  } else {
    toggleColorMode(false);
  }
  const icon = "î§‹";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Skopiowano!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Skopiowano!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      const annoteTargets = window.document.querySelectorAll('.code-annotation-anchor');
      for (let i=0; i<annoteTargets.length; i++) {
        const annoteTarget = annoteTargets[i];
        const targetCell = annoteTarget.getAttribute("data-target-cell");
        const targetAnnotation = annoteTarget.getAttribute("data-target-annotation");
        const contentFn = () => {
          const content = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          if (content) {
            const tipContent = content.cloneNode(true);
            tipContent.classList.add("code-annotation-tip-content");
            return tipContent.outerHTML;
          }
        }
        const config = {
          allowHTML: true,
          content: contentFn,
          onShow: (instance) => {
            selectCodeLines(instance.reference);
            instance.reference.classList.add('code-annotation-active');
            window.tippy.hideAll();
          },
          onHide: (instance) => {
            unselectCodeLines();
            instance.reference.classList.remove('code-annotation-active');
          },
          maxWidth: 300,
          delay: [50, 0],
          duration: [200, 0],
          offset: [5, 10],
          arrow: true,
          appendTo: function(el) {
            return el.parentElement.parentElement.parentElement;
          },
          interactive: true,
          interactiveBorder: 10,
          theme: 'quarto',
          placement: 'right',
          popperOptions: {
            modifiers: [
            {
              name: 'flip',
              options: {
                flipVariations: false, // true by default
                allowedAutoPlacements: ['right'],
                fallbackPlacements: ['right', 'top', 'top-start', 'top-end', 'bottom', 'bottom-start', 'bottom-end', 'left'],
              },
            },
            {
              name: 'preventOverflow',
              options: {
                mainAxis: false,
                altAxis: false
              }
            }
            ]        
          }      
        };
        window.tippy(annoteTarget, config); 
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script><nav class="page-navigation"><div class="nav-page nav-page-previous">
      <a href="./fourier.html" class="pagination-link  aria-label=" fouriera="">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Transformata Fouriera</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./fundamentals.html" class="pagination-link" aria-label="<span class='chapter-number'>11</span>&nbsp; <span class='chapter-title'>Fundamenty DNN</span>">
        <span class="nav-page-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Fundamenty DNN</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->
<footer class="footer"><div class="nav-footer">
    <div class="nav-footer-left">
<p>Automatyczna analiza obrazu, Dariusz Majerek</p>
</div>   
    <div class="nav-footer-center">
      &nbsp;
    <div class="toc-actions d-sm-block d-md-none"><ul><li><a href="https://github.com/dax44/ComputerVision/issues/new" class="toc-action"><i class="bi bi-github"></i>ZgÅ‚oÅ› problem</a></li></ul></div></div>
    <div class="nav-footer-right">
<p>KsiÄ…Å¼ka zostaÅ‚a napisana w <a href="https://quarto.org/">Quarto</a></p>
</div>
  </div>
</footer>


</body></html>