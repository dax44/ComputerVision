<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="pl" xml:lang="pl"><head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.203">
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">
<title>Automatyczna analiza obrazu - 10&nbsp; Deep learning</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./references.html" rel="next">
<link href="./fourier.html" rel="prev">
<link href="./cover.png" rel="icon" type="image/png">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-dark.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="site_libs/bootstrap/bootstrap-dark.min.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark"><script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 20,
  "language": {
    "search-no-results-text": "Brak wynikÃ³w",
    "search-matching-documents-text": "dopasowane dokumenty",
    "search-copy-link-title": "Kopiuj link do wyszukiwania",
    "search-hide-matches-text": "Ukryj dodatkowe dopasowania",
    "search-more-match-text": "wiÄ™cej dopasowaÅ„ w tym dokumencie",
    "search-more-matches-text": "wiÄ™cej dopasowaÅ„ w tym dokumencie",
    "search-clear-button-title": "WyczyÅ›Ä‡",
    "search-detached-cancel-button-title": "Anuluj",
    "search-submit-button-title": "ZatwierdÅº"
  }
}</script><script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>
</head>
<body class="nav-sidebar floating slimcontent">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top"><nav class="quarto-secondary-nav"><div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
      <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./deeplearning.html">&lt;span class='chapter-number'&gt;10&lt;/span&gt;&nbsp; &lt;span class='chapter-title'&gt;Deep learning&lt;/span&gt;</a></li></ol></nav>
      <a class="flex-grow-1" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
      </a>
    </div>
  </nav></header><!-- content --><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal sidebar-navigation floating overflow-auto"><div class="pt-lg-2 mt-2 text-left sidebar-header sidebar-header-stacked">
      <a href="./index.html" class="sidebar-logo-link">
      <img src="./images/logo.png" alt="" class="sidebar-logo py-0 d-lg-inline d-none"></a>
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Automatyczna analiza obrazu</a> 
        <div class="sidebar-tools-main tools-wide">
    <a href="https://twitter.com" title="" class="quarto-navigation-tool px-1" aria-label=""><i class="bi bi-twitter"></i></a>
    <a href="https://github.com/dax44/ComputerVision/" title="Source Code" class="quarto-navigation-tool px-1" aria-label="Source Code"><i class="bi bi-github"></i></a>
    <a href="https://twitter.com/intent/tweet?url=%7Curl%7C" title="Twitter" class="quarto-navigation-tool px-1" aria-label="Twitter"><i class="bi bi-twitter"></i></a>
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
  <a href="" class="quarto-reader-toggle quarto-navigation-tool px-1" onclick="window.quartoToggleReader(); return false;" title="Toggle reader mode">
  <div class="quarto-reader-toggle-btn">
  <i class="bi"></i>
  </div>
</a>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">WstÄ™p</a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./intro.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Wprowadzenie</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./history.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Historia wizji komputerowej</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./digt_img.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Obrazy cyfrowe</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./transformations.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Transformacje geometryczne</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./point_trans.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Transformacje punktowe</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./filters.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Filtry</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./edge.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Wykrywanie krawÄ™dzi i konturÃ³w</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./morpho.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Filtry morfologiczne</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./fourier.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Transformata Fouriera</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./deeplearning.html" class="sidebar-item-text sidebar-link active"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Deep learning</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./references.html" class="sidebar-item-text sidebar-link">Bibliografia</a>
  </div>
</li>
    </ul>
</div>
</nav><div id="quarto-sidebar-glass" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active"><h2 id="toc-title">Spis treÅ›ci</h2>
   
  <ul>
<li><a href="#uczenie-si%C4%99-reprezentacji-na-podstawie-danych" id="toc-uczenie-siÄ™-reprezentacji-na-podstawie-danych" class="nav-link active" data-scroll-target="#uczenie-si%C4%99-reprezentacji-na-podstawie-danych"><span class="toc-section-number">10.1</span>  Uczenie siÄ™ reprezentacji na podstawie danych</a></li>
  <li><a href="#jak-dzia%C5%82a-deep-learning" id="toc-jak-dziaÅ‚a-deep-learning" class="nav-link" data-scroll-target="#jak-dzia%C5%82a-deep-learning"><span class="toc-section-number">10.2</span>  Jak dziaÅ‚a deep learning?</a></li>
  <li>
<a href="#kr%C3%B3tki-rys-historyczny-dl" id="toc-krÃ³tki-rys-historyczny-dl" class="nav-link" data-scroll-target="#kr%C3%B3tki-rys-historyczny-dl"><span class="toc-section-number">10.3</span>  KrÃ³tki rys historyczny DL</a>
  <ul class="collapse">
<li><a href="#hardware" id="toc-hardware" class="nav-link" data-scroll-target="#hardware"><span class="toc-section-number">10.3.1</span>  Hardware</a></li>
  <li><a href="#dane" id="toc-dane" class="nav-link" data-scroll-target="#dane"><span class="toc-section-number">10.3.2</span>  Dane</a></li>
  <li><a href="#algorytmy" id="toc-algorytmy" class="nav-link" data-scroll-target="#algorytmy"><span class="toc-section-number">10.3.3</span>  Algorytmy</a></li>
  </ul>
</li>
  </ul><div class="toc-actions"><div><i class="bi bi-github"></i></div><div class="action-links"><p><a href="https://github.com/dax44/ComputerVision/issues/new" class="toc-action">ZgÅ‚oÅ› problem</a></p></div></div></nav>
    </div>
<!-- main -->
<main class="content page-columns page-full" id="quarto-document-content"><header id="title-block-header" class="quarto-title-block default"><div class="quarto-title">
<h1 class="title">
<span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Deep learning</span>
</h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  

</header><p>Jak to zostaÅ‚o wspomniane na poczÄ…tku tej ksiÄ…Å¼ki do automatycznej analizy obrazu wykorzystamy techniki z zakresu uczenia maszynowego, ktÃ³re mieszczÄ… siÄ™ pod pojÄ™ciem gÅ‚Ä™bokiego uczenia (ang. <em>deep learning</em>). Uczenie maszynowe wynika bezpoÅ›rednio z pytania: czy komputer mÃ³gÅ‚by wyjÅ›Ä‡ poza to, co wiemy i samodzielnie nauczyÄ‡ siÄ™, jak wykonaÄ‡ okreÅ›lone zadanie? Czy komputer mÃ³gÅ‚by nas zaskoczyÄ‡? Czy zamiast programistÃ³w rÄ™cznie tworzÄ…cych reguÅ‚y przetwarzania danych, komputer mÃ³gÅ‚by automatycznie nauczyÄ‡ siÄ™ tych reguÅ‚ patrzÄ…c na dane?</p>
<div id="fig-ml1" class="quarto-figure quarto-figure-center anchored">
<figure class="figure"><p><img src="images/Zrzut ekranu 2023-02-23 o 19.01.53.png" class="img-fluid figure-img" width="400"></p>
<p></p><figcaption class="figure-caption">Rysunek&nbsp;10.1: Dwa schematy myÅ›lenia o programowaniu komputerÃ³w</figcaption><p></p>
</figure>
</div>
<p>To pytanie otwiera drzwi do nowego paradygmatu programowania. W klasycznym programowaniu, paradygmacie symbolicznej AI, ludzie wprowadzajÄ… reguÅ‚y (program) i dane, ktÃ³re majÄ… byÄ‡ przetwarzane zgodnie z tymi reguÅ‚ami, a nastÄ™pnie otrzymujÄ… odpowiedzi (patrz <a href="#fig-ml1">Rysunek&nbsp;<span>10.1</span></a>). W przypadku uczenia maszynowego, czÅ‚owiek wprowadza dane oraz odpowiedzi oczekiwane na podstawie tych danych, a nastÄ™pnie otrzymuje reguÅ‚y. ReguÅ‚y te mogÄ… byÄ‡ nastÄ™pnie zastosowane do nowych danych, aby uzyskaÄ‡ oryginalne odpowiedzi.</p>
<p>System uczenia maszynowego jest raczej uczony niÅ¼ programowany. Przedstawia siÄ™ mu wiele przykÅ‚adÃ³w zwiÄ…zanych z zadaniem, a on znajduje w nich strukturÄ™ statystycznÄ…, ktÃ³ra w koÅ„cu pozwala mu wymyÅ›liÄ‡ reguÅ‚y automatyzacji zadania. Na przykÅ‚ad, jeÅ›li chciaÅ‚byÅ› zautomatyzowaÄ‡ zadanie oznaczania zdjÄ™Ä‡ z wakacji, mÃ³gÅ‚byÅ› przedstawiÄ‡ systemowi uczenia maszynowego wiele przykÅ‚adÃ³w zdjÄ™Ä‡ juÅ¼ oznaczonych przez ludzi, a system nauczyÅ‚by siÄ™ statystycznych reguÅ‚ kojarzenia konkretnych zdjÄ™Ä‡ z konkretnymi tagami.</p>
<p>ChociaÅ¼ uczenie maszynowe zaczÄ™Å‚o siÄ™ rozwijaÄ‡ dopiero w latach 90-tych, szybko staÅ‚o siÄ™ najpopularniejszÄ… i odnoszÄ…cÄ… najwiÄ™ksze sukcesy dziedzinÄ… AI, a trend ten jest napÄ™dzany przez dostÄ™pnoÅ›Ä‡ szybszego sprzÄ™tu i wiÄ™kszych zbiorÃ³w danych. Uczenie maszynowe jest Å›ciÅ›le zwiÄ…zane ze statystykÄ… matematycznÄ…, ale rÃ³Å¼ni siÄ™ od niej na kilka waÅ¼nych sposobÃ³w. W przeciwieÅ„stwie do statystyki, uczenie maszynowe ma tendencjÄ™ do zajmowania siÄ™ duÅ¼ymi, zÅ‚oÅ¼onymi zbiorami danych (takimi jak zbiÃ³r milionÃ³w obrazÃ³w, z ktÃ³rych kaÅ¼dy skÅ‚ada siÄ™ z dziesiÄ…tek tysiÄ™cy pikseli), dla ktÃ³rych klasyczna analiza statystyczna byÅ‚aby niepraktyczna. W rezultacie, uczenie maszynowe, a zwÅ‚aszcza gÅ‚Ä™bokie uczenie, wykazuje stosunkowo maÅ‚o teorii matematycznej - byÄ‡ moÅ¼e zbyt maÅ‚o - i jest zorientowane na inÅ¼ynieriÄ™. Jest to praktyczna dyscyplina, w ktÃ³rej pomysÅ‚y sÄ… sprawdzane empirycznie znacznie czÄ™Å›ciej niÅ¼ teoretycznie.</p>
<section id="uczenie-siÄ™-reprezentacji-na-podstawie-danych" class="level2" data-number="10.1"><h2 data-number="10.1" class="anchored" data-anchor-id="uczenie-siÄ™-reprezentacji-na-podstawie-danych">
<span class="header-section-number">10.1</span> Uczenie siÄ™ reprezentacji na podstawie danych</h2>
<p>Na to aby zdefiniowaÄ‡ gÅ‚Ä™bokie uczenie i zrozumieÄ‡ rÃ³Å¼nicÄ™ miÄ™dzy gÅ‚Ä™bokim uczeniem a innymi podejÅ›ciami do uczenia maszynowego, najpierw musimy mieÄ‡ pewne pojÄ™cie o tym, co robiÄ… algorytmy uczenia maszynowego. WÅ‚aÅ›nie stwierdziliÅ›my, Å¼e uczenie maszynowe odkrywa reguÅ‚y wykonywania zadania przetwarzania danych, biorÄ…c pod uwagÄ™ przykÅ‚ady tego, co jest oczekiwane na wyjÅ›ciu. Zatem, aby przeprowadziÄ‡ uczenie maszynowe, potrzebujemy trzech rzeczy:</p>
<ul>
<li>Punkty danych wejÅ›ciowych - na przykÅ‚ad, jeÅ›li zadaniem jest rozpoznawanie mowy, tymi punktami danych mogÄ… byÄ‡ pliki dÅºwiÄ™kowe osÃ³b mÃ³wiÄ…cych. JeÅ›li zadanie polega na oznaczaniu obrazÃ³w, mogÄ… to byÄ‡ pliki z obrazami.</li>
<li>PrzykÅ‚ady oczekiwanych wynikÃ³w - w zadaniu rozpoznawania mowy mogÄ… to byÄ‡ generowane przez czÅ‚owieka transkrypcje plikÃ³w dÅºwiÄ™kowych. W zadaniu dotyczÄ…cym obrazÃ³w, oczekiwanymi danymi wyjÅ›ciowymi mogÄ… byÄ‡ tagi takie jak â€œpiesâ€, â€œkotâ€ itd.</li>
<li>SposÃ³b pomiaru, czy algorytm dobrze wykonuje swojÄ… pracÄ™ - jest on niezbÄ™dny do okreÅ›lenia odlegÅ‚oÅ›ci miÄ™dzy aktualnym wyjÅ›ciem algorytmu a jego oczekiwanym wyjÅ›ciem. Pomiar jest uÅ¼ywany jako sygnaÅ‚ zwrotny do dostosowania sposobu dziaÅ‚ania algorytmu. Ten krok dostosowawczy nazywamy uczeniem siÄ™ modelu.</li>
</ul>
<p>Model uczenia maszynowego przeksztaÅ‚ca dane wejÅ›ciowe w sensowne dane wyjÅ›ciowe, a proces ten jest â€œuczonyâ€ przez ekspozycjÄ™ na znane przykÅ‚ady danych wejÅ›ciowych i wyjÅ›ciowych. Dlatego centralnym problemem w uczeniu maszynowym i gÅ‚Ä™bokim uczeniu jest sensowne przeksztaÅ‚canie danych: innymi sÅ‚owy, uczenie siÄ™ uÅ¼ytecznych reprezentacji danych wejÅ›ciowych - reprezentacji, ktÃ³re przybliÅ¼ajÄ… nas do oczekiwanych wynikÃ³w. Zanim przejdziemy dalej: co to jest reprezentacja? W gruncie rzeczy jest to inny sposÃ³b patrzenia na dane - reprezentacja lub kodowanie danych. Na przykÅ‚ad, kolorowy obraz moÅ¼e byÄ‡ zakodowany w formacie RGB lub w formacie HSV (barwa-nasycenie-wartoÅ›Ä‡): sÄ… to dwie rÃ³Å¼ne reprezentacje tych samych danych. NiektÃ³re zadania, ktÃ³re mogÄ… byÄ‡ trudne do rozwiÄ…zania przy jednej reprezentacji, mogÄ… staÄ‡ siÄ™ Å‚atwe przy drugiej. Na przykÅ‚ad zadanie â€œwybierz wszystkie czerwone piksele na obrazieâ€ jest prostsze w formacie RBG, natomiast â€œspraw, by obraz byÅ‚ mniej nasyconyâ€ jest prostsze w formacie HSV. Modele uczenia maszynowego polegajÄ… na znalezieniu odpowiednich reprezentacji dla danych wejÅ›ciowych - przeksztaÅ‚ceÅ„ danych, ktÃ³re czyniÄ… je bardziej przydatnymi do wykonania zadania, np.zadania klasyfikacji.</p>
<p>Wszystkie algorytmy uczenia maszynowego polegajÄ… na automatycznym znajdowaniu takich przeksztaÅ‚ceÅ„, ktÃ³re zmieniajÄ… dane w bardziej uÅ¼yteczne reprezentacje dla danego zadania. Operacje te mogÄ… byÄ‡ zmianami wspÃ³Å‚rzÄ™dnych lub rzutami liniowymi, tÅ‚umaczeniami, operacjami nieliniowymi (takimi jak wybierz wszystkie punkty takie, Å¼e <span class="math inline">\(x &gt;0\)</span>) i tak dalej. Algorytmy uczenia maszynowego zazwyczaj nie sÄ… kreatywne w znajdowaniu tych przeksztaÅ‚ceÅ„; po prostu przeszukujÄ… wczeÅ›niej zdefiniowany zestaw operacji, zwany przestrzeniÄ… hipotez.</p>
<p>Tak wiÄ™c, technicznie rzecz biorÄ…c, uczenie maszynowe polega na poszukiwaniu uÅ¼ytecznych reprezentacji pewnych danych wejÅ›ciowych, w ramach predefiniowanej przestrzeni moÅ¼liwoÅ›ci, przy uÅ¼yciu wskazÃ³wek pochodzÄ…cych z jakiegoÅ› sygnaÅ‚u zwrotnego. Ta prosta idea pozwala na rozwiÄ…zywanie niezwykle szerokiego zakresu zadaÅ„ naturalnych dla czÅ‚owieka, od rozpoznawania mowy po autonomiczne prowadzenie samochodu.</p>
<p>GÅ‚Ä™bokie uczenie jest specyficznÄ… dziedzinÄ… uczenia maszynowego: nowe podejÅ›cie do uczenia siÄ™ reprezentacji z danych, ktÃ³re kÅ‚adzie nacisk na uczenie siÄ™ kolejnych warstw coraz bardziej znaczÄ…cych reprezentacji. GÅ‚Ä™bokie uczenie nie jest odniesieniem do jakiegokolwiek gÅ‚Ä™bszego zrozumienia osiÄ…ganego przez to podejÅ›cie; raczej oznacza ideÄ™ kolejnych warstw reprezentacji. To, ile warstw skÅ‚ada siÄ™ na model danych, nazywane jest gÅ‚Ä™bokoÅ›ciÄ… modelu. Innymi wÅ‚aÅ›ciwymi nazwami dla tej dziedziny mogÅ‚yby byÄ‡ uczenie siÄ™ reprezentacji warstwowych i uczenie siÄ™ reprezentacji hierarchicznych. Nowoczesne uczenie gÅ‚Ä™bokie czÄ™sto obejmuje dziesiÄ…tki, a nawet setki kolejnych warstw - i wszystkie one sÄ… uczone automatycznie na podstawie danych treningowych. Tymczasem inne podejÅ›cia do uczenia maszynowego koncentrujÄ… siÄ™ na uczeniu siÄ™ tylko jednej lub dwÃ³ch warstw reprezentacji danych; stÄ…d czasem nazywa siÄ™ je uczeniem pÅ‚ytkim.</p>
<p>W gÅ‚Ä™bokim uczeniu, te warstwowe reprezentacje sÄ… (prawie zawsze) uczone za pomocÄ… modeli zwanych sieciami neuronowymi, zbudowanymi w dosÅ‚ownych warstwach uÅ‚oÅ¼onych jedna za drugÄ…. Termin sieÄ‡ neuronowa jest odniesieniem do neurobiologii, jednak mimo Å¼e niektÃ³re z gÅ‚Ã³wnych koncepcji gÅ‚Ä™bokiego uczenia zostaÅ‚y opracowane czÄ™Å›ciowo poprzez czerpanie inspiracji z naszego rozumienia mÃ³zgu, modele gÅ‚Ä™bokiego uczenia nie sÄ… modelami mÃ³zgu. Nie ma dowodÃ³w na to, Å¼e mÃ³zg implementuje cokolwiek w rodzaju mechanizmÃ³w uczenia siÄ™ wykorzystywanych w nowoczesnych modelach gÅ‚Ä™bokiego uczenia. MoÅ¼esz natknÄ…Ä‡ siÄ™ na artykuÅ‚y popularno-naukowe gÅ‚oszÄ…ce, Å¼e gÅ‚Ä™bokie uczenie dziaÅ‚a jak mÃ³zg lub byÅ‚o wzorowane na mÃ³zgu, ale to nie jest prawda. ByÅ‚oby to mylÄ…ce, aby myÅ›leÄ‡ o gÅ‚Ä™bokim uczeniu jako w jakikolwiek sposÃ³b zwiÄ…zanym z neurobiologiÄ…. Dla naszych celÃ³w, gÅ‚Ä™bokie uczenie jest matematycznÄ… strukturÄ… do uczenia siÄ™ reprezentacji danych.</p>
<p>Jak wyglÄ…dajÄ… reprezentacje wyuczone przez algorytm gÅ‚Ä™bokiego uczenia? Przyjrzyjmy siÄ™, jak sieÄ‡ o gÅ‚Ä™bokoÅ›ci kilku warstw (patrz <a href="#fig-dl1">Rysunek&nbsp;<span>10.2</span></a>) przeksztaÅ‚ca obraz cyfry w celu rozpoznania, jaka to cyfra.</p>
<div id="fig-dl1" class="quarto-figure quarto-figure-center anchored">
<figure class="figure"><p><img src="images/Zrzut ekranu 2023-02-23 o 19.22.38.png" class="img-fluid figure-img" width="600"></p>
<p></p><figcaption class="figure-caption">Rysunek&nbsp;10.2: Schemat dziaÅ‚ania sieci rozpoznajÄ…cej cyfry</figcaption><p></p>
</figure>
</div>
<p>Jak widaÄ‡ na <a href="#fig-dl2">Rysunek&nbsp;<span>10.3</span></a>, sieÄ‡ przeksztaÅ‚ca obraz cyfry w reprezentacje coraz bardziej rÃ³Å¼niÄ…ce siÄ™ od obrazu oryginalnego i coraz bardziej informujÄ…ce o wyniku koÅ„cowym. MoÅ¼na myÅ›leÄ‡ o sieci gÅ‚Ä™bokiej jak o wielostopniowej operacji destylacji informacji, gdzie informacja przechodzi przez kolejne filtry i wychodzi coraz bardziej oczyszczona (czyli przydatna w odniesieniu do jakiegoÅ› zadania).</p>
<div id="fig-dl2" class="quarto-figure quarto-figure-center anchored">
<figure class="figure"><p><img src="images/Zrzut ekranu 2023-02-23 o 19.24.25.png" class="img-fluid figure-img" width="600"></p>
<p></p><figcaption class="figure-caption">Rysunek&nbsp;10.3: Przedstawienie zasady dziaÅ‚ania poszczegÃ³lnych warstw sieci neuronowej w rozpoznawaniu cyfr</figcaption><p></p>
</figure>
</div>
<p>Tak wÅ‚aÅ›nie wyglÄ…da gÅ‚Ä™bokie uczenie, technicznie rzecz biorÄ…c: jest to wieloetapowy sposÃ³b uczenia siÄ™ reprezentacji danych. To prosty pomysÅ‚ - ale jak siÄ™ okazuje, bardzo proste mechanizmy, odpowiednio skalowane, mogÄ… w koÅ„cu wyglÄ…daÄ‡ jak magia.</p>
</section><section id="jak-dziaÅ‚a-deep-learning" class="level2" data-number="10.2"><h2 data-number="10.2" class="anchored" data-anchor-id="jak-dziaÅ‚a-deep-learning">
<span class="header-section-number">10.2</span> Jak dziaÅ‚a deep learning?</h2>
<p>W tym wiemy juÅ¼, Å¼e uczenie maszynowe polega na mapowaniu danych wejÅ›ciowych (takich jak obrazy) na dane docelowe (takie jak etykieta â€œkotâ€), co odbywa siÄ™ poprzez obserwacjÄ™ wielu przykÅ‚adÃ³w danych wejÅ›ciowych i danych docelowych. Wiemy teÅ¼, Å¼e gÅ‚Ä™bokie sieci neuronowe wykonujÄ… odwzorowanie danych wejÅ›ciowych na docelowe poprzez gÅ‚Ä™bokÄ… sekwencjÄ™ prostych transformacji danych (warstwy) i Å¼e te transformacje danych sÄ… uczone przez ekspozycjÄ™ na przykÅ‚ady. Przyjrzyjmy siÄ™ teraz, jak to uczenie przebiega, konkretnie.</p>
<p>Specyfikacja tego, co warstwa robi ze swoimi danymi wejÅ›ciowymi, jest przechowywana w wagach warstwy (zwanych wagami synaptycznymi), ktÃ³re w istocie sÄ… zbiorem liczb. W sensie technicznym moÅ¼na powiedzieÄ‡, Å¼e transformacja wykonywana przez warstwÄ™ jest sparametryzowana przez jej wagi (patrz <a href="#fig-dl3">Rysunek&nbsp;<span>10.4</span></a>). W tym kontekÅ›cie uczenie oznacza znalezienie zestawu wartoÅ›ci dla wag wszystkich warstw w sieci, tak aby sieÄ‡ poprawnie odwzorowywaÅ‚a przykÅ‚adowe wejÅ›cia na przypisane im cele. Rzecz w tym, Å¼e gÅ‚Ä™boka sieÄ‡ neuronowa moÅ¼e zawieraÄ‡ dziesiÄ…tki milionÃ³w parametrÃ³w. Znalezienie poprawnej wartoÅ›ci dla wszystkich z nich moÅ¼e wydawaÄ‡ siÄ™ trudnym zadaniem, szczegÃ³lnie biorÄ…c pod uwagÄ™ fakt, Å¼e zmiana wartoÅ›ci jednego parametru wpÅ‚ynie na zachowanie wszystkich pozostaÅ‚ych!</p>
<div id="fig-dl3" class="quarto-figure quarto-figure-center anchored">
<figure class="figure"><p><img src="images/Zrzut ekranu 2023-02-23 o 19.37.23.png" class="img-fluid figure-img" width="400"></p>
<p></p><figcaption class="figure-caption">Rysunek&nbsp;10.4: SieÄ‡ neuronowa parametryzowana przez wagi</figcaption><p></p>
</figure>
</div>
<p>Aby coÅ› kontrolowaÄ‡, trzeba najpierw mÃ³c to obserwowaÄ‡. Aby kontrolowaÄ‡ wyjÅ›cie sieci neuronowej, musisz byÄ‡ w stanie zmierzyÄ‡, jak daleko to wyjÅ›cie jest od tego, czego siÄ™ spodziewaÅ‚eÅ›. Jest to zadanie funkcji straty sieci, zwanej rÃ³wnieÅ¼ funkcjÄ… celu. Funkcja straty bierze predykcje sieci oraz prawdziwy wynik (to, co chciaÅ‚eÅ›, aby sieÄ‡ â€œwypluÅ‚aâ€) i oblicza wynik odlegÅ‚oÅ›ci, ujmujÄ…c, jak dobrze sieÄ‡ poradziÅ‚a sobie z tym konkretnym przykÅ‚adem (patrz <a href="#fig-dl4">Rysunek&nbsp;<span>10.5</span></a>).</p>
<div id="fig-dl4" class="quarto-figure quarto-figure-center anchored">
<figure class="figure"><p><img src="images/Zrzut ekranu 2023-02-23 o 19.37.35.png" class="img-fluid figure-img" width="400"></p>
<p></p><figcaption class="figure-caption">Rysunek&nbsp;10.5: Funkcja straty mierzÄ…ca jakoÅ›Ä‡ predykcji</figcaption><p></p>
</figure>
</div>
<p>PodstawowÄ… sztuczkÄ… w uczeniu gÅ‚Ä™bokim jest wykorzystanie wyniku jako sygnaÅ‚u zwrotnego do skorygowania wartoÅ›ci wag w kierunku, ktÃ³ry obniÅ¼y wynik straty dla bieÅ¼Ä…cego przykÅ‚adu (patrz <a href="#fig-dl5">Rysunek&nbsp;<span>10.6</span></a>). Ta korekta jest zadaniem optymalizatora, ktÃ³ry implementuje coÅ›, co nazywa siÄ™ algorytmem wstecznej propagacji (ang. <em>backpropagation</em>): gÅ‚Ã³wny algorytm w uczeniu gÅ‚Ä™bokim. W dalszej czÄ™Å›ci wyjaÅ›nimy bardziej szczegÃ³Å‚owo, jak dziaÅ‚a wsteczna propagacja.</p>
<div id="fig-dl5" class="quarto-figure quarto-figure-center anchored">
<figure class="figure"><p><img src="images/Zrzut ekranu 2023-02-23 o 19.37.48.png" class="img-fluid figure-img" width="400"></p>
<p></p><figcaption class="figure-caption">Rysunek&nbsp;10.6: Korekta wag wykorzystujÄ…ca wartoÅ›Ä‡ funkcji straty</figcaption><p></p>
</figure>
</div>
<p>PoczÄ…tkowo wagom sieci przypisane sÄ… losowe wartoÅ›ci, wiÄ™c sieÄ‡ wykonuje jedynie seriÄ™ losowych przeksztaÅ‚ceÅ„. OczywiÅ›cie jej wynik jest daleki od tego, jaki powinien byÄ‡ w idealnej sytuacji, a wynik funkcji straty jest bardzo wysoki. Ale z kaÅ¼dym przykÅ‚adem, ktÃ³ry sieÄ‡ przetwarza, wagi sÄ… dostosowywane w prawidÅ‚owym kierunku, a wynik strat maleje. Jest to pÄ™tla treningowa, ktÃ³ra powtarzana odpowiedniÄ… iloÅ›Ä‡ razy (zwykle dziesiÄ…tki iteracji na tysiÄ…cach przykÅ‚adÃ³w) daje wartoÅ›ci wag, ktÃ³re minimalizujÄ… funkcjÄ™ straty. SieÄ‡ z minimalnÄ… stratÄ… to taka, dla ktÃ³rej wyjÅ›cia sÄ… tak bliskie celom, jak to tylko moÅ¼liwe - sieÄ‡ wytrenowana.</p>
</section><section id="krÃ³tki-rys-historyczny-dl" class="level2 page-columns page-full" data-number="10.3"><h2 data-number="10.3" class="anchored" data-anchor-id="krÃ³tki-rys-historyczny-dl">
<span class="header-section-number">10.3</span> KrÃ³tki rys historyczny DL</h2>
<p>OkoÅ‚o 2010 roku, mimo Å¼e sieci neuronowe byÅ‚y niemal caÅ‚kowicie odrzucane przez ogÃ³Å‚ spoÅ‚ecznoÅ›ci naukowej, kilka osÃ³b wciÄ…Å¼ pracujÄ…cych nad sieciami neuronowymi zaczÄ™Å‚o dokonywaÄ‡ waÅ¼nych przeÅ‚omÃ³w: grupy Geoffreya Hintona z Uniwersytetu w Toronto, Yoshua Bengio z Uniwersytetu w Montrealu, Yann LeCun z Uniwersytetu Nowojorskiego oraz IDSIA w Szwajcarii.</p>
<div class="page-columns page-full"><p>W 2011 roku Dan Ciresan z IDSIA zaczÄ…Å‚ wygrywaÄ‡ akademickie konkursy klasyfikacji obrazÃ³w za pomocÄ… trenowanych na GPU gÅ‚Ä™bokich sieci neuronowych - byÅ‚ to pierwszy praktyczny sukces nowoczesnego uczenia gÅ‚Ä™bokiego. Jednak przeÅ‚omowy moment nastÄ…piÅ‚ w 2012 roku, gdy grupa Hintona wziÄ™Å‚a udziaÅ‚ w corocznym wyzwaniu ImageNet dotyczÄ…cym klasyfikacji obrazÃ³w na duÅ¼Ä… skalÄ™. Wyzwanie ImageNet byÅ‚o w tamtym czasie wyjÄ…tkowo trudne, polegaÅ‚o na klasyfikacji kolorowych obrazÃ³w o wysokiej rozdzielczoÅ›ci do 1000 rÃ³Å¼nych kategorii po przeszkoleniu na 1,4 mln obrazÃ³w. W 2011 roku dokÅ‚adnoÅ›Ä‡ zwyciÄ™skiego modelu, opartego na klasycznym podejÅ›ciu do widzenia komputerowego, wyniosÅ‚a zaledwie 74,3%. NastÄ™pnie, w 2012 roku, zespÃ³Å‚ kierowany przez Alexa Krizhevskyâ€™ego i wspierany przez Geoffreya Hintona byÅ‚ w stanie osiÄ…gnÄ…Ä‡ dokÅ‚adnoÅ›Ä‡ w pierwszej piÄ…tce<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a> na poziomie 83,6% - byÅ‚ to znaczÄ…cy przeÅ‚om. Od tego czasu co roku konkurs byÅ‚ zdominowany przez gÅ‚Ä™bokie konwencjonalne sieci neuronowe. W 2015 roku zwyciÄ™zca osiÄ…gnÄ…Å‚ dokÅ‚adnoÅ›Ä‡ 96,4%, a zadanie klasyfikacji na ImageNet uznano za caÅ‚kowicie rozwiÄ…zany problem.</p><div class="no-row-height column-margin column-container"><li id="fn1"><p><sup>1</sup>&nbsp;(ang. <em>top 5 accuracy</em>) <em>-</em> oznacza, Å¼e wÅ›rÃ³d 5 kategorii z najwyÅ¼szym prawdopodobieÅ„stwem jest prawdziwa klasa</p></li></div></div>
<p>Od 2012 r. gÅ‚Ä™bokie konwolucyjne sieci neuronowe (CovNets - <em>Convolutional Networks</em>) staÅ‚y siÄ™ algorytmem pierwszego wyboru dla wszystkich zadaÅ„ widzenia komputerowego. Na najwaÅ¼niejszych konferencjach poÅ›wiÄ™conych widzeniu komputerowemu w 2015 i 2016 r. niemal niemoÅ¼liwe byÅ‚o znalezienie prezentacji, ktÃ³re w jakiejÅ› formie nie wiÄ…zaÅ‚yby siÄ™ z CovNets. JednoczeÅ›nie gÅ‚Ä™bokie uczenie znalazÅ‚o zastosowanie w wielu innych typach problemÃ³w, takich jak np. przetwarzanie jÄ™zyka naturalnego. W szerokim zakresie zastosowaÅ„ caÅ‚kowicie zastÄ…piÅ‚o klasyczne modele SVM i drzewa decyzyjne. Na przykÅ‚ad przez kilka lat Europejska Organizacja BadaÅ„ JÄ…drowych (CERN), uÅ¼ywaÅ‚a metod opartych na drzewach decyzyjnych do analizy danych czÄ…stek z detektora ATLAS w Wielkim Zderzaczu HadronÃ³w (LHC); ale CERN ostatecznie przeszedÅ‚ na gÅ‚Ä™bokie sieci neuronowe oparte na Keras ze wzglÄ™du na ich wyÅ¼szÄ… wydajnoÅ›Ä‡ i Å‚atwoÅ›Ä‡ szkolenia na duÅ¼ych zbiorach danych.</p>
<p>Podstawowym powodem, dla ktÃ³rego uczenie gÅ‚Ä™bokie odniosÅ‚o sukces tak szybko, jest to, Å¼e oferowaÅ‚o lepszÄ… wydajnoÅ›Ä‡ w wielu problemach. Ale to nie jest jedyny powÃ³d. GÅ‚Ä™bokie uczenie uÅ‚atwia rÃ³wnieÅ¼ rozwiÄ…zywanie problemÃ³w, poniewaÅ¼ caÅ‚kowicie automatyzuje to, co kiedyÅ› byÅ‚o najbardziej kluczowym krokiem w procesie uczenia maszynowego: inÅ¼ynieriÄ™ cech.</p>
<p>Poprzednie techniki uczenia maszynowego - uczenie gÅ‚Ä™bokie - polegaÅ‚y jedynie na przeksztaÅ‚ceniu danych wejÅ›ciowych w jednÄ… lub dwie kolejne przestrzenie reprezentacji, zwykle poprzez proste przeksztaÅ‚cenia, takie jak wielowymiarowe projekcje nieliniowe (SVM) lub drzewa decyzyjne. Jednak wyrafinowane reprezentacje wymagane przez zÅ‚oÅ¼one problemy zazwyczaj nie mogÄ… byÄ‡ realizowane przez wspomniane techniki. W zwiÄ…zku z tym, ludzie musieli zadaÄ‡ sobie wiele trudu, aby uczyniÄ‡ poczÄ…tkowe dane wejÅ›ciowe bardziej podatnymi na przetwarzanie przez te metody: to znaczy, musieli rÄ™cznie oparcowaÄ‡ dobre warstwy reprezentacji dla swoich danych. Nazywa siÄ™ to inÅ¼ynieriÄ… cech. Uczenie gÅ‚Ä™bokie caÅ‚kowicie automatyzuje ten krok: w przypadku uczenia gÅ‚Ä™bokiego, uczysz siÄ™ wszystkich cech w jednym przejÅ›ciu i nie musisz ich samodzielnie opracowywaÄ‡. To znacznie uproÅ›ciÅ‚o przepÅ‚ywy pracy zwiÄ…zane z uczeniem maszynowym, czÄ™sto zastÄ™pujÄ…c skomplikowane, wieloetapowe potoki jednym, prostym, kompleksowym modelem uczenia gÅ‚Ä™bokiego.</p>
<p>MoÅ¼na zapytaÄ‡, skoro sednem sprawy jest posiadanie wielu kolejnych warstw reprezentacji, to czy pÅ‚ytkie metody mogÄ… byÄ‡ stosowane wielokrotnie, aby emulowaÄ‡ efekty gÅ‚Ä™bokiego uczenia? W praktyce, korzyÅ›Ä‡ z zastosowania kilku metod pÅ‚ytkiego uczenia szybko maleje, poniewaÅ¼ optymalna pierwsza warstwa reprezentacji w modelu trÃ³jwarstwowym nie jest optymalnÄ… pierwszÄ… warstwÄ… w modelu jedno- lub dwuwarstwowym. To, co jest przeÅ‚omowe w uczeniu gÅ‚Ä™bokim, to fakt, Å¼e pozwala ono modelowi uczyÄ‡ siÄ™ wszystkich warstw reprezentacji wspÃ³lnie, w tym samym czasie, a nie po kolei (zachÅ‚annie). DziÄ™ki wspÃ³lnemu uczeniu cech, gdy model dostosowuje jednÄ… ze swoich wewnÄ™trznych cech, wszystkie inne cechy, ktÃ³re od niej zaleÅ¼Ä…, automatycznie dostosowujÄ… siÄ™ do tej zmiany, bez koniecznoÅ›ci interwencji czÅ‚owieka. Wszystko jest nadzorowane przez pojedynczy sygnaÅ‚ zwrotny: kaÅ¼da zmiana w modelu sÅ‚uÅ¼y celowi koÅ„cowemu. Jest to znacznie potÄ™Å¼niejsze niÅ¼ skÅ‚adanie pÅ‚ytkich modeli, poniewaÅ¼ pozwala na uczenie siÄ™ zÅ‚oÅ¼onych, abstrakcyjnych reprezentacji poprzez rozbicie ich na dÅ‚ugie serie poÅ›rednich warstw; kaÅ¼da warstwa jest tylko prostym przeksztaÅ‚ceniem w stosunku do poprzedniej.</p>
<p>SÄ… to dwie zasadnicze cechy tego, jak gÅ‚Ä™bokie uczenie uczy siÄ™ z danych: przyrostowy, warstwa po warstwie sposÃ³b, w jaki korygowane sÄ… coraz bardziej zÅ‚oÅ¼one reprezentacje, oraz fakt, Å¼e te poÅ›rednie, przyrostowe reprezentacje sÄ… uczone wspÃ³lnie, a kaÅ¼da warstwa jest aktualizowana, aby podÄ…Å¼aÄ‡ zarÃ³wno za potrzebami reprezentacyjnymi warstwy powyÅ¼ej, jak i potrzebami warstwy poniÅ¼ej. Razem, te dwie wÅ‚aÅ›ciwoÅ›ci sprawiÅ‚y, Å¼e gÅ‚Ä™bokie uczenie jest znacznie bardziej skuteczne niÅ¼ poprzednie podejÅ›cia do uczenia maszynowego.</p>
<p>Åšwietnym sposobem na poznanie aktualnego krajobrazu algorytmÃ³w i narzÄ™dzi uczenia maszynowego jest przyjrzenie siÄ™ konkursom uczenia maszynowego na Kaggle. DziÄ™ki wysoce konkurencyjnemu Å›rodowisku (niektÃ³re konkursy majÄ… tysiÄ…ce uczestnikÃ³w i milionowe nagrody) i szerokiej gamie problemÃ³w uczenia maszynowego, Kaggle oferuje realistyczny sposÃ³b oceny tego, co dziaÅ‚a, a co nie. Jaki wiÄ™c rodzaj algorytmu niezawodnie wygrywa konkursy? Z jakich narzÄ™dzi korzystajÄ… najlepsi uczestnicy?<br></p>
<p>W 2016 roku Kaggle zostaÅ‚ zdominowany przez dwa podejÅ›cia: gradient boosting machines i deep learning. Konkretnie, gradient boosting jest uÅ¼ywany do problemÃ³w, w ktÃ³rych dostÄ™pne sÄ… ustrukturyzowane dane, podczas gdy gÅ‚Ä™bokie uczenie jest uÅ¼ywane do problemÃ³w percepcyjnych, takich jak klasyfikacja obrazÃ³w. Zwolennicy tego pierwszego rozwiÄ…zania prawie zawsze korzystajÄ… ze znakomitej biblioteki <code>XGBoost</code>. Tymczasem wiÄ™kszoÅ›Ä‡ uczestnikÃ³w Kaggle wykorzystujÄ…cych uczenie gÅ‚Ä™bokie uÅ¼ywa biblioteki <code>Keras</code>, ze wzglÄ™du na jej Å‚atwoÅ›Ä‡ uÅ¼ycia i elastycznoÅ›Ä‡. ZarÃ³wno <code>XGBoost</code>, jak i <code>Keras</code> wspierajÄ… dwa najpopularniejsze jÄ™zyki data science: R i Python.</p>
<section id="hardware" class="level3" data-number="10.3.1"><h3 data-number="10.3.1" class="anchored" data-anchor-id="hardware">
<span class="header-section-number">10.3.1</span> Hardware</h3>
<p>W latach 1990-2010 procesory dostÄ™pne na rynku staÅ‚y siÄ™ szybsze o okoÅ‚o 5000 razy. W rezultacie, obecnie moÅ¼liwe jest uruchomienie maÅ‚ych modeli gÅ‚Ä™bokiego uczenia na laptopie, podczas gdy 25 lat temu byÅ‚oby to niewykonalne.</p>
<p>Jednak typowe modele gÅ‚Ä™bokiego uczenia wykorzystywane w wizji komputerowej lub rozpoznawaniu mowy wymagajÄ… mocy obliczeniowej o kilka rzÄ™dÃ³w wielkoÅ›ci wiÄ™kszej niÅ¼ ta, ktÃ³rÄ… moÅ¼e zapewniÄ‡ laptop. Przez caÅ‚Ä… dekadÄ™ XXI wieku firmy takie jak NVIDIA i AMD inwestowaÅ‚y miliardy dolarÃ³w w rozwÃ³j szybkich, rÃ³wnolegÅ‚ych ukÅ‚adÃ³w (procesorÃ³w graficznych [GPU]), ktÃ³re napÄ™dzaÅ‚y grafikÄ™ w coraz bardziej fotorealistycznych grach wideo - tanich, osobistych komputerÃ³w zaprojektowanych do renderowania zÅ‚oÅ¼onych scen 3D na ekranie w czasie rzeczywistym. Inwestycja ta przyniosÅ‚a korzyÅ›ci spoÅ‚ecznoÅ›ci naukowej, gdy w 2007 roku NVIDIA wprowadziÅ‚a CUDA (<a href="https://developer.nvidia.com/about-cuda" class="uri">https://developer.nvidia.com/about-cuda</a>), interfejs programistyczny dla swojej linii ukÅ‚adÃ³w GPU. Niewielka liczba procesorÃ³w graficznych zaczÄ™Å‚a zastÄ™powaÄ‡ klastry CPU w rÃ³Å¼nych zÅ‚oÅ¼onych zadaniach, poczÄ…wszy od modelowania w fizyce. GÅ‚Ä™bokie sieci neuronowe, skÅ‚adajÄ…ce siÄ™ gÅ‚Ã³wnie z wielu mnoÅ¼eÅ„ macierzy, sÄ… rÃ³wnieÅ¼ wysoce paralelizowalne i okoÅ‚o 2011 roku niektÃ³rzy badacze zaczÄ™li pisaÄ‡ implementacje CUDA sieci neuronowych - jednymi z pierwszych byli Dan Ciresan<span class="citation" data-cites="ciresanFlexibleHighPerformance">(<a href="references.html#ref-ciresanFlexibleHighPerformance" role="doc-biblioref">Ciresan i in., b.d.</a>)</span> i Alex Krizhevsky<span class="citation" data-cites="krizhevsky2017">(<a href="references.html#ref-krizhevsky2017" role="doc-biblioref">Krizhevsky, Sutskever, i Hinton 2017</a>)</span>.</p>
<p><br>
StaÅ‚o siÄ™ tak, Å¼e rynek gier dofinansowaÅ‚ superkomputery dla nastÄ™pnej generacji aplikacji sztucznej inteligencji. Czasami wielkie rzeczy zaczynajÄ… siÄ™ do zabawy ğŸ™ˆ. DziÅ› NVIDIA Titan X, procesor graficzny dla graczy, ktÃ³ry kosztowaÅ‚ 1000 dolarÃ³w pod koniec 2015 roku, moÅ¼e zapewniÄ‡ szczytowÄ… wydajnoÅ›Ä‡ 6,6 TLOPS w pojedynczej precyzji: to znaczy 6,6 biliona operacji float32 na sekundÄ™. To okoÅ‚o 350 razy wiÄ™cej niÅ¼ to, co moÅ¼na wyciÄ…gnÄ…Ä‡ z nowoczesnego laptopa. Na Tytanie X trenowanie modelu ImageNet, ktÃ³ry kilka lat temu wygraÅ‚by konkurs ILSVRC, zajmuje zaledwie kilka dni. Tymczasem duÅ¼e firmy trenujÄ… modele gÅ‚Ä™bokiego uczenia na klastrach skÅ‚adajÄ…cych siÄ™ z setek jednostek GPU, takich jak NVIDIA K80, opracowanych specjalnie na potrzeby gÅ‚Ä™bokiego uczenia. Sama moc obliczeniowa takich klastrÃ³w jest czymÅ›, co nigdy nie byÅ‚oby moÅ¼liwe bez nowoczesnych procesorÃ³w graficznych.</p>
<p>Co wiÄ™cej, branÅ¼a gÅ‚Ä™bokiego uczenia zaczyna wychodziÄ‡ poza procesory graficzne i inwestuje w coraz bardziej wyspecjalizowane, wydajne ukÅ‚ady do gÅ‚Ä™bokiego uczenia. W 2016 roku, na corocznej konwencji I/O, Google ujawniÅ‚o swÃ³j projekt procesora tensorowego (TPU): nowy ukÅ‚ad scalony opracowany od podstaw w celu uruchamiania gÅ‚Ä™bokich sieci neuronowych, ktÃ³ry jest podobno 10 razy szybszy i znacznie bardziej energooszczÄ™dny niÅ¼ topowe ukÅ‚ady GPU.</p>
</section><section id="dane" class="level3 page-columns page-full" data-number="10.3.2"><h3 data-number="10.3.2" class="anchored" data-anchor-id="dane">
<span class="header-section-number">10.3.2</span> Dane</h3>
<div class="page-columns page-full"><p>AI jest czasem zapowiadana jako nowa rewolucja przemysÅ‚owa. JeÅ›li gÅ‚Ä™bokie uczenie jest maszynÄ… parowÄ… tej rewolucji, to dane sÄ… jej wÄ™glem: surowcem, ktÃ³ry zasila nasze inteligentne maszyny, bez ktÃ³rego nic nie byÅ‚oby moÅ¼liwe. JeÅ›li chodzi o dane, to oprÃ³cz wykÅ‚adniczego postÄ™pu w dziedzinie sprzÄ™tu do przechowywania danych w ciÄ…gu ostatnich 20 lat (zgodnie z prawem Mooreâ€™a<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a>), kluczowym czynnikiem byÅ‚ rozwÃ³j Internetu, dziÄ™ki ktÃ³remu moÅ¼liwe staÅ‚o siÄ™ gromadzenie i rozpowszechnianie bardzo duÅ¼ych zbiorÃ³w danych na potrzeby uczenia maszynowego. Obecnie duÅ¼e firmy pracujÄ… z zestawami danych obrazowych, zestawami danych wideo i zestawami danych w jÄ™zyku naturalnym, ktÃ³re nie mogÅ‚yby zostaÄ‡ zebrane bez Internetu. PrzykÅ‚adowo, generowane przez uÅ¼ytkownikÃ³w tagi do obrazÃ³w w serwisie Flickr sÄ… skarbnicÄ… danych dla wizji komputerowej. Podobnie jest z filmami z YouTube. A Wikipedia jest kluczowym zbiorem danych dla przetwarzania jÄ™zyka naturalnego.</p><div class="no-row-height column-margin column-container"><li id="fn2"><p><sup>2</sup>&nbsp;mÃ³wi o tym, Å¼e liczba tranzystorÃ³w w procesorach roÅ›nie wykÅ‚adniczo</p></li></div></div>
<p>JeÅ›li jest jakiÅ› zbiÃ³r danych, ktÃ³ry staÅ‚ siÄ™ katalizatorem rozwoju gÅ‚Ä™bokiego uczenia, to jest to zbiÃ³r danych ImageNet, skÅ‚adajÄ…cy siÄ™ z 1,4 miliona obrazÃ³w, ktÃ³re zostaÅ‚y rÄ™cznie przypisane do 1000 kategorii obrazÃ³w (1 kategoria na obraz). Jednak to, co czyni ImageNet wyjÄ…tkowym, to nie tylko jego duÅ¼y rozmiar, ale takÅ¼e coroczny konkurs z nim zwiÄ…zany. Jak pokazuje Kaggle od 2010 roku, publiczne konkursy sÄ… doskonaÅ‚ym sposobem motywowania naukowcÃ³w i inÅ¼ynierÃ³w do przekraczania granic. Posiadanie wspÃ³lnych benchmarkÃ³w, ktÃ³re badacze starajÄ… siÄ™ pokonaÄ‡, bardzo pomogÅ‚o w niedawnym rozwoju uczenia gÅ‚Ä™bokiego.</p>
</section><section id="algorytmy" class="level3" data-number="10.3.3"><h3 data-number="10.3.3" class="anchored" data-anchor-id="algorytmy">
<span class="header-section-number">10.3.3</span> Algorytmy</h3>
<p>OprÃ³cz sprzÄ™tu i danych, aÅ¼ do pÃ³Åºnych lat 2000 brakowaÅ‚o nam niezawodnego sposobu trenowania bardzo gÅ‚Ä™bokich sieci neuronowych. W rezultacie sieci neuronowe byÅ‚y wciÄ…Å¼ doÅ›Ä‡ pÅ‚ytkie, wykorzystujÄ…c tylko jednÄ… lub dwie warstwy reprezentacji; nie byÅ‚y wiÄ™c w stanie zabÅ‚ysnÄ…Ä‡ w porÃ³wnaniu z bardziej wyrafinowanymi pÅ‚ytkimi metodami, takimi jak SVM czy lasy losowe. Kluczowym problemem byÅ‚a propagacja gradientu przez gÅ‚Ä™bokie stosy warstw. SygnaÅ‚ zwrotny uÅ¼ywany do trenowania sieci neuronowych zanikaÅ‚ wraz ze wzrostem liczby warstw.</p>
<p>ZmieniÅ‚o siÄ™ to okoÅ‚o 2009-2010 roku wraz z pojawieniem siÄ™ kilku prostych, ale waÅ¼nych ulepszeÅ„ algorytmicznych, ktÃ³re pozwoliÅ‚y na lepszÄ… propagacjÄ™ gradientu:</p>
<ul>
<li>lepsze funkcje aktywacji dla warstw neuronowych;</li>
<li>lepsze schematy inicjalizacji wag, poczÄ…wszy od wstÄ™pnego szkolenia z podziaÅ‚em na warstwy, ktÃ³re zostaÅ‚o szybko porzucone;</li>
<li>lepsze schematy optymalizacji, takie jak RMSProp i Adam.</li>
</ul>
<p>Dopiero gdy te ulepszenia zaczÄ™Å‚y umoÅ¼liwiaÄ‡ trenowanie modeli z 10 lub wiÄ™cej warstwami, uczenie gÅ‚Ä™bokie zaczÄ™Å‚o bÅ‚yszczeÄ‡. Wreszcie w latach 2014, 2015 i 2016 odkryto jeszcze bardziej zaawansowane sposoby wspomagania propagacji gradientu, takie jak normalizacja partii (ang. <em>batch normalization</em>), poÅ‚Ä…czenia resztkowe (ang. <em>residual connections</em>) czy konwolucje separowalne w gÅ‚Ä…b (ang. <em>depthwise separable convolutions</em>). DziÅ› moÅ¼emy trenowaÄ‡ od podstaw modele, ktÃ³re majÄ… tysiÄ…ce warstw gÅ‚Ä™bokoÅ›ci.</p>
<p>Czy jest coÅ› szczegÃ³lnego w gÅ‚Ä™bokich sieciach neuronowych, co sprawia, Å¼e sÄ… one â€œwÅ‚aÅ›ciwymâ€ podejÅ›ciem dla firm, w ktÃ³re naleÅ¼y inwestowaÄ‡ i dla naukowcÃ³w, ktÃ³rzy chcÄ… siÄ™ nimi zainteresowaÄ‡? Czy moÅ¼e gÅ‚Ä™bokie uczenie siÄ™ jest tylko modÄ…, ktÃ³ra moÅ¼e nie przetrwaÄ‡? Czy za 20 lat nadal bÄ™dziemy uÅ¼ywaÄ‡ gÅ‚Ä™bokich sieci neuronowych?</p>
<p>KrÃ³tka odpowiedÅº brzmi: tak ğŸ™ - gÅ‚Ä™bokie uczenie ma kilka wÅ‚aÅ›ciwoÅ›ci, ktÃ³re uzasadniajÄ… jego status jako rewolucji AI. ByÄ‡ moÅ¼e za dwie dekady nie bÄ™dziemy uÅ¼ywaÄ‡ sieci neuronowych, ale cokolwiek bÄ™dziemy uÅ¼ywaÄ‡, bÄ™dzie bezpoÅ›rednio dziedziczyÄ‡ po nowoczesnym gÅ‚Ä™bokim uczeniu i jego podstawowych koncepcjach. NajwaÅ¼niejsze wÅ‚aÅ›ciwoÅ›ci moÅ¼na ogÃ³lnie podzieliÄ‡ na trzy kategorie:</p>
<ul>
<li>Prostota - gÅ‚Ä™bokie uczenie eliminuje potrzebÄ™ inÅ¼ynierii cech, zastÄ™pujÄ…c zÅ‚oÅ¼one, wraÅ¼liwe i wymagajÄ…ce inÅ¼ynierii potoki prostymi, kompleksowo wytrenowanymi modelami, ktÃ³re sÄ… zazwyczaj budowane przy uÅ¼yciu tylko piÄ™ciu lub szeÅ›ciu rÃ³Å¼nych operacji na tensorach.</li>
<li>SkalowalnoÅ›Ä‡ - gÅ‚Ä™bokie uczenie jest bardzo podatne na rÃ³wnolegÅ‚e przetwarzanie na ukÅ‚adach GPU lub TPU. Dodatkowo, modele gÅ‚Ä™bokiego uczenia sÄ… trenowane poprzez iteracjÄ™ na maÅ‚ych partiach danych, co pozwala na ich trenowanie na zbiorach danych o dowolnym rozmiarze. (Jedynym wÄ…skim gardÅ‚em jest iloÅ›Ä‡ dostÄ™pnej mocy obliczeniowej).</li>
<li>WszechstronnoÅ›Ä‡ i moÅ¼liwoÅ›Ä‡ ponownego wykorzystania - w przeciwieÅ„stwie do wielu wczeÅ›niejszych podejÅ›Ä‡ do uczenia maszynowego, modele gÅ‚Ä™bokiego uczenia mogÄ… byÄ‡ trenowane na dodatkowych danych bez koniecznoÅ›ci ponownego rozpoczynania od zera, co czyni je realnymi dla ciÄ…gÅ‚ego uczenia siÄ™ na bierzÄ…co - waÅ¼na wÅ‚aÅ›ciwoÅ›Ä‡ dla bardzo duÅ¼ych modeli produkcyjnych. Co wiÄ™cej, wytrenowane modele gÅ‚Ä™bokiego uczenia mogÄ… byÄ‡ ponownie wykorzystane, na przykÅ‚ad, moÅ¼liwe jest wziÄ™cie modelu gÅ‚Ä™bokiego uczenia wytrenowanego do klasyfikacji obrazÃ³w i wrzucenie go do potoku przetwarzania wideo.</li>
</ul>


<div id="refs" class="references csl-bib-body hanging-indent" role="doc-bibliography" style="display: none">
<div id="ref-ciresanFlexibleHighPerformance" class="csl-entry" role="doc-biblioentry">
Ciresan, Dan C, Ueli Meier, Jonathan Masci, Luca M Gambardella, i Jurgen Schmidhuber. b.d. <span>â€Flexible, <span>High Performance Convolutional Neural Networks</span> for <span>Image Classification</span>â€</span>.
</div>
<div id="ref-krizhevsky2017" class="csl-entry" role="doc-biblioentry">
Krizhevsky, Alex, Ilya Sutskever, i Geoffrey E. Hinton. 2017. <span>â€ImageNet Classification with Deep Convolutional Neural Networksâ€</span>. <em>Communications of the ACM</em> 60 (6): 84â€“90. <a href="https://doi.org/10.1145/3065386">https://doi.org/10.1145/3065386</a>.
</div>
</div>
</section></section></main><!-- /main --><script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const disableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'prefetch';
    }
  }
  const enableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'stylesheet';
    }
  }
  const manageTransitions = (selector, allowTransitions) => {
    const els = window.document.querySelectorAll(selector);
    for (let i=0; i < els.length; i++) {
      const el = els[i];
      if (allowTransitions) {
        el.classList.remove('notransition');
      } else {
        el.classList.add('notransition');
      }
    }
  }
  const toggleColorMode = (alternate) => {
    // Switch the stylesheets
    const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
    manageTransitions('#quarto-margin-sidebar .nav-link', false);
    if (alternate) {
      enableStylesheet(alternateStylesheets);
      for (const sheetNode of alternateStylesheets) {
        if (sheetNode.id === "quarto-bootstrap") {
          toggleBodyColorMode(sheetNode);
        }
      }
    } else {
      disableStylesheet(alternateStylesheets);
      toggleBodyColorPrimary();
    }
    manageTransitions('#quarto-margin-sidebar .nav-link', true);
    // Switch the toggles
    const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
    for (let i=0; i < toggles.length; i++) {
      const toggle = toggles[i];
      if (toggle) {
        if (alternate) {
          toggle.classList.add("alternate");     
        } else {
          toggle.classList.remove("alternate");
        }
      }
    }
    // Hack to workaround the fact that safari doesn't
    // properly recolor the scrollbar when toggling (#1455)
    if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
      manageTransitions("body", false);
      window.scrollTo(0, 1);
      setTimeout(() => {
        window.scrollTo(0, 0);
        manageTransitions("body", true);
      }, 40);  
    }
  }
  const isFileUrl = () => { 
    return window.location.protocol === 'file:';
  }
  const hasAlternateSentinel = () => {  
    let styleSentinel = getColorSchemeSentinel();
    if (styleSentinel !== null) {
      return styleSentinel === "alternate";
    } else {
      return false;
    }
  }
  const setStyleSentinel = (alternate) => {
    const value = alternate ? "alternate" : "default";
    if (!isFileUrl()) {
      window.localStorage.setItem("quarto-color-scheme", value);
    } else {
      localAlternateSentinel = value;
    }
  }
  const getColorSchemeSentinel = () => {
    if (!isFileUrl()) {
      const storageValue = window.localStorage.getItem("quarto-color-scheme");
      return storageValue != null ? storageValue : localAlternateSentinel;
    } else {
      return localAlternateSentinel;
    }
  }
  let localAlternateSentinel = 'default';
  // Dark / light mode switch
  window.quartoToggleColorScheme = () => {
    // Read the current dark / light value 
    let toAlternate = !hasAlternateSentinel();
    toggleColorMode(toAlternate);
    setStyleSentinel(toAlternate);
  };
  // Ensure there is a toggle, if there isn't float one in the top right
  if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
    const a = window.document.createElement('a');
    a.classList.add('top-right');
    a.classList.add('quarto-color-scheme-toggle');
    a.href = "";
    a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
    const i = window.document.createElement("i");
    i.classList.add('bi');
    a.appendChild(i);
    window.document.body.appendChild(a);
  }
  // Switch to dark mode if need be
  if (hasAlternateSentinel()) {
    toggleColorMode(true);
  } else {
    toggleColorMode(false);
  }
  const icon = "î§‹";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Skopiowano!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Skopiowano!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script><nav class="page-navigation"><div class="nav-page nav-page-previous">
      <a href="./fourier.html" class="pagination-link">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Transformata Fouriera</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./references.html" class="pagination-link">
        <span class="nav-page-text">Bibliografia</span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->
<footer class="footer"><div class="nav-footer">
    <div class="nav-footer-left">Automatyczna analiza obrazu, Dariusz Majerek</div>   
    <div class="nav-footer-right">KsiÄ…Å¼ka zostaÅ‚a napisana w <a href="https://quarto.org/">Quarto</a></div>
  </div>
</footer>


</body></html>